{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Spatial-omics pipeline and analysis","text":"<p>Built on top of SpatialData, Sopa enables processing and analyses of spatial omics data with single-cell resolution (spatial transcriptomics or multiplex imaging data) using a standard data structure and output. We currently support the following technologies: Xenium, Visium HD, MERSCOPE, CosMx, PhenoCycler, MACSima, Molecular Cartography, and others. Sopa was designed for generability and low memory consumption on large images (scales to <code>1TB+</code> images).</p> <p>Info</p> <p>You may also be interested in Novae, developed by the same authors, now published in Nature Methods \ud83c\udf89</p>"},{"location":"#overview","title":"Overview","text":"<p>The following illustration describes the main steps of <code>sopa</code>:</p> <p> </p>"},{"location":"#why-use-sopa","title":"Why use <code>sopa</code>","text":"<p>Sopa is a modern Python toolkit that is easy to use and offers many advantages:</p> <ul> <li><code>sopa</code> is designed to be memory-efficient, and it scales to slides with millions of cells</li> <li><code>sopa</code> can be used on any spatial technology with single-cell resolution, making it straightforward to apply it to multiple projects</li> <li>Many segmentation tools are implemented in Sopa, so you can try/compare them all easily</li> <li>Depending on your need, you can use our API, CLI, or directly the Snakemake pipeline</li> <li>You can visualize your data in an interactive manner</li> <li>Spatial operations are optimized and use <code>shapely</code> internally</li> <li><code>sopa</code> integrates naturally with other community tools such as Scanpy or Squidpy.</li> </ul> <p>Start using Sopa by reading our getting started guide!</p>"},{"location":"cite_us/","title":"Cite us","text":"<p>Our article is published in Nature Communications. You can cite our paper as below:</p> <pre><code>Blampey, Q., Mulder, K., Gardet, M. et al. Sopa: a technology-invariant pipeline for analyses of image-based spatial omics.\nNat Commun 15, 4981 (2024). https://doi.org/10.1038/s41467-024-48981-z\n</code></pre> <p>This library has been developed by Quentin Blampey, PhD researcher in biomathematics and deep learning. The following institutions funded this work:</p> <ul> <li>Lab of Mathematics and Computer Science (MICS), CentraleSup\u00e9lec (Engineering School, Paris-Saclay University).</li> <li>PRISM center, Gustave Roussy Institute (Cancer campus, Paris-Saclay University).</li> </ul>"},{"location":"faq/","title":"Frequently asked questions","text":""},{"location":"faq/#what-are-the-inputs-of-sopa","title":"What are the inputs of Sopa?","text":"<p>You need the raw inputs of your machine, that is:</p> <ul> <li> <p>One or multiple image(s), usually corresponding to one or multiple <code>.tiff</code> file(s)</p> </li> <li> <p>Optionally, a file of transcript location, usually a <code>.csv</code> or <code>.parquet</code> file</p> </li> </ul> <p>In this documentation, <code>data_path</code> denotes the path to your raw data. Select the correct tab below to understand what is the right path to your raw data:</p> XeniumMERSCOPECosMxMACSimaPhenoCyclerHyperionOthers (CZI, ...) <p><code>data_path</code> is the path to the directory containing the following files: <code>morphology.ome.tif</code>, <code>experiment.xenium</code> and <code>transcripts.parquet</code>. In brief, you should have this file structure:</p> <pre><code>.\n\u251c\u2500 morphology_focus.ome.tif   # or a directory (for recent versions of the Xenium)\n\u251c\u2500 experiment.xenium\n\u2514\u2500 transcripts.parquet\n</code></pre> <p><code>data_path</code> is the path to the \"region\" directory containing a <code>detected_transcripts.csv</code> file and an <code>images</code> directory. For instance, the directory may be called <code>region_0</code>. In brief, you should have this file structure:</p> <pre><code>.\n\u251c\u2500 detected_transcripts.csv\n\u2514\u2500 images\n   \u251c\u2500 mosaic_{stain}_z{z_layer}.tif\n   \u2514\u2500 micron_to_mosaic_pixel_transform.csv\n</code></pre> <p><code>data_path</code> is the path to the directory containing:</p> <ul> <li>a transcript file <code>*_tx_file</code> (with columns <code>target</code>, <code>x_global_px</code>, <code>y_global_px</code>)</li> <li>a FOV locations file <code>*_fov_positions_file</code> (with columns <code>FOV</code>, <code>X_mm</code>, <code>Y_mm</code>)</li> <li>a <code>Morphology_ChannelID_Dictionary.txt</code> file containing channel names</li> <li>a <code>Morphology2D</code> directory containing the images, end in <code>_F*.TIF</code>.</li> </ul> <p>These files must be exported as flat files in AtomX. That is: within a study, click on \"Export\" and then select files from the \"Flat CSV Files\" section (transcripts flat and FOV position flat). You should have this file structure:</p> <pre><code>.\n\u251c\u2500 &lt;DATASET_ID&gt;_tx_file.csv (or csv.gz)\n\u251c\u2500 &lt;DATASET_ID&gt;_fov_positions_file.csv (or csv.gz)\n\u251c\u2500 Morphology_ChannelID_Dictionary.txt\n\u2514\u2500 Morphology2D\n   \u251c\u2500 XXX_F001.TIF\n   \u251c\u2500 XXX_F002.TIF\n   \u2514\u2500 ...\n</code></pre> <p><code>data_path</code> is the path to the directory containing multiple <code>.ome.tif</code> files (one file per channel). In brief, you should have this file structure:</p> <pre><code>.\n\u251c\u2500 AAA.ome.tif\n\u251c\u2500 BBB.ome.tif\n\u2514\u2500 CCC.ome.tif\n</code></pre> <p><code>data_path</code> is the path to one <code>.qptiff</code> file, or one <code>.tif</code> file (if exported from QuPath).</p> <p><code>data_path</code> is path to the directory containing multiple <code>.ome.tiff</code> files (one file per channel). In brief, you should have this file structure: <pre><code>.\n\u251c\u2500 AAA.ome.tiff\n\u251c\u2500 BBB.ome.tiff\n\u2514\u2500 CCC.ome.tiff\n</code></pre></p> <p>Other file formats (ND2, CZI, LIF, or DV) are supported via the <code>bioio</code> reader. In that case, you'll need to add new dependencies: <code>pip install bioio</code> (and potentially some file-format specific dependencies, see documentation).</p> <p>This reader is called <code>bioio</code>, i.e. you can use it via <code>sopa.io.bioio(data_path)</code>, where <code>data_path</code> is the path to your data file containing your image(s). For the Snakemake pipeline, provide <code>bioio</code> as a <code>technology</code> in the config file.</p>"},{"location":"faq/#how-to-disable-the-auto-save","title":"How to disable the auto-save?","text":"<p>When using the API, and when your <code>SpatialData</code> object is saved on-disk, Sopa will automatically save any new spatial element on disk by default. To disable this behavior, use the following command from the API:</p> <pre><code>sopa.settings.auto_save_on_disk = False\n</code></pre>"},{"location":"faq/#how-to-parallelize-segmentation","title":"How to parallelize segmentation?","text":"<p>Some steps of Sopa, notably the segmentation, can be accelerated via a parallelization backend. If you use the API, you can set the <code>\"dask\"</code> backend as below.</p> <pre><code># when using the API\nsopa.settings.parallelization_backend = \"dask\"\n</code></pre> <p>Otherwise, if you don't use the API, you can also set the <code>SOPA_PARALLELIZATION_BACKEND</code> env variable, e.g.: <pre><code>export SOPA_PARALLELIZATION_BACKEND=dask\n</code></pre></p> <p>Warning</p> <p>The <code>dask</code> backend is still experimental. You can add a comment to this issue to help us improve it.</p> <p>You can also pass some kwargs to the dask Client as below. These kwargs are highly dependent of your cluster and the size of your patches. For \"middle-size\" patches, we recommend about 4GB of memory per worker for cellpose, and between 8GB and 16GB or memory for baysor.</p> <pre><code>sopa.settings.dask_client_kwargs[\"n_workers\"] = 4\n</code></pre> <p>For testing purposes, you can run the lines below, which will show you how many workers and memory you have by default: <pre><code>from dask.distributed import Client\n\nclient = Client()\n\nn_workers = len(client.cluster.workers)\nmem_worker0 = client.cluster.workers[0].memory_manager.memory_limit / 1024**3\n\nprint(f\"{n_workers=}, {mem_worker0=:.3}GB\")\n</code></pre></p>"},{"location":"faq/#which-pipeline-parameters-should-i-use","title":"Which pipeline parameters should I use?","text":"<p>Some parameters such as the Cellpose diameter is crucial and depends highly on the resolution of your technology (pixel size). As a guide, you can start from the parameters of the config files of your specific technology, and adjust them based on your knowledge of the tissue you work on.</p> <p>Here are some parameters which are important to check: <code>diameter</code> (in pixels for cellpose), <code>min_area</code> (in pixels^2 for cellpose, in microns^2 for baysor), <code>scale</code> (in microns for baysor), <code>pixel_size</code> (for the Xenium Explorer conversion, to have the right scale during display).</p>"},{"location":"faq/#how-to-filter-genes","title":"How to filter genes?","text":"<p>By default, we remove some genes names during segmentation and aggregation (for instance, <code>\"blank\"</code> or <code>\"unassigned\"</code> gene names). To change this behavior, you can update the gene pattern under <code>sopa.settings.gene_exclude_pattern</code> (this pattern is used by <code>pandas.Series.str.match</code>).</p> <p>You can also decide not to remove some specific low quality transcripts for segmenation. To do that, create a (boolean) column called <code>\"low_quality_transcript\"</code> to your transcript dataframe. The rows whose value is <code>True</code> will not be used during segmentation. For instance, if you have Xenium data, you can filter the genes based on a QV value of 20.</p> <pre><code>df = sdata[\"transcripts\"]\ndf[\"low_quality_transcript\"] = df.qv &lt; 20\n</code></pre>"},{"location":"faq/#how-does-sopa-know-when-using-which-elements","title":"How does Sopa know when using which elements?","text":"<p>Many functions of Sopa can run without any argument. For instance, <code>sopa.aggregate(sdata)</code> works for very different technologies, such as VisiumHD, MERSCOPE, or MACSima data.</p> <p>Internally, when reading the raw data, Sopa saves some attributes inside <code>sdata.attrs</code>. These attributes are then used to know which spatial element corresponds to what. For instance, one H&amp;E image may be tagged for tissue segmentation, while the DAPI image will be tagged to be used for cellpose.</p> <p>Sopa handles this internally by default, and it is completely invisible to the user. But, to get a full control on what is done, you can always set some arguments to specify which element to be used. You can refer to the following arguments of the API: <code>image_key</code>, <code>points_key</code>, <code>shapes_key</code>, <code>bins_key</code>, and <code>table_key</code>.</p>"},{"location":"faq/#how-to-remove-cells-artifacts","title":"How to remove cells artifacts?","text":"<p>When segmenting a patch that is outside of the issue, Cellpose may \"hallucinate\" and generate some fake cells. To avoid that, you can run <code>sopa.segmentation.tissue</code> to ensure segmentation is always run inside the tissue.</p> <p>Otherwise, if you have inside the tissue some small cells artefacts, <code>Sopa</code> offers three filtering approaches:</p> <ul> <li>Using a min_area threshold to remove small cells (provide this argument to the segmentation methods).</li> <li>A min_transcripts threshold to remove cells with a low transcript count (provide this argument to the aggregation step).</li> <li>A min_intensity_ratio value to remove cells with a low fluorescence intensity (provide this argument to the aggregation step).</li> </ul>"},{"location":"faq/#how-to-get-more-cells-with-cellpose","title":"How to get more cells with Cellpose?","text":"<ul> <li>The main Cellpose parameter to check is <code>diameter</code>, i.e. a typical cell diameter in pixels. Note that this is highly specific to the technology you're using since the micron-to-pixel ratio can differ. We advise you to start with the default parameter for your technology of interest (see the <code>diameter</code> parameter inside our config files here).</li> <li>Maybe <code>min_area</code> is too high, and all the cells are filtered because they are smaller than this area. Remind that, when using Cellpose, the areas correspond to pixels^2.</li> <li>This can be due to a low image quality. If the image is too pixelated, consider increasing <code>gaussian_sigma</code> (e.g., <code>2</code>) under the cellpose parameters of our config. If the image has a low contrast, consider increasing <code>clip_limit</code> (e.g., <code>0.3</code>). These parameters are detailed in this example config.</li> <li>Consider updating the official Cellpose parameters. In particular, try <code>cellprob_threshold=-6</code> and <code>flow_threshold=2</code>.</li> </ul>"},{"location":"faq/#how-to-use-a-custom-cellpose-model","title":"How to use a custom Cellpose model?","text":"<p>You can use any existing Cellpose model with the <code>model_type</code> argument (via the API, CLI, or Snakemake pipeline). For the Snakemake pipeline, see here how to set this argument. If you have a custom pretrained model, use the <code>pretrained_model</code> argument instead of <code>model_type</code>, and give the path to your cellpose model.</p>"},{"location":"faq/#how-to-use-the-gpu-for-cellpose","title":"How to use the GPU for Cellpose?","text":"<p>You can provide <code>gpu=True</code> to <code>sopa.segmentation.cellpose</code>. This is recommended for <code>cellpose&gt;=4.0.0</code>, which supports larger models and may be much faster on GPUs.</p> <p>Warning</p> <p>If you have many CPU cores and only one GPU, it may be faster to run in parallel on CPUs rather than sequentially using the GPU (mostly on <code>cellpose&lt;4.0.0</code>). Also, if you are on MacOS, you may experience issues because the PyTorch MPS backend doesn't support all features yet.</p> <pre><code>import sopa\n\nsdata = sopa.io.toy_dataset()\nsopa.make_image_patches(sdata)\n\nsopa.segmentation.cellpose(sdata, channels=\"DAPI\", diameter=30, cellpose_model_kwargs={\"gpu\": True})\n</code></pre>"},{"location":"faq/#how-to-provide-other-arguments-to-cellpose","title":"How to provide other arguments to Cellpose?","text":"<p>When using the Snakemake pipeline, you can use <code>method_kwargs</code> to provide extra arguments to Cellpose. For instance, we use <code>resample=False</code> in the example below, which may significantly speed up the segmentation while not decreasing significantly the segmentation quality:</p> <pre><code>segmentation:\n  cellpose:\n    diameter: 60\n    channels: [\"DAPI\"]\n    flow_threshold: 2\n    cellprob_threshold: -6\n    min_area: 2000\n    method_kwargs:\n      resample: False\n</code></pre>"},{"location":"faq/#how-to-use-a-prior-cell-segmentation","title":"How to use a prior cell segmentation?","text":"<p>If you have MERSCOPE or Xenium data, you probably already have a cell segmentation. This can be used as a prior for Proseg or Baysor, instead of running Cellpose with Sopa. For that, you have an existing config file for the Snakemake pipeline for both MERSCOPE and Xenium data. If using the API/CLI, consider using the <code>prior_shapes_key</code> and the <code>unassigned_value</code> arguments when creating the patches for the transcripts. For MERSCOPE data, <code>prior_shapes_key=\"cell_id\"</code> and <code>unassigned_value=-1</code>. For Xenium data, <code>prior_shapes_key=\"cell_id\"</code> and <code>unassigned_value=\"UNASSIGNED\"</code>. You can also decide to run Cellpose via Sopa, and then use it as a prior: in that case, simply pass <code>prior_shapes_key=\"cellpose_boundaries\"</code> after running cellpose.</p>"},{"location":"faq/#how-to-optimize-the-segmentation-parameters","title":"How to optimize the segmentation parameters?","text":"<p>Selecting the right parameters for Cellpose/Baysor can significantly improve the output data quality. To choose these parameters, we recommend subsetting the data (<code>spatialdata.bounding_box_query</code>), saving the subset (<code>sdata.write(\"subset.zarr\")</code>), running different segmentation on the subset (use <code>key_added</code> to save the segmentation with a specific name), and compare the results. Refer to this tutorial for an example.</p>"},{"location":"faq/#how-to-provide-dictionnaries-to-cli-arguments","title":"How to provide dictionnaries to CLI arguments?","text":"<p>Some CLI arguments are optionnal dictionnaries. For instance, <code>sopa convert</code> has a <code>--kwargs</code> option. In that case, a dictionnary can be provided as an inline string, for instance:</p> <p><code>--kwargs \"{'backend': 'rioxarray'}\"</code></p>"},{"location":"faq/#how-to-fix-an-out-of-memory-issue-on-merscope-data","title":"How to fix an \"out-of-memory\" issue on MERSCOPE data?","text":"<p>If using MERSCOPE data, images can be huge. To improve RAM efficiency, you can install <code>rioxarray</code> (<code>pip install rioxarray</code>). Then, the <code>rioxarray</code> will be used by default by the reader (no change needed, it will be detected automatically).</p>"},{"location":"faq/#how-to-remove-the-logs","title":"How to remove the logs?","text":"<p>You can change the level of <code>logging</code> for sopa, e.g. you can run the lines below to set the logging level to show only errors:</p> <pre><code>import sopa\n\nsopa.log.setLevel(sopa.logging.ERROR)\n</code></pre>"},{"location":"faq/#how-to-ask-for-help","title":"How to ask for help?","text":"<p>If you have an issue that is not detailed in this FAQ, you can still open an issue on Sopa's Github repository, and detail your issue with as much precision as possible for the maintainers to be able to reproduce it.</p> <p>Make sure to have a quick look to the existing issues, maybe someone faced the same problem.</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installing-sopa","title":"Installing Sopa","text":"<p>Sopa can be installed from <code>PyPI</code> on all OS, for any Python version from <code>3.10</code> to <code>3.13</code> (included).</p> <p>Advice (optional)</p> <p>We advise creating a new environment via a package manager (except if you use Poetry, which will automatically create the environment).</p> <p>For instance, you can create a new <code>conda</code> environment:</p> <pre><code>conda create --name sopa python=3.12\nconda activate sopa\n</code></pre> <p>Choose one of the following, depending on your needs:</p> From PyPIEditable modeuv (dev mode) <pre><code>pip install sopa\n</code></pre> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\n# no extra\npip install  -e .\n\n# or, to install extras, among cellpose/baysor/stardist/wsi:\npip install -e '.[cellpose,baysor]'\n</code></pre> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\nuv sync --all-extras --dev\n</code></pre> <p>Extra dependencies</p> <p>Dependending on the segmentation tool that you use, you'll need extras, as detailed in the next section.</p>"},{"location":"getting_started/#extra-dependencies","title":"Extra dependencies","text":"<p>By default, <code>sopa</code> only install the minimal dependencies to avoid a heavy installation. Depending on your usage, you can install some extras. The available extras are listed below.</p> CellposeProsegBaysorStardistComsegWSI <p>If you need to run Cellpose, you can use the corresponding extra:</p> <pre><code>pip install 'sopa[cellpose]'\n\n# you can also combine extras: pip install 'sopa[cellpose,baysor,wsi,stardist]'\n</code></pre> <p>Proseg has to be installed independently, this can be done with <code>cargo</code>:</p> <pre><code>cargo install proseg\n</code></pre> <p>Executable path</p> <p>If the <code>proseg</code> executable is not at <code>~/.cargo/bin/proseg</code>, please make the <code>proseg</code> command available (e.g., via creating a symlink <code>~/.local/bin/proseg</code> pointing to the executable), or export the path to the executable via <code>export proseg=/path/to/proseg/executable</code>.</p> <p>To use Baysor, you'll first need to install Sopa with the <code>baysor</code> extra:</p> <pre><code>pip install 'sopa[baysor]'\n</code></pre> <p>Important: then, you also have to install the <code>baysor</code> command line as detailed in the official documentation.</p> <p>Executable path</p> <p>If the Baysor executable is not at <code>~/.julia/bin/baysor</code>, please make the <code>baysor</code> command available (e.g., via creating a symlink <code>~/.local/bin/baysor</code> pointing to the executable), or export the path to the executable via <code>export baysor=/path/to/baysor/executable</code>.</p> <p>If you need to run Stardist, you can install the corresponding extra:</p> <pre><code>pip install 'sopa[stardist]'\n</code></pre> <p>If you need to run Comseg, you can install it via pip:</p> <pre><code>pip install comseg\n</code></pre> <p>If you need to work on whole slide images / H&amp;E images, you can install the corresponding extras as below. You can also consider the <code>stardist</code> extra, if you want to run cell segmentation on the H&amp;E image.</p> <pre><code>pip install 'sopa[wsi]'\n</code></pre>"},{"location":"getting_started/#snakemake-setup","title":"Snakemake setup","text":"<p>If you plan to use Snakemake, in addition to the above <code>sopa</code> environment, you'll need to clone the <code>sopa</code> repository containing the Snakemake workflow:</p> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa   # move inside the sopa repository\n</code></pre> <p>Also, make sure you have installed <code>snakemake&gt;=8.0.0</code>. This does not necessarily have to be inside the <code>sopa</code> environment \u2014 for instance, you can create a new environment specific to snakemake:</p> <pre><code># this will create a new environment called \"snakemake\"\nconda create -c conda-forge -c bioconda -n snakemake snakemake\nconda activate snakemake\n</code></pre> <p>Now, follow our snakemake tutorial to run your first pipeline.</p>"},{"location":"getting_started/#usage","title":"Usage","text":"<p>Sopa comes in four different flavours, each corresponding to a different use case:</p> <ul> <li><code>API</code>: use directly <code>sopa</code> as a Python package for full flexibility and customization (see a tutorial here).</li> <li><code>Snakemake pipeline</code>: choose a config, and run our pipeline on your spatial data in a few minutes. See our snakemake tutorial.</li> <li><code>nf-core/sopa</code>: run Sopa with Nextflow (see this repo and the corresponding usage guide). Great for Docker users.</li> <li><code>CLI</code>: use our command-line-interface to prototype quickly your own pipeline (advanced users).</li> </ul>"},{"location":"api/aggregation/","title":"Aggregation","text":"<p>Recommendation</p> <p>We recommend using the <code>sopa.aggregate</code> function below, which is a wrapper for all types of aggregation. Internally, it uses <code>aggregate_channels</code>, <code>count_transcripts</code>, and/or <code>aggregate_bins</code>, which are also documented below if needed.</p>"},{"location":"api/aggregation/#sopa.aggregate","title":"<code>sopa.aggregate(sdata, aggregate_genes=None, aggregate_channels=True, image_key=None, points_key=None, gene_column=None, shapes_key=None, bins_key=None, expand_radius_ratio=None, min_transcripts=0, min_intensity_ratio=0.1, no_overlap=False, key_added='table')</code>","text":"<p>Aggregate gene counts and/or channel intensities over a <code>SpatialData</code> object to create an <code>AnnData</code> table (saved in <code>sdata[\"table\"]</code>).</p> <p>Info</p> <p>The main arguments are <code>sdata</code>, <code>aggregate_genes</code>, and <code>aggregate_channels</code>. The rest of the arguments are optional and will be inferred from the data if not provided.</p> <ul> <li>If channels are aggregated and not genes, then <code>sdata['table'].X</code> will contain the mean channel intensities per cell.</li> <li>If genes are aggregated and not channels, then <code>sdata['table'].X</code> will contain the gene counts per cell.</li> <li>If both genes and channels are aggregated, then <code>sdata['table'].X</code> will contain the gene counts per cell and <code>sdata['table'].obsm['intensities']</code> will contain the mean channel intensities per cell.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>aggregate_genes</code> <code>bool | None</code> <p>Whether to aggregate gene counts. If None, it will be inferred from the data.</p> <code>None</code> <code>aggregate_channels</code> <code>bool</code> <p>Whether to aggregate channel intensities inside cells.</p> <code>True</code> <code>image_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the image channels to be averaged. By default, uses the segmentation image.</p> <code>None</code> <code>points_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the points dataframe representing the transcripts. Inferred by default.</p> <code>None</code> <code>gene_column</code> <code>str | None</code> <p>Key of <code>sdata[points_key]</code> with the gene names. Inferred by default.</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the shapes corresponding to the cells boundaries. Inferred by default.</p> <code>None</code> <code>bins_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the table corresponding to the bin-by-gene table of gene counts (e.g., for Visium HD data). Inferred by default.</p> <code>None</code> <code>expand_radius_ratio</code> <code>float | None</code> <p>Ratio to expand the cells polygons for channels averaging. For instance, a ratio of 0.5 expands the shape radius by 50%. If <code>None</code> (default), use 1 if we aggregate bins data, and 0 otherwise.</p> <code>None</code> <code>min_transcripts</code> <code>int</code> <p>Min number of transcripts to keep a cell.</p> <code>0</code> <code>min_intensity_ratio</code> <code>float</code> <p>Min ratio of the 90th quantile of the mean channel intensity to keep a cell.</p> <code>0.1</code> <code>no_overlap</code> <code>bool</code> <p>Experimental feature: If <code>True</code>, the (expanded) cells will not overlap for channels and bins aggregation.</p> <code>False</code> <code>key_added</code> <code>str | None</code> <p>Key to save the table in <code>sdata.tables</code>. If <code>None</code>, it will be <code>f\"{shapes_key}_table\"</code>.</p> <code>'table'</code> Source code in <code>sopa/aggregation/aggregation.py</code> <pre><code>def aggregate(\n    sdata: SpatialData,\n    aggregate_genes: bool | None = None,\n    aggregate_channels: bool = True,\n    image_key: str | None = None,\n    points_key: str | None = None,\n    gene_column: str | None = None,\n    shapes_key: str | None = None,\n    bins_key: str | None = None,\n    expand_radius_ratio: float | None = None,\n    min_transcripts: int = 0,\n    min_intensity_ratio: float = 0.1,\n    no_overlap: bool = False,\n    key_added: str | None = \"table\",\n):\n    \"\"\"Aggregate gene counts and/or channel intensities over a `SpatialData` object to create an `AnnData` table (saved in `sdata[\"table\"]`).\n\n    !!! info\n        The main arguments are `sdata`, `aggregate_genes`, and `aggregate_channels`. The rest of the arguments are optional and will be inferred from the data if not provided.\n\n        - If channels are aggregated and not genes, then `sdata['table'].X` will contain the mean channel intensities per cell.\n        - If genes are aggregated and not channels, then `sdata['table'].X` will contain the gene counts per cell.\n        - If both genes and channels are aggregated, then `sdata['table'].X` will contain the gene counts per cell and `sdata['table'].obsm['intensities']` will contain the mean channel intensities per cell.\n\n    Args:\n        sdata: A `SpatialData` object\n        aggregate_genes: Whether to aggregate gene counts. If None, it will be inferred from the data.\n        aggregate_channels: Whether to aggregate channel intensities inside cells.\n        image_key: Key of `sdata` with the image channels to be averaged. By default, uses the segmentation image.\n        points_key: Key of `sdata` with the points dataframe representing the transcripts. Inferred by default.\n        gene_column: Key of `sdata[points_key]` with the gene names. Inferred by default.\n        shapes_key: Key of `sdata` with the shapes corresponding to the cells boundaries. Inferred by default.\n        bins_key: Key of `sdata` with the table corresponding to the bin-by-gene table of gene counts (e.g., for Visium HD data). Inferred by default.\n        expand_radius_ratio: Ratio to expand the cells polygons for channels averaging. For instance, a ratio of 0.5 expands the shape radius by 50%. If `None` (default), use 1 if we aggregate bins data, and 0 otherwise.\n        min_transcripts: Min number of transcripts to keep a cell.\n        min_intensity_ratio: Min ratio of the 90th quantile of the mean channel intensity to keep a cell.\n        no_overlap: *Experimental feature*: If `True`, the (expanded) cells will not overlap for channels and bins aggregation.\n        key_added: Key to save the table in `sdata.tables`. If `None`, it will be `f\"{shapes_key}_table\"`.\n    \"\"\"\n    assert points_key is None or bins_key is None, \"Provide either `points_key` or `bins_key`, not both.\"\n\n    if points_key is None:\n        bins_key = bins_key or sdata.attrs.get(SopaAttrs.BINS_TABLE)\n\n    if (bins_key is None) and (aggregate_genes or (aggregate_genes is None and sdata.points)):\n        assert sdata.points, (\n            \"No points in the SpatialData object. You must have points, or set the `bins_key` argument (for VisiumHD-like data).\"\n        )\n\n        points_key, _ = get_spatial_element(\n            sdata.points, key=points_key or sdata.attrs.get(SopaAttrs.TRANSCRIPTS), return_key=True\n        )\n\n    aggr = Aggregator(sdata, image_key=image_key, shapes_key=shapes_key, bins_key=bins_key, points_key=points_key)\n\n    if key_added is None:\n        key_added = f\"{aggr.shapes_key}_{SopaKeys.TABLE}\"\n        log.info(f\"key_added is None, saving the table as '{key_added}' by default.\")\n\n    aggr.compute_table(\n        aggregate_genes=aggregate_genes,\n        aggregate_channels=aggregate_channels,\n        expand_radius_ratio=expand_radius_ratio,\n        min_transcripts=min_transcripts,\n        min_intensity_ratio=min_intensity_ratio,\n        gene_column=gene_column,\n        no_overlap=no_overlap,\n        key_added=key_added,\n    )\n</code></pre>"},{"location":"api/aggregation/#sopa.aggregation.aggregate_channels","title":"<code>sopa.aggregation.aggregate_channels(sdata, image_key=None, shapes_key=None, expand_radius_ratio=0, mode='average', no_overlap=False)</code>","text":"<p>Aggregate the channel intensities per cell (either <code>\"average\"</code>, or take the <code>\"min\"</code> / <code>\"max\"</code>).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>image_key</code> <code>str | None</code> <p>Key of <code>sdata</code> containing the image. If only one <code>images</code> element, this does not have to be provided.</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Key of <code>sdata</code> containing the cell boundaries. If only one <code>shapes</code> element, this does not have to be provided.</p> <code>None</code> <code>expand_radius_ratio</code> <code>float</code> <p>Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code>. This help better aggregate boundary stainings.</p> <code>0</code> <code>mode</code> <code>str</code> <p>Aggregation mode. One of <code>\"average\"</code>, <code>\"min\"</code>, <code>\"max\"</code>. By default, average the intensity inside the cell mask.</p> <code>'average'</code> <code>no_overlap</code> <code>bool</code> <p>If <code>True</code>, the (expanded) cells will not overlap.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy <code>ndarray</code> of shape <code>(n_cells, n_channels)</code></p> Source code in <code>sopa/aggregation/channels.py</code> <pre><code>def aggregate_channels(\n    sdata: SpatialData,\n    image_key: str | None = None,\n    shapes_key: str | None = None,\n    expand_radius_ratio: float = 0,\n    mode: str = \"average\",\n    no_overlap: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Aggregate the channel intensities per cell (either `\"average\"`, or take the `\"min\"` / `\"max\"`).\n\n    Args:\n        sdata: A `SpatialData` object\n        image_key: Key of `sdata` containing the image. If only one `images` element, this does not have to be provided.\n        shapes_key: Key of `sdata` containing the cell boundaries. If only one `shapes` element, this does not have to be provided.\n        expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius`. This help better aggregate boundary stainings.\n        mode: Aggregation mode. One of `\"average\"`, `\"min\"`, `\"max\"`. By default, average the intensity inside the cell mask.\n        no_overlap: If `True`, the (expanded) cells will not overlap.\n\n    Returns:\n        A numpy `ndarray` of shape `(n_cells, n_channels)`\n    \"\"\"\n    assert mode in AVAILABLE_MODES, f\"Invalid {mode=}. Available modes are {AVAILABLE_MODES}\"\n\n    image = get_spatial_image(sdata, image_key)\n\n    geo_df = get_boundaries(sdata, key=shapes_key)\n    geo_df = to_intrinsic(sdata, geo_df, image)\n    geo_df = expand_radius(geo_df, expand_radius_ratio, no_overlap=no_overlap)\n\n    return _aggregate_channels_aligned(image, geo_df, mode)\n</code></pre>"},{"location":"api/aggregation/#sopa.aggregation.count_transcripts","title":"<code>sopa.aggregation.count_transcripts(sdata, gene_column=None, shapes_key=None, points_key=None, geo_df=None, only_excluded=False)</code>","text":"<p>Counts transcripts per cell.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>gene_column</code> <code>str | None</code> <p>Column of the transcript dataframe containing the gene names</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Key of <code>sdata</code> containing the cell boundaries. If only one <code>shapes</code> element, this does not have to be provided.</p> <code>None</code> <code>points_key</code> <code>str | None</code> <p>Key of <code>sdata</code> containing the transcripts. If only one <code>points</code> element, this does not have to be provided.</p> <code>None</code> <code>geo_df</code> <code>GeoDataFrame | None</code> <p>If the cell boundaries are not yet in <code>sdata</code>, a <code>GeoDataFrame</code> can be directly provided for cell boundaries</p> <code>None</code> <code>only_excluded</code> <code>bool</code> <p>By default, the genes matching the pattern in <code>sopa.settings.gene_exclude_pattern</code> are excluded from the count. If <code>only_excluded=True</code>, it counts only these excluded genes.</p> <code>False</code> <p>Returns:</p> Type Description <code>AnnData</code> <p>An <code>AnnData</code> object of shape <code>(n_cells, n_genes)</code> with the counts per cell</p> Source code in <code>sopa/aggregation/transcripts.py</code> <pre><code>def count_transcripts(\n    sdata: SpatialData,\n    gene_column: str | None = None,\n    shapes_key: str | None = None,\n    points_key: str | None = None,\n    geo_df: gpd.GeoDataFrame | None = None,\n    only_excluded: bool = False,\n) -&gt; AnnData:\n    \"\"\"Counts transcripts per cell.\n\n    Args:\n        sdata: A `SpatialData` object\n        gene_column: Column of the transcript dataframe containing the gene names\n        shapes_key: Key of `sdata` containing the cell boundaries. If only one `shapes` element, this does not have to be provided.\n        points_key: Key of `sdata` containing the transcripts. If only one `points` element, this does not have to be provided.\n        geo_df: If the cell boundaries are not yet in `sdata`, a `GeoDataFrame` can be directly provided for cell boundaries\n        only_excluded: By default, the genes matching the pattern in `sopa.settings.gene_exclude_pattern` are excluded from the count. If `only_excluded=True`, it counts **only** these excluded genes.\n\n    Returns:\n        An `AnnData` object of shape `(n_cells, n_genes)` with the counts per cell\n    \"\"\"\n    points_key, points = get_spatial_element(\n        sdata.points, key=points_key or sdata.attrs.get(SopaAttrs.TRANSCRIPTS), return_key=True\n    )\n\n    if geo_df is None:\n        geo_df = get_boundaries(sdata, key=shapes_key)\n        geo_df = to_intrinsic(sdata, geo_df, points_key)\n\n    gene_column = gene_column or get_feature_key(points, raise_error=True)\n\n    log.info(f\"Aggregating transcripts over {len(geo_df)} cells\")\n    return _count_transcripts_aligned(geo_df, points, gene_column, only_excluded)\n</code></pre>"},{"location":"api/aggregation/#sopa.aggregation.aggregate_bins","title":"<code>sopa.aggregation.aggregate_bins(sdata, shapes_key, bins_key, expand_radius_ratio=0, no_overlap=False)</code>","text":"<p>Aggregate bins (for instance, from Visium HD data) into cells.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>The <code>SpatialData</code> object</p> required <code>shapes_key</code> <code>str</code> <p>Key of the shapes containing the cell boundaries</p> required <code>bins_key</code> <code>str</code> <p>Key of the table containing the bin-by-gene counts</p> required <code>expand_radius_ratio</code> <code>float</code> <p>Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code>. This help better aggregate bins from the cytoplasm.</p> <code>0</code> <code>no_overlap</code> <code>bool</code> <p>If <code>True</code>, bins belonging to multiple cells will be assigned to only one, based on transcript-profile proximity.</p> <code>False</code> <p>Returns:</p> Type Description <code>AnnData</code> <p>An <code>AnnData</code> object of shape with the cell-by-gene count matrix</p> Source code in <code>sopa/aggregation/bins.py</code> <pre><code>def aggregate_bins(\n    sdata: SpatialData,\n    shapes_key: str,\n    bins_key: str,\n    expand_radius_ratio: float = 0,\n    no_overlap: bool = False,\n) -&gt; AnnData:\n    \"\"\"Aggregate bins (for instance, from Visium HD data) into cells.\n\n    Args:\n        sdata: The `SpatialData` object\n        shapes_key: Key of the shapes containing the cell boundaries\n        bins_key: Key of the table containing the bin-by-gene counts\n        expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius`. This help better aggregate bins from the cytoplasm.\n        no_overlap: If `True`, bins belonging to multiple cells will be assigned to only one, based on transcript-profile proximity.\n\n    Returns:\n        An `AnnData` object of shape with the cell-by-gene count matrix\n    \"\"\"\n    bins_table: AnnData = sdata.tables[bins_key]\n\n    bins_shapes_key = sdata.get_annotated_regions(bins_table)\n    bins_shapes_key = bins_shapes_key[0] if isinstance(bins_shapes_key, list) else bins_shapes_key\n    bins = sdata.shapes[bins_shapes_key].loc[sdata.get_instance_key_column(bins_table).values]\n    bins = gpd.GeoDataFrame(geometry=bins.centroid.values)  # bins as points\n\n    cells = to_intrinsic(sdata, shapes_key, bins_shapes_key).reset_index(drop=True)\n    cells = expand_radius(cells, expand_radius_ratio, no_overlap=False)\n\n    bin_within_cell = gpd.sjoin(bins, cells)\n\n    indices_matrix = csr_matrix(\n        (np.full(len(bin_within_cell), 1), (bin_within_cell[\"index_right\"], bin_within_cell.index)),\n        shape=(len(cells), len(bins)),\n    )\n\n    if no_overlap:\n        log.warning(\"Unique bin assignments is currently experimental. Any feedback on GitHub is welcome.\")\n        indices_matrix = _get_unique_bins_assignments(indices_matrix, bins_table)\n\n    adata = AnnData(indices_matrix @ bins_table.X, obs=cells[[]], var=bins_table.var)\n    adata.obsm[\"spatial\"] = np.stack([cells.centroid.x, cells.centroid.y], axis=1)\n    adata.obsm[\"bins_assignments\"] = indices_matrix\n    return adata\n</code></pre>"},{"location":"api/aggregation/#sopa.overlay_segmentation","title":"<code>sopa.overlay_segmentation(sdata, shapes_key, gene_column=None, area_ratio_threshold=0.25, image_key=None, table_key=SopaKeys.TABLE)</code>","text":"<p>Overlay a segmentation on top of an existing segmentation</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>shapes_key</code> <code>str</code> <p>The key of the new shapes to be added</p> required <code>gene_column</code> <code>str | None</code> <p>Key of the points dataframe containing the genes names</p> <code>None</code> <code>area_ratio_threshold</code> <code>float</code> <p>Threshold between 0 and 1. For each original cell overlapping with a new cell, we compute the overlap-area/cell-area, if above the threshold the cell is removed.</p> <code>0.25</code> <code>image_key</code> <code>str | None</code> <p>Optional key of the original image</p> <code>None</code> <code>table_key</code> <code>str</code> <p>Key of the table to be overlayed</p> <code>TABLE</code> Source code in <code>sopa/aggregation/overlay.py</code> <pre><code>def overlay_segmentation(\n    sdata: SpatialData,\n    shapes_key: str,\n    gene_column: str | None = None,\n    area_ratio_threshold: float = 0.25,\n    image_key: str | None = None,\n    table_key: str = SopaKeys.TABLE,\n):\n    \"\"\"Overlay a segmentation on top of an existing segmentation\n\n    Args:\n        sdata: A `SpatialData` object\n        shapes_key: The key of the new shapes to be added\n        gene_column: Key of the points dataframe containing the genes names\n        area_ratio_threshold: Threshold between 0 and 1. For each original cell overlapping with a new cell, we compute the overlap-area/cell-area, if above the threshold the cell is removed.\n        image_key: Optional key of the original image\n        table_key: Key of the table to be overlayed\n    \"\"\"\n    aggregate_genes, aggregate_channels = False, False\n\n    assert table_key in sdata.tables, f\"No table with name '{table_key}' found in the SpatialData object\"\n\n    old_table: AnnData = sdata.tables[table_key]\n\n    assert SopaKeys.UNS_KEY in old_table.uns, \"It seems the table was not aggregated using `sopa.aggregate`\"\n\n    sopa_attrs = old_table.uns[SopaKeys.UNS_KEY]\n\n    aggregate_genes = sopa_attrs[SopaKeys.UNS_HAS_TRANSCRIPTS]\n    aggregate_channels = sopa_attrs[SopaKeys.UNS_HAS_INTENSITIES]\n\n    if aggregate_genes and gene_column is None:\n        points = get_spatial_element(sdata.points, key=sdata.attrs.get(SopaAttrs.TRANSCRIPTS))\n        gene_column = get_feature_key(points, raise_error=True)\n\n    aggregator = Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)\n    aggregator.sdata.tables[f\"{SopaKeys.OLD_TABLE_PREFFIX}{table_key}\"] = old_table\n    del aggregator.sdata.tables[table_key]\n\n    old_shapes_key = old_table.uns[\"spatialdata_attrs\"][\"region\"]\n    instance_key = old_table.uns[\"spatialdata_attrs\"][\"instance_key\"]\n\n    if isinstance(old_shapes_key, list):\n        assert len(old_shapes_key) == 1, \"Can't overlap segmentation on multi-region SpatialData object\"\n        old_shapes_key = old_shapes_key[0]\n\n    old_geo_df = aggregator.sdata[old_shapes_key]\n    geo_df = to_intrinsic(aggregator.sdata, aggregator.geo_df, old_geo_df)\n\n    geo_df.index.name = None\n    gdf_join = gpd.sjoin(old_geo_df, geo_df)\n    gdf_join[\"geometry_right\"] = gdf_join[\"index_right\"].map(lambda i: geo_df.geometry.iloc[i])\n    gdf_join[\"overlap_ratio\"] = gdf_join.apply(_overlap_area_ratio, axis=1)\n    gdf_join: gpd.GeoDataFrame = gdf_join[gdf_join.overlap_ratio &gt;= area_ratio_threshold]\n\n    table_crop = old_table[~np.isin(old_table.obs[instance_key], gdf_join.index)].copy()\n    table_crop.obs[SopaKeys.CELL_OVERLAY_KEY] = False\n\n    aggregator.compute_table(\n        aggregate_channels=aggregate_channels,\n        aggregate_genes=aggregate_genes,\n        gene_column=gene_column,\n        key_added=table_key,\n    )\n    aggregator.table.obs[SopaKeys.CELL_OVERLAY_KEY] = True\n\n    aggregator.table = anndata.concat(\n        [table_crop, aggregator.table],\n        uns_merge=\"first\",\n        join=\"outer\",\n    )\n\n    aggregator.shapes_key = f\"{old_shapes_key}_overlay_{aggregator.shapes_key}\"\n\n    geo_df_cropped = old_geo_df.loc[~old_geo_df.index.isin(gdf_join.index)]\n    aggregator.geo_df = pd.concat([geo_df_cropped, geo_df], join=\"outer\", axis=0)\n    aggregator.geo_df.attrs = old_geo_df.attrs\n\n    aggregator.add_standardized_table(table_key)\n</code></pre>"},{"location":"api/misc/","title":"Misc","text":""},{"location":"api/misc/#settings","title":"Settings","text":""},{"location":"api/misc/#disabling-auto-save","title":"Disabling auto-save","text":"<p>By default, if your <code>SpatialData</code> object is stored on-disk, it will also store the new elements on disk.</p> <p>You can disable this behavior as follow:</p> <pre><code>sopa.settings.auto_save_on_disk = False\n</code></pre>"},{"location":"api/misc/#parallelization-backends","title":"Parallelization backends","text":"<p>Some methods (for instance <code>sopa.segmentation.cellpose</code>) may need a parallelization backend to run fast enough.</p> <p>You can set it as below:</p> <pre><code>sopa.settings.parallelization_backend = \"dask\" # using dask\nsopa.settings.parallelization_backend = None # no backend (i.e., sequential)\n</code></pre> <p>Warning</p> <p>The <code>dask</code> backend is still experimental. You can add a comment to this issue to help us improve it.</p> <p>You can also pass some kwargs to the dask Client: <pre><code>sopa.settings.dask_client_kwargs[\"n_workers\"] = 4\n</code></pre></p> <p>Otherwise, if you don't use the API, you can also set the <code>SOPA_PARALLELIZATION_BACKEND</code> env variable, e.g.: <pre><code>export SOPA_PARALLELIZATION_BACKEND=dask\n</code></pre></p>"},{"location":"api/misc/#gene-filtering","title":"Gene filtering","text":"<p>Use <code>sopa.settings.gene_exclude_pattern</code> to filter out gene names during segmentation and aggregation. By default, we use the variable below: <pre><code>sopa.settings.gene_exclude_pattern: str | None = \"negcontrol.*|blank.*|antisense.*|unassigned.*|deprecated.*|intergenic.*\"\n</code></pre> Use <code>sopa.settings.gene_exclude_pattern = None</code> to keep all genes.</p>"},{"location":"api/misc/#shapes-operations","title":"Shapes operations","text":""},{"location":"api/misc/#sopa.shapes.expand_radius","title":"<code>sopa.shapes.expand_radius(geo_df, expand_radius_ratio, no_overlap=False, inplace=False)</code>","text":"<p>Expand the radius of the cells by a given ratio.</p> <p>Parameters:</p> Name Type Description Default <code>geo_df</code> <code>GeoDataFrame</code> <p>A GeoDataFrame containing the cells or shapes.</p> required <code>expand_radius_ratio</code> <code>float | None</code> <p>Ratio to expand the cells polygons for channels averaging. For instance, a ratio of 0.5 expands the shape radius by 50%. If <code>None</code>, doesn't expand cells.</p> required <code>no_overlap</code> <code>bool</code> <p>Experimental feature: if <code>True</code>, ensures that the expanded cells do not overlap by computing the Voronoi diagram of the centroids of the cells.</p> <code>False</code> <code>inplace</code> <code>bool</code> <p>If <code>True</code>, modifies the input GeoDataFrame in place. If <code>False</code>, returns a new GeoDataFrame.</p> <code>False</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A GeoDataFrame with the expanded cells.</p> Source code in <code>sopa/shapes/expand.py</code> <pre><code>def expand_radius(\n    geo_df: gpd.GeoDataFrame, expand_radius_ratio: float | None, no_overlap: bool = False, inplace: bool = False\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Expand the radius of the cells by a given ratio.\n\n    Args:\n        geo_df: A GeoDataFrame containing the cells or shapes.\n        expand_radius_ratio: Ratio to expand the cells polygons for channels averaging. For instance, a ratio of 0.5 expands the shape radius by 50%. If `None`, doesn't expand cells.\n        no_overlap: *Experimental feature*: if `True`, ensures that the expanded cells do not overlap by computing the Voronoi diagram of the centroids of the cells.\n        inplace: If `True`, modifies the input GeoDataFrame in place. If `False`, returns a new GeoDataFrame.\n\n    Returns:\n        A GeoDataFrame with the expanded cells.\n    \"\"\"\n    if not inplace:\n        geo_df = geo_df.copy()\n\n    if not expand_radius_ratio:\n        return geo_df\n\n    expand_radius_ = expand_radius_ratio * np.mean(np.sqrt(geo_df.area / np.pi))\n    geo_df.geometry = geo_df.buffer(expand_radius_)\n\n    if no_overlap:\n        log.warning(\n            \"Computing Voronoi polygons to ensure no overlap between shapes is still experimental. It can take 10+ minutes for 100k+ shapes.\"\n        )\n        geo_df.geometry = remove_overlap(geo_df, as_gdf=False)\n\n    return geo_df\n</code></pre>"},{"location":"api/misc/#sopa.shapes.remove_overlap","title":"<code>sopa.shapes.remove_overlap(geo_df, as_gdf=True)</code>","text":"<p>Remove overlapping areas from a GeoDataFrame by computing the Voronoi polygons of the shapes.</p> <p>Parameters:</p> Name Type Description Default <code>geo_df</code> <code>GeoDataFrame</code> <p>A GeoDataFrame containing the shapes.</p> required <code>as_gdf</code> <code>bool</code> <p>Whether to return a GeoDataFrame or a GeoSeries.</p> <code>True</code> <p>Returns:</p> Type Description <code>GeoSeries | GeoDataFrame</code> <p>A GeoSeries or GeoDataFrame with the overlapping areas removed.</p> Source code in <code>sopa/shapes/expand.py</code> <pre><code>def remove_overlap(geo_df: gpd.GeoDataFrame, as_gdf: bool = True) -&gt; gpd.GeoSeries | gpd.GeoDataFrame:\n    \"\"\"Remove overlapping areas from a GeoDataFrame by computing the Voronoi polygons of the shapes.\n\n    Args:\n        geo_df: A GeoDataFrame containing the shapes.\n        as_gdf: Whether to return a GeoDataFrame or a GeoSeries.\n\n    Returns:\n        A GeoSeries or GeoDataFrame with the overlapping areas removed.\n    \"\"\"\n    geo_df[\"_index\"] = geo_df.index  # to keep track of the index after the overlay\n\n    overlay = geo_df.overlay(geo_df, how=\"intersection\")\n    overlap = overlay[overlay[\"_index_1\"] != overlay[\"_index_2\"]].union_all()\n\n    del geo_df[\"_index\"]\n\n    if overlap.is_empty:\n        return geo_df.geometry\n\n    shapes_no_overlap = geo_df.difference(overlap).buffer(-1e-4)  # to avoid touching polygons on single points\n    _voronoi = voronoi_frames(shapes_no_overlap)\n\n    geometry = geo_df.intersection(_voronoi)\n\n    nan_locs = geometry.type.isna()\n\n    if nan_locs.any():\n        log.warning(f\"Found {nan_locs.sum()} NaN geometries after removing the overlap. Replacing with empty polygons.\")\n        geometry[nan_locs] = shapely.Polygon()\n\n    geometry = geometry.buffer(1e-4)  # to re-expand the polygons to their original size\n    geometry = geometry.map(ensure_polygon)\n\n    if not as_gdf:\n        return geometry\n\n    geo_df = geo_df.copy()\n    geo_df.geometry = geometry\n    return geo_df\n</code></pre>"},{"location":"api/misc/#sopa.shapes.vectorize","title":"<code>sopa.shapes.vectorize(mask, tolerance=None, smooth_radius_ratio=0.1)</code>","text":"<p>Convert a cells mask to multiple <code>shapely</code> geometries. Each shape is smoothen and converted to a single polygon. Inspired from VPT.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>A cell mask. Non-null values correspond to cell ids</p> required <code>tolerance</code> <code>float | None</code> <p>Tolerance parameter used by <code>shapely</code> during simplification. By default, define the tolerance automatically.</p> <code>None</code> <code>smooth_radius_ratio</code> <code>float</code> <p>Ratio of the cell radius used to smooth the cell polygon.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>GeoDataFrame of polygons representing each cell ID of the mask</p> Source code in <code>sopa/shapes/_vectorize.py</code> <pre><code>def vectorize(mask: np.ndarray, tolerance: float | None = None, smooth_radius_ratio: float = 0.1) -&gt; gpd.GeoDataFrame:\n    \"\"\"Convert a cells mask to multiple `shapely` geometries. Each shape is smoothen and converted to a single polygon. Inspired from [VPT](https://github.com/Vizgen/vizgen-postprocessing).\n\n    Args:\n        mask: A cell mask. Non-null values correspond to cell ids\n        tolerance: Tolerance parameter used by `shapely` during simplification. By default, define the tolerance automatically.\n        smooth_radius_ratio: Ratio of the cell radius used to smooth the cell polygon.\n\n    Returns:\n        GeoDataFrame of polygons representing each cell ID of the mask\n    \"\"\"\n    max_cells = mask.max()\n\n    if max_cells == 0:\n        log.warning(\"No cell was returned by the segmentation\")\n        return gpd.GeoDataFrame(geometry=[])\n\n    cells = _vectorize_mask(mask)\n\n    mean_radius = np.sqrt(cells.area / np.pi).mean()\n    smooth_radius = mean_radius * smooth_radius_ratio\n\n    tolerance = _default_tolerance(mean_radius) if tolerance is None else tolerance\n\n    cells.geometry = cells.geometry.map(lambda cell: _smoothen_cell(cell, smooth_radius, tolerance))\n    cells = cells[~cells.is_empty]\n\n    return cells\n</code></pre>"},{"location":"api/misc/#xenium-explorer","title":"Xenium Explorer","text":""},{"location":"api/misc/#sopa.io.explorer.write","title":"<code>sopa.io.explorer.write(path, sdata, table_key=SopaKeys.TABLE, image_key=None, shapes_key=None, points_key=None, gene_column=None, pixel_size=0.2125, layer=None, polygon_max_vertices=13, lazy=True, ram_threshold_gb=4, mode=None, raw_data_path=None, save_h5ad=False, run_name=None)</code>","text":"<p>Transform a SpatialData object into inputs for the Xenium Explorer - it can be downloaded for free here. After running this function, double-click on the <code>experiment.xenium</code> file to open the explorer.</p> <p>Quick explorer update</p> <p>If you have already run this function but updated/filtered your table and cells, you can simply provide <code>mode=\"-it\"</code> to prevent from writing the image and transcript files again, since they are the same.</p> Note <p>This function will create up to 7 files, depending on the <code>SpatialData</code> object and the arguments:</p> <ul> <li> <p><code>experiment.xenium</code> contains some experiment metadata. Double-click on this file to open the Xenium Explorer. This file can also be created with <code>write_metadata</code>.</p> </li> <li> <p><code>morphology.ome.tif</code> is the primary image. This file can also be created with <code>write_image</code>. Add more images with <code>align</code>.</p> </li> <li> <p><code>analysis.zarr.zip</code> contains the cells categories (or clusters), i.e. <code>adata.obs</code>. This file can also be created with <code>write_cell_categories</code>.</p> </li> <li> <p><code>cell_feature_matrix.zarr.zip</code> contains the cell-by-gene counts. This file can also be created with <code>write_gene_counts</code>.</p> </li> <li> <p><code>cells.zarr.zip</code> contains the cells polygon boundaries. This file can also be created with <code>write_polygons</code>.</p> </li> <li> <p><code>transcripts.zarr.zip</code> contains transcripts locations. This file can also be created with <code>write_transcripts</code>.</p> </li> <li> <p><code>adata.h5ad</code> is the <code>AnnData</code> object from the <code>SpatialData</code>. This is not used by the Explorer, but only saved for convenience.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the directory where files will be saved.</p> required <code>sdata</code> <code>SpatialData</code> <p>SpatialData object.</p> required <code>table_key</code> <code>str</code> <p>Name of the table containing the gene counts or intensities (key of <code>sdata.tables</code>). By default, uses <code>sdata[\"table\"]</code>.</p> <code>TABLE</code> <code>image_key</code> <code>str | None</code> <p>Name of the image of interest (key of <code>sdata.images</code>). By default, it will be inferred.</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Name of the cell shapes (key of <code>sdata.shapes</code>). By default, it will be inferred from the table.</p> <code>None</code> <code>points_key</code> <code>str | None</code> <p>Name of the transcripts (key of <code>sdata.points</code>). By default, it will be inferred.</p> <code>None</code> <code>gene_column</code> <code>str | None</code> <p>Column name of the points dataframe containing the gene names.</p> <code>None</code> <code>pixel_size</code> <code>float</code> <p>Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.</p> <code>0.2125</code> <code>layer</code> <code>str | None</code> <p>Layer of the AnnData table where the gene counts are saved. If <code>None</code>, uses <code>table.X</code>.</p> <code>None</code> <code>polygon_max_vertices</code> <code>int</code> <p>Maximum number of vertices for the cell polygons.</p> <code>13</code> <code>lazy</code> <code>bool</code> <p>If <code>True</code>, will not load the full images in memory (except if the image memory is below <code>ram_threshold_gb</code>).</p> <code>True</code> <code>ram_threshold_gb</code> <code>int | None</code> <p>Threshold (in gigabytes) from which image can be loaded in memory. If <code>None</code>, the image is never loaded in memory.</p> <code>4</code> <code>mode</code> <code>str | None</code> <p>String that indicates which files should be created. For instance, <code>\"-it\"</code> means everything except images and transcripts, while <code>\"+bocm\"</code> means only boundaries/observations/counts/metadata (each letter corresponds to one explorer file). By default, keeps everything.</p> <code>None</code> <code>save_h5ad</code> <code>bool</code> <p>Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)</p> <code>False</code> <code>run_name</code> <code>str | None</code> <p>Name of the run displayed in the Xenium Explorer. If <code>None</code>, uses the <code>image_key</code>.</p> <code>None</code> Source code in <code>sopa/io/explorer/converter.py</code> <pre><code>def write(\n    path: str,\n    sdata: SpatialData,\n    table_key: str = SopaKeys.TABLE,\n    image_key: str | None = None,\n    shapes_key: str | None = None,\n    points_key: str | None = None,\n    gene_column: str | None = None,\n    pixel_size: float = 0.2125,\n    layer: str | None = None,\n    polygon_max_vertices: int = 13,\n    lazy: bool = True,\n    ram_threshold_gb: int | None = 4,\n    mode: str | None = None,\n    raw_data_path: str | None = None,\n    save_h5ad: bool = False,\n    run_name: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Transform a SpatialData object into inputs for the Xenium Explorer - it can be [downloaded for free here](https://www.10xgenomics.com/support/software/xenium-explorer).\n    After running this function, double-click on the `experiment.xenium` file to open the explorer.\n\n    !!! note \"Quick explorer update\"\n        If you have already run this function but updated/filtered your table and cells,\n        you can simply provide `mode=\"-it\"` to prevent from writing the image and transcript files again, since they are the same.\n\n    Note:\n        This function will create up to 7 files, depending on the `SpatialData` object and the arguments:\n\n        - `experiment.xenium` contains some experiment metadata. Double-click on this file to open the Xenium Explorer. This file can also be created with [`write_metadata`](./#sopa.io.explorer.write_metadata).\n\n        - `morphology.ome.tif` is the primary image. This file can also be created with [`write_image`](./#sopa.io.explorer.write_image). Add more images with `align`.\n\n        - `analysis.zarr.zip` contains the cells categories (or clusters), i.e. `adata.obs`. This file can also be created with [`write_cell_categories`](./#sopa.io.explorer.write_cell_categories).\n\n        - `cell_feature_matrix.zarr.zip` contains the cell-by-gene counts. This file can also be created with [`write_gene_counts`](./#sopa.io.explorer.write_gene_counts).\n\n        - `cells.zarr.zip` contains the cells polygon boundaries. This file can also be created with [`write_polygons`](./#sopa.io.explorer.write_polygons).\n\n        - `transcripts.zarr.zip` contains transcripts locations. This file can also be created with [`write_transcripts`](./#sopa.io.explorer.write_transcripts).\n\n        - `adata.h5ad` is the `AnnData` object from the `SpatialData`. This is **not** used by the Explorer, but only saved for convenience.\n\n    Args:\n        path: Path to the directory where files will be saved.\n        sdata: SpatialData object.\n        table_key: Name of the table containing the gene counts or intensities (key of `sdata.tables`). By default, uses `sdata[\"table\"]`.\n        image_key: Name of the image of interest (key of `sdata.images`). By default, it will be inferred.\n        shapes_key: Name of the cell shapes (key of `sdata.shapes`). By default, it will be inferred from the table.\n        points_key: Name of the transcripts (key of `sdata.points`). By default, it will be inferred.\n        gene_column: Column name of the points dataframe containing the gene names.\n        pixel_size: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.\n        layer: Layer of the AnnData table where the gene counts are saved. If `None`, uses `table.X`.\n        polygon_max_vertices: Maximum number of vertices for the cell polygons.\n        lazy: If `True`, will not load the full images in memory (except if the image memory is below `ram_threshold_gb`).\n        ram_threshold_gb: Threshold (in gigabytes) from which image can be loaded in memory. If `None`, the image is never loaded in memory.\n        mode: String that indicates which files should be created. For instance, `\"-it\"` means everything except **i**mages and **t**ranscripts, while `\"+bocm\"` means only **b**oundaries/**o**bservations/**c**ounts/**m**etadata (each letter corresponds to one explorer file). By default, keeps everything.\n        save_h5ad: Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)\n        run_name: Name of the run displayed in the Xenium Explorer. If `None`, uses the `image_key`.\n    \"\"\"\n    path: Path = Path(path)\n    _check_explorer_directory(path)\n\n    image_key, _ = get_spatial_image(sdata, key=image_key, return_key=True)\n    preserve_ids: bool | None = None\n\n    # try using symlinks to avoid re-generating large files\n    raw_data_path = raw_data_path or sdata.attrs.get(SopaAttrs.XENIUM_OUTPUT_PATH)\n\n    ### Saving table / cell categories / gene counts\n    if table_key in sdata.tables:\n        adata: AnnData = sdata.tables[table_key]\n\n        _shapes_key = adata.uns[ATTRS_KEY][\"region\"]\n        assert shapes_key is None or _shapes_key == shapes_key, (\n            f\"Got {shapes_key=}, while the table corresponds to the shapes {_shapes_key}\"\n        )\n        shapes_key = _shapes_key[0] if isinstance(_shapes_key, list) else _shapes_key\n\n        geo_df = sdata[shapes_key]\n\n        preserve_ids = _update_preserve_ids(adata.obs_names, geo_df.index)\n\n        if _should_save(mode, \"c\"):\n            write_gene_counts(path, adata, layer=layer, preserve_ids=preserve_ids)\n        if _should_save(mode, \"o\"):\n            write_cell_categories(path, adata)\n        if save_h5ad:\n            adata.write_h5ad(path / FileNames.H5AD)\n\n    ### Saving cell boundaries\n    if not _should_save(mode, \"b\") and not _should_save(mode, \"m\"):\n        shapes_key, geo_df = None, None\n    elif shapes_key is None:\n        shapes_key, geo_df = get_boundaries(sdata, return_key=True, warn=True)\n    else:\n        geo_df = sdata[shapes_key]\n\n    if _should_save(mode, \"b\") and geo_df is not None:\n        geo_df = to_intrinsic(sdata, geo_df, image_key)\n\n        if table_key in sdata.tables:\n            geo_df = geo_df.loc[adata.obs[adata.uns[ATTRS_KEY][\"instance_key\"]]]\n\n        if preserve_ids is None:\n            preserve_ids = _update_preserve_ids(geo_df.index)\n\n        write_polygons(path, geo_df, polygon_max_vertices, pixel_size=pixel_size, preserve_ids=preserve_ids)\n\n    ### Saving transcripts\n    df = None\n    if len(sdata.points):\n        df = get_spatial_element(sdata.points, key=points_key or sdata.attrs.get(SopaAttrs.TRANSCRIPTS))\n\n    if _should_save(mode, \"t\") and not _use_symlink(path, raw_data_path, \"transcripts*\") and df is not None:\n        gene_column = gene_column or get_feature_key(df)\n        if gene_column is not None:\n            df = to_intrinsic(sdata, df, image_key)\n            write_transcripts(path, df, gene_column, pixel_size=pixel_size)\n        else:\n            log.warning(\"The argument 'gene_column' has to be provided to save the transcripts\")\n\n    ### Saving image\n    if _should_save(mode, \"i\") and not _use_symlink(path, raw_data_path, \"morphology*\"):\n        write_image(\n            path,\n            sdata[image_key],\n            lazy=lazy,\n            ram_threshold_gb=ram_threshold_gb,\n            pixel_size=pixel_size,\n        )\n\n    ### Saving experiment.xenium file\n    if _should_save(mode, \"m\"):\n        region_name = _get_region_name(sdata, shapes_key)\n        write_metadata(path, run_name or image_key, region_name, _get_n_obs(sdata, geo_df, table_key), pixel_size)\n\n    log.info(f\"Saved files in the following directory: {path}\")\n    log.info(f\"You can open the experiment with 'open {path / FileNames.METADATA}'\")\n</code></pre>"},{"location":"api/misc/#sopa.io.explorer.align","title":"<code>sopa.io.explorer.align(sdata, image, transformation_matrix_path, key_added=None, image_key=None, overwrite=False)</code>","text":"<p>Add an image to the <code>SpatialData</code> object after alignment with the Xenium Explorer.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>image</code> <code>DataArray</code> <p>A <code>DataArray</code> object. Note that <code>image.name</code> is used as the key for the aligned image.</p> required <code>transformation_matrix_path</code> <code>str</code> <p>Path to the <code>.csv</code> transformation matrix exported from the Xenium Explorer</p> required <code>key_added</code> <code>str | None</code> <p>Optional name to add to the new image. If <code>None</code>, will use <code>image.name</code>.</p> <code>None</code> <code>image_key</code> <code>str | None</code> <p>Optional name of the image on which it has been aligned. Required if multiple images in the <code>SpatialData</code> object.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the image, if already existing.</p> <code>False</code> Source code in <code>sopa/io/explorer/images.py</code> <pre><code>def align(\n    sdata: SpatialData,\n    image: DataArray,\n    transformation_matrix_path: str,\n    key_added: str | None = None,\n    image_key: str | None = None,\n    overwrite: bool = False,\n):\n    \"\"\"Add an image to the `SpatialData` object after alignment with the Xenium Explorer.\n\n    Args:\n        sdata: A `SpatialData` object\n        image: A `DataArray` object. Note that `image.name` is used as the key for the aligned image.\n        transformation_matrix_path: Path to the `.csv` transformation matrix exported from the Xenium Explorer\n        key_added: Optional name to add to the new image. If `None`, will use `image.name`.\n        image_key: Optional name of the image on which it has been aligned. Required if multiple images in the `SpatialData` object.\n        overwrite: Whether to overwrite the image, if already existing.\n    \"\"\"\n    key_added = key_added or image.name\n\n    assert key_added is not None, \"The image has no name, use the `key_added` argument to provide one\"\n    assert key_added not in sdata, f\"Image '{key_added}' already exists in the `SpatialData` object\"\n\n    to_pixel = Sequence([\n        Affine(\n            np.genfromtxt(transformation_matrix_path, delimiter=\",\"),\n            input_axes=(\"x\", \"y\"),\n            output_axes=(\"x\", \"y\"),\n        )\n    ])\n\n    default_image = get_spatial_image(sdata, image_key)\n\n    original_transformations = get_transformation(default_image, get_all=True)\n    transformations = {cs: to_pixel.compose_with(t) for cs, t in original_transformations.items()}\n\n    set_transformation(image, transformations, set_all=True)\n\n    add_spatial_element(sdata, key_added, image, overwrite=overwrite)\n    log.info(f\"Added image '{key_added}' (aligned with the Xenium Explorer)\")\n</code></pre>"},{"location":"api/misc/#sopa.io.explorer.add_explorer_selection","title":"<code>sopa.io.explorer.add_explorer_selection(sdata, path, key_added='explorer_selection', image_key=None, pixel_size=0.2125)</code>","text":"<p>After saving a selection on the Xenium Explorer, it will add all polygons inside <code>sdata.shapes[shapes_key]</code></p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>path</code> <code>str</code> <p>The path to the <code>coordinates.csv</code> selection file</p> required <code>key_added</code> <code>str</code> <p>The name to provide to the selection as shapes</p> <code>'explorer_selection'</code> <code>image_key</code> <code>str | None</code> <p>The original image name</p> <code>None</code> <code>pixel_size</code> <code>float</code> <p>Number of microns in a pixel. It must be the same value as the one used in <code>sopa.io.write</code></p> <code>0.2125</code> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def add_explorer_selection(\n    sdata: SpatialData,\n    path: str,\n    key_added: str = \"explorer_selection\",\n    image_key: str | None = None,\n    pixel_size: float = 0.2125,\n):\n    \"\"\"After saving a selection on the Xenium Explorer, it will add all polygons inside `sdata.shapes[shapes_key]`\n\n    Args:\n        sdata: A `SpatialData` object\n        path: The path to the `coordinates.csv` selection file\n        key_added: The name to provide to the selection as shapes\n        image_key: The original image name\n        pixel_size: Number of microns in a pixel. It must be the same value as the one used in `sopa.io.write`\n    \"\"\"\n    polys = xenium_explorer_selection(path, pixel_size=pixel_size, return_list=True)\n    image = get_spatial_element(sdata.images, key=image_key or sdata.attrs.get(SopaAttrs.CELL_SEGMENTATION))\n\n    geo_df = ShapesModel.parse(gpd.GeoDataFrame(geometry=polys), transformations=copy_transformations(image))\n    add_spatial_element(sdata, key_added, geo_df)\n</code></pre>"},{"location":"api/misc/#sopa.io.explorer.int_cell_id","title":"<code>sopa.io.explorer.int_cell_id(explorer_cell_id)</code>","text":"<p>Transforms an alphabetical cell id from the Xenium Explorer to an integer ID</p> <p>E.g., int_cell_id('aaaachba-1') = 10000</p> <p>Parameters:</p> Name Type Description Default <code>explorer_cell_id</code> <code>str | Index</code> <p>An alphabetical cell ID or a pandas Index of many explorer cell IDs</p> required <p>Returns:</p> Type Description <code>int | Index</code> <p>An integer or a pandas Index of integers representing cell IDs as indices</p> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def int_cell_id(explorer_cell_id: str | pd.Index) -&gt; int | pd.Index:\n    \"\"\"Transforms an alphabetical cell id from the Xenium Explorer to an integer ID\n\n    E.g., int_cell_id('aaaachba-1') = 10000\n\n    Args:\n        explorer_cell_id: An alphabetical cell ID or a pandas Index of many explorer cell IDs\n\n    Returns:\n        An integer or a pandas Index of integers representing cell IDs as indices\"\"\"\n    if isinstance(explorer_cell_id, pd.Index):\n        return explorer_cell_id.map(int_cell_id)\n\n    assert isinstance(explorer_cell_id, str), \"The cell ID must be a string or a pandas Index of strings\"\n    assert is_valid_explorer_id(explorer_cell_id), \"The cell ID must be a valid Xenium Explorer ID\"\n\n    code = explorer_cell_id[:-2] if explorer_cell_id[-2] == \"-\" else explorer_cell_id\n    coefs = [ord(c) - 97 for c in code][::-1]\n    return sum(value * 16**i for i, value in enumerate(coefs))\n</code></pre>"},{"location":"api/misc/#sopa.io.explorer.str_cell_id","title":"<code>sopa.io.explorer.str_cell_id(cell_id)</code>","text":"<p>Transforms an integer cell ID into an Xenium Explorer alphabetical cell id</p> <p>E.g., str_cell_id(10000) = 'aaaachba-1'</p> <p>Parameters:</p> Name Type Description Default <code>cell_id</code> <code>int | Index</code> <p>An integer or a pandas Index of integers representing cell indices</p> required <p>Returns:</p> Type Description <code>str | Index</code> <p>A string or a pandas Index of strings representing cell IDs in the Xenium Explorer format</p> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def str_cell_id(cell_id: int | pd.Index) -&gt; str | pd.Index:\n    \"\"\"Transforms an integer cell ID into an Xenium Explorer alphabetical cell id\n\n    E.g., str_cell_id(10000) = 'aaaachba-1'\n\n    Args:\n        cell_id: An integer or a pandas Index of integers representing cell indices\n\n    Returns:\n        A string or a pandas Index of strings representing cell IDs in the Xenium Explorer format\n    \"\"\"\n    if isinstance(cell_id, pd.Index):\n        return cell_id.map(str_cell_id)\n\n    assert isinstance(cell_id, int), \"The cell ID must be an integer or a pandas Index of integers\"\n\n    coefs = []\n    for _ in range(8):\n        cell_id, coef = divmod(cell_id, 16)\n        coefs.append(coef)\n    return \"\".join([chr(97 + coef) for coef in coefs][::-1]) + \"-1\"\n</code></pre>"},{"location":"api/misc/#sopa.io.explorer.write_image","title":"<code>sopa.io.explorer.write_image(path, image, lazy=True, tile_width=TILE_SIZE, n_subscales=5, pixel_size=0.2125, ram_threshold_gb=4, is_dir=True)</code>","text":"<p>Convert an image into a <code>morphology.ome.tif</code> file that can be read by the Xenium Explorer</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Xenium Explorer directory where the image will be written</p> required <code>image</code> <code>DataTree | DataArray | ndarray</code> <p>Image of shape <code>(C, Y, X)</code></p> required <code>lazy</code> <code>bool</code> <p>If <code>True</code>, the image will not be read in-memory (except if the image size is below <code>ram_threshold_gb</code>). If <code>False</code>, all the images levels are always loaded in-memory.</p> <code>True</code> <code>tile_width</code> <code>int</code> <p>Xenium tile width (do not update).</p> <code>TILE_SIZE</code> <code>n_subscales</code> <code>int</code> <p>Number of sub-scales in the pyramidal image.</p> <code>5</code> <code>pixel_size</code> <code>float</code> <p>Xenium pixel size (do not update).</p> <code>0.2125</code> <code>ram_threshold_gb</code> <code>int | None</code> <p>If an image (of any level of the pyramid) is below this threshold, it will be loaded in-memory.</p> <code>4</code> <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> Source code in <code>sopa/io/explorer/images.py</code> <pre><code>def write_image(\n    path: str,\n    image: DataTree | DataArray | np.ndarray,\n    lazy: bool = True,\n    tile_width: int = TILE_SIZE,\n    n_subscales: int = 5,\n    pixel_size: float = 0.2125,\n    ram_threshold_gb: int | None = 4,\n    is_dir: bool = True,\n):\n    \"\"\"Convert an image into a `morphology.ome.tif` file that can be read by the Xenium Explorer\n\n    Args:\n        path: Path to the Xenium Explorer directory where the image will be written\n        image: Image of shape `(C, Y, X)`\n        lazy: If `True`, the image will not be read in-memory (except if the image size is below `ram_threshold_gb`). If `False`, all the images levels are always loaded in-memory.\n        tile_width: Xenium tile width (do not update).\n        n_subscales: Number of sub-scales in the pyramidal image.\n        pixel_size: Xenium pixel size (do not update).\n        ram_threshold_gb: If an image (of any level of the pyramid) is below this threshold, it will be loaded in-memory.\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.IMAGE, is_dir)\n\n    if isinstance(image, np.ndarray):\n        assert len(image.shape) == 3, \"Can only write channels with shape (C,Y,X)\"\n        log.info(f\"Converting image of shape {image.shape} into a DataArray (with dims: C,Y,X)\")\n        image = DataArray(image, dims=[\"c\", \"y\", \"x\"], name=\"image\")\n\n    image = _to_xenium_explorer_multiscale(image, n_subscales)\n\n    image_writer = MultiscaleImageWriter(image, pixel_size=pixel_size, tile_width=tile_width)\n    image_writer.write(path, lazy=lazy, ram_threshold_gb=ram_threshold_gb)\n</code></pre>"},{"location":"api/misc/#sopa.io.explorer.write_cell_categories","title":"<code>sopa.io.explorer.write_cell_categories(path, adata, is_dir=True)</code>","text":"<p>Write a <code>analysis.zarr.zip</code> file containing the cell categories/clusters (i.e., from <code>adata.obs</code>)</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Xenium Explorer directory where the cell-categories file will be written</p> required <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> Source code in <code>sopa/io/explorer/table.py</code> <pre><code>def write_cell_categories(path: str, adata: AnnData, is_dir: bool = True) -&gt; None:\n    \"\"\"Write a `analysis.zarr.zip` file containing the cell categories/clusters (i.e., from `adata.obs`)\n\n    Args:\n        path: Path to the Xenium Explorer directory where the cell-categories file will be written\n        adata: An `AnnData` object\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.CELL_CATEGORIES, is_dir)\n\n    adata.strings_to_categoricals()\n    cat_columns = [name for name, cat in adata.obs.dtypes.items() if cat == \"category\"]\n\n    log.info(f\"Writing {len(cat_columns)} cell/observations categories: {', '.join(cat_columns)}\")\n\n    ATTRS = cell_categories_attrs()\n    ATTRS[\"number_groupings\"] = len(cat_columns)\n\n    with zarr.ZipStore(path, mode=\"w\") as store:\n        g = zarr.group(store=store)\n        cell_groups = g.create_group(\"cell_groups\")\n\n        for i, name in enumerate(cat_columns):\n            if adata.obs[name].isna().any():\n                NA = \"NA\"\n                log.warning(f\"Column {name} has nan values. They will be displayed as '{NA}'\")\n                adata.obs[name] = adata.obs[name].cat.add_categories(NA).fillna(NA)\n\n            categories = list(adata.obs[name].cat.categories)\n            ATTRS[\"grouping_names\"].append(name)\n            ATTRS[\"group_names\"].append(categories)\n\n            _write_categorical_column(cell_groups, i, adata.obs[name], categories)\n\n        cell_groups.attrs.put(ATTRS)\n</code></pre>"},{"location":"api/misc/#sopa.io.explorer.save_column_csv","title":"<code>sopa.io.explorer.save_column_csv(path, adata, key)</code>","text":"<p>Save one column of the AnnData object as a CSV that can be open interactively in the explorer, under the \"cell\" panel.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path where to write the CSV that will be open in the Xenium Explorer</p> required <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the column to convert</p> required Source code in <code>sopa/io/explorer/table.py</code> <pre><code>def save_column_csv(path: str, adata: AnnData, key: str):\n    \"\"\"Save one column of the AnnData object as a CSV that can be open interactively in the explorer, under the \"cell\" panel.\n\n    Args:\n        path: Path where to write the CSV that will be open in the Xenium Explorer\n        adata: An `AnnData` object\n        key: Key of `adata.obs` containing the column to convert\n    \"\"\"\n    df = pd.DataFrame({\"cell_id\": adata.obs_names, \"group\": adata.obs[key].values})\n    df.to_csv(path, index=None)\n</code></pre>"},{"location":"api/misc/#report","title":"Report","text":""},{"location":"api/misc/#sopa.io.write_report","title":"<code>sopa.io.write_report(path, sdata, table_key=SopaKeys.TABLE)</code>","text":"<p>Create a HTML report (or web report) after running Sopa.</p> Note <p>This report is automatically generated based on a custom python-to-html engine</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the <code>.html</code> report that has to be created</p> required <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object, after running Sopa</p> required <code>table_key</code> <code>str</code> <p>Key of the table in the <code>SpatialData</code> object to be used for the report</p> <code>TABLE</code> Source code in <code>sopa/io/report/generate.py</code> <pre><code>def write_report(path: str, sdata: SpatialData, table_key: str = SopaKeys.TABLE):\n    \"\"\"Create a HTML report (or web report) after running Sopa.\n\n    Note:\n        This report is automatically generated based on a custom python-to-html engine\n\n    Args:\n        path: Path to the `.html` report that has to be created\n        sdata: A `SpatialData` object, after running Sopa\n        table_key: Key of the table in the `SpatialData` object to be used for the report\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\n        sections = SectionBuilder(sdata, table_key).compute_sections()\n\n        log.info(f\"Writing report to {path}\")\n        Root(sections).write(path)\n</code></pre>"},{"location":"api/patches/","title":"Patches","text":""},{"location":"api/patches/#sopa.make_image_patches","title":"<code>sopa.make_image_patches(sdata, patch_width=2000, patch_overlap=50, image_key=None, roi_key=SopaKeys.ROI, key_added=None)</code>","text":"<p>Create overlapping patches on an image. This can be used for image-based segmentation methods such as Cellpose, which will run on each patch.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>patch_width</code> <code>int | None</code> <p>Width of the patches, in pixels. If <code>None</code>, creates only one patch.</p> <code>2000</code> <code>patch_overlap</code> <code>int</code> <p>Number of pixels of overlap between patches.</p> <code>50</code> <code>image_key</code> <code>str | None</code> <p>Optional key of the image on which the patches will be made. If not provided, it is found automatically.</p> <code>None</code> <code>roi_key</code> <code>str | None</code> <p>Optional name of the shapes that need to touch the patches. Patches that do not touch any shape will be ignored during segmentation. By default, uses <code>\"region_of_interest\"</code> if existing. If <code>None</code>, all patches will be used.</p> <code>ROI</code> <code>key_added</code> <code>str | None</code> <p>Optional name of the patches to be saved. By default, uses <code>\"image_patches\"</code>.</p> <code>None</code> Source code in <code>sopa/patches/factory.py</code> <pre><code>def make_image_patches(\n    sdata: SpatialData,\n    patch_width: int | None = 2000,\n    patch_overlap: int = 50,\n    image_key: str | None = None,\n    roi_key: str | None = SopaKeys.ROI,\n    key_added: str | None = None,\n):\n    \"\"\"Create overlapping patches on an image. This can be used for image-based segmentation methods such as Cellpose, which will run on each patch.\n\n    Args:\n        sdata: A `SpatialData` object.\n        patch_width: Width of the patches, in pixels. If `None`, creates only one patch.\n        patch_overlap: Number of pixels of overlap between patches.\n        image_key: Optional key of the image on which the patches will be made. If not provided, it is found automatically.\n        roi_key: Optional name of the shapes that need to touch the patches. Patches that do not touch any shape will be ignored during segmentation. By default, uses `\"region_of_interest\"` if existing. If `None`, all patches will be used.\n        key_added: Optional name of the patches to be saved. By default, uses `\"image_patches\"`.\n    \"\"\"\n    image_key, _ = get_spatial_image(sdata, key=image_key, return_key=True)\n\n    patches = Patches2D(\n        sdata,\n        image_key,\n        patch_width=patch_width,\n        patch_overlap=patch_overlap,\n        roi_key=roi_key,\n    )\n\n    patches.add_shapes(key_added=key_added)\n</code></pre>"},{"location":"api/patches/#sopa.make_transcript_patches","title":"<code>sopa.make_transcript_patches(sdata, patch_width=2000, patch_overlap=50, points_key=None, prior_shapes_key=None, unassigned_value=None, min_points_per_patch=4000, write_cells_centroids=False, roi_key=SopaKeys.ROI, key_added=None, **kwargs)</code>","text":"<p>Create overlapping patches on a transcripts dataframe, and save it in a cache. This can be used for trancript-based segmentation methods such as Baysor or Proseg.</p> <p>Prior segmentation usage</p> <p>To save assign a prior segmentation to each transcript, you can use the <code>prior_shapes_key</code> argument:</p> <ul> <li>If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use <code>prior_shapes_key=\"auto\"</code> to use it (or, provide manually the column name and the <code>unassigned_value</code> argument).</li> <li>If you have already run segmentation with Sopa, use <code>prior_shapes_key</code> to denote the name of the shapes (GeoDataFrame) containing the boundaries, e.g. <code>prior_shapes_key=\"cellpose_boundaries\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>patch_width</code> <code>float | int | None</code> <p>Width of the patches, in microns. If <code>None</code>, creates only one patch.</p> <code>2000</code> <code>patch_overlap</code> <code>int</code> <p>Number of microns of overlap between patches.</p> <code>50</code> <code>points_key</code> <code>str | None</code> <p>Optional key of the points on which the patches will be made. If not provided, it is found automatically.</p> <code>None</code> <code>prior_shapes_key</code> <code>Literal['auto'] | str | None</code> <p>Optional key of <code>sdata</code> containing the shapes with the prior segmentation, or column of the points dataframe. If <code>\"auto\"</code>, use the prior column from the technology.</p> <code>None</code> <code>unassigned_value</code> <code>int | str | None</code> <p>If <code>prior_shapes_key</code> has been provided and corresponds to a points column: this argument is the value given to the transcript that are not inside any cell.</p> <code>None</code> <code>min_points_per_patch</code> <code>int</code> <p>Minimum number of points/transcripts for a patch to be considered for segmentation.</p> <code>4000</code> <code>write_cells_centroids</code> <code>bool</code> <p>If <code>True</code>, the centroids of the prior cells will be saved. This is useful for some segmentation tools such as ComSeg.</p> <code>False</code> <code>roi_key</code> <code>str | None</code> <p>Optional name of the shapes that need to touch the patches. Patches that do not touch any shape will be ignored during segmentation. By default, uses <code>\"region_of_interest\"</code> if existing. If <code>None</code>, all patches will be used.</p> <code>ROI</code> <code>key_added</code> <code>str | None</code> <p>Optional name of the patches to be saved. By default, uses <code>\"transcripts_patches\"</code>.</p> <code>None</code> <code>**kwargs</code> <code>int</code> <p>Additional arguments passed to the <code>OnDiskTranscriptPatches</code> class.</p> <code>{}</code> Source code in <code>sopa/patches/factory.py</code> <pre><code>def make_transcript_patches(\n    sdata: SpatialData,\n    patch_width: float | int | None = 2000,\n    patch_overlap: int = 50,\n    points_key: str | None = None,\n    prior_shapes_key: Literal[\"auto\"] | str | None = None,\n    unassigned_value: int | str | None = None,\n    min_points_per_patch: int = 4000,\n    write_cells_centroids: bool = False,\n    roi_key: str | None = SopaKeys.ROI,\n    key_added: str | None = None,\n    **kwargs: int,\n):\n    \"\"\"Create overlapping patches on a transcripts dataframe, and save it in a cache. This can be used for trancript-based segmentation methods such as Baysor or Proseg.\n\n    !!! info \"Prior segmentation usage\"\n        To save assign a prior segmentation to each transcript, you can use the `prior_shapes_key` argument:\n\n        - If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use `prior_shapes_key=\"auto\"` to use it (or, provide manually the column name and the `unassigned_value` argument).\n        - If you have already run segmentation with Sopa, use `prior_shapes_key` to denote the name of the shapes (GeoDataFrame) containing the boundaries, e.g. `prior_shapes_key=\"cellpose_boundaries\"`.\n\n    Args:\n        sdata: A `SpatialData` object.\n        patch_width: Width of the patches, in microns. If `None`, creates only one patch.\n        patch_overlap: Number of microns of overlap between patches.\n        points_key: Optional key of the points on which the patches will be made. If not provided, it is found automatically.\n        prior_shapes_key: Optional key of `sdata` containing the shapes with the prior segmentation, or column of the points dataframe. If `\"auto\"`, use the prior column from the technology.\n        unassigned_value: If `prior_shapes_key` has been provided and corresponds to a points column: this argument is the value given to the transcript that are not inside any cell.\n        min_points_per_patch: Minimum number of points/transcripts for a patch to be considered for segmentation.\n        write_cells_centroids: If `True`, the centroids of the prior cells will be saved. This is useful for some segmentation tools such as ComSeg.\n        roi_key: Optional name of the shapes that need to touch the patches. Patches that do not touch any shape will be ignored during segmentation. By default, uses `\"region_of_interest\"` if existing. If `None`, all patches will be used.\n        key_added: Optional name of the patches to be saved. By default, uses `\"transcripts_patches\"`.\n        **kwargs: Additional arguments passed to the `OnDiskTranscriptPatches` class.\n    \"\"\"\n    assert not write_cells_centroids or prior_shapes_key, \"write_cells_centroids argument requires prior_shapes_key\"\n\n    points_key, _ = get_spatial_element(\n        sdata.points,\n        key=points_key or sdata.attrs.get(SopaAttrs.TRANSCRIPTS),\n        return_key=True,\n    )\n\n    if prior_shapes_key == \"auto\":\n        assert SopaAttrs.PRIOR_TUPLE_KEY in sdata.attrs, (\n            f\"prior_shapes_key='auto' requires a prior segmentation to be present in the points dataframe ('{SopaAttrs.PRIOR_TUPLE_KEY}' must be in `sdata.attrs`).\"\n        )\n        prior_shapes_key, unassigned_value = sdata.attrs[SopaAttrs.PRIOR_TUPLE_KEY]\n\n    patches = OnDiskTranscriptPatches(\n        sdata,\n        points_key,\n        patch_width=patch_width,\n        patch_overlap=patch_overlap,\n        prior_shapes_key=prior_shapes_key,\n        unassigned_value=unassigned_value,\n        min_points_per_patch=min_points_per_patch,\n        write_cells_centroids=write_cells_centroids,\n        roi_key=roi_key,\n        **kwargs,\n    )\n\n    patches.write()\n    patches.add_shapes(key_added=key_added)\n</code></pre>"},{"location":"api/patches/#sopa.patches.compute_embeddings","title":"<code>sopa.patches.compute_embeddings(sdata, model, patch_width, patch_overlap=0, level=0, magnification=None, image_key=None, batch_size=32, device=None, data_parallel=False, roi_key=SopaKeys.ROI, key_added=None, **kwargs)</code>","text":"<p>It creates patches, runs a computer vision model on each patch, and store the embeddings of each all patches as an <code>AnnData</code> object. This is mostly useful for WSI images.</p> <p>Info</p> <p>The <code>AnnData</code> object will be saved into the <code>SpatialData</code> object with the key <code>\"{model_name}_embeddings\"</code> (see the <code>model_name</code> argument below), except if <code>key_added</code> is provided. The shapes of the patches will be saved with the key <code>\"embeddings_patches\"</code>.</p> <p>Warning</p> <p>In addition to the WSI extra (<code>pip install 'sopa[wsi]'</code>) and depending on the model used, you might need to install additional dependencies. Also, CONCH requires to be logged in Hugging Face and having approved their License.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>model</code> <code>Callable | str</code> <p>A supported model name (<code>resnet50</code>, <code>histo_ssl</code>, <code>dinov2</code>, <code>hoptimus0</code>, or <code>conch</code>), or a callable that takes as an input a tensor of size <code>(batch_size, channels, x, y)</code> and returns a vector for each tile <code>(batch_size, emb_dim)</code>.</p> required <code>patch_width</code> <code>int</code> <p>Width of the patches in pixels.</p> required <code>patch_overlap</code> <code>int</code> <p>Width of the overlap between the patches in pixels.</p> <code>0</code> <code>level</code> <code>int | None</code> <p>Image level on which the processing is performed. Either <code>level</code> or <code>magnification</code> should be provided.</p> <code>0</code> <code>magnification</code> <code>int | None</code> <p>The target magnification on which the processing is performed. If <code>magnification</code> is provided, the <code>level</code> argument will be automatically computed.</p> <code>None</code> <code>image_key</code> <code>str | None</code> <p>Optional image key of the image. By default, uses the only image (if only one) or the image used for cell or tissue segmentation.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Mini-batch size used during inference.</p> <code>32</code> <code>device</code> <code>str | None</code> <p>Device used for the computer vision model.</p> <code>None</code> <code>data_parallel</code> <code>bool | list[int]</code> <p>If <code>True</code>, the model will be run in data parallel mode. If a list of GPUs is provided, the model will be run in data parallel mode on the specified GPUs.</p> <code>False</code> <code>roi_key</code> <code>str | None</code> <p>Optional name of the shapes that needs to touch the patches. Patches that do not touch any shape will be ignored. If <code>None</code>, all patches will be used. By default, uses the tissue segmentation if available.</p> <code>ROI</code> <code>key_added</code> <code>str | None</code> <p>Optional name of the spatial element that will be added (storing the embeddings).</p> <code>None</code> <code>**kwargs</code> <code>int</code> <p>Additional keyword arguments passed to the <code>Patches2D</code> constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The name of the <code>AnnData</code> table that was added to the <code>SpatialData</code> object.</p> Source code in <code>sopa/patches/infer.py</code> <pre><code>def compute_embeddings(\n    sdata: SpatialData,\n    model: Callable | str,\n    patch_width: int,\n    patch_overlap: int = 0,\n    level: int | None = 0,\n    magnification: int | None = None,\n    image_key: str | None = None,\n    batch_size: int = 32,\n    device: str | None = None,\n    data_parallel: bool | list[int] = False,\n    roi_key: str | None = SopaKeys.ROI,\n    key_added: str | None = None,\n    **kwargs: int,\n) -&gt; str:\n    \"\"\"It creates patches, runs a computer vision model on each patch, and store the embeddings of each all patches as an [`AnnData` object](https://anndata.readthedocs.io/en/stable/). This is mostly useful for WSI images.\n\n    !!! info\n        The `AnnData` object will be saved into the `SpatialData` object with the key `\"{model_name}_embeddings\"` (see the `model_name` argument below), except if `key_added` is provided.\n        The shapes of the patches will be saved with the key `\"embeddings_patches\"`.\n\n    !!! warning\n        In addition to the WSI extra (`pip install 'sopa[wsi]'`) and depending on the model used, you might need to install additional dependencies. Also, CONCH requires to be logged in Hugging Face and having approved their License.\n\n    Args:\n        sdata: A `SpatialData` object\n        model: A supported model name (`resnet50`, `histo_ssl`, `dinov2`, `hoptimus0`, or `conch`), or a callable that takes as an input a tensor of size `(batch_size, channels, x, y)` and returns a vector for each tile `(batch_size, emb_dim)`.\n        patch_width: Width of the patches in pixels.\n        patch_overlap: Width of the overlap between the patches in pixels.\n        level: Image level on which the processing is performed. Either `level` or `magnification` should be provided.\n        magnification: The target magnification on which the processing is performed. If `magnification` is provided, the `level` argument will be automatically computed.\n        image_key: Optional image key of the image. By default, uses the only image (if only one) or the image used for cell or tissue segmentation.\n        batch_size: Mini-batch size used during inference.\n        device: Device used for the computer vision model.\n        data_parallel: If `True`, the model will be run in data parallel mode. If a list of GPUs is provided, the model will be run in data parallel mode on the specified GPUs.\n        roi_key: Optional name of the shapes that needs to touch the patches. Patches that do not touch any shape will be ignored. If `None`, all patches will be used. By default, uses the tissue segmentation if available.\n        key_added: Optional name of the spatial element that will be added (storing the embeddings).\n        **kwargs: Additional keyword arguments passed to the `Patches2D` constructor.\n\n    Returns:\n        The name of the `AnnData` table that was added to the `SpatialData` object.\n    \"\"\"\n    try:\n        import torch\n    except ImportError:\n        raise ImportError(\n            \"For patch embedding, you need `torch` (and perhaps `torchvision`). Consider installing the sopa WSI extra: `pip install 'sopa[wsi]'`.\"\n        )\n    from . import models\n\n    if isinstance(model, str):\n        assert model in models.available_models, (\n            f\"'{model}' is not a valid model name. Valid names are: {', '.join(list(models.available_models.keys()))}\"\n        )\n        model_name, model = model, models.available_models[model]()\n    else:\n        model_name = model.__class__.__name__\n\n    if device is not None:\n        model.to(device)\n\n    if data_parallel:\n        ids = data_parallel if isinstance(data_parallel, list) else list(range(torch.cuda.device_count()))\n        model = torch.nn.DataParallel(model, device_ids=ids)\n\n    tile_loader = TileLoader(sdata, patch_width, image_key, level, magnification, patch_overlap, roi_key)\n\n    log.info(f\"Processing {len(tile_loader)} patches extracted from level {tile_loader.level}\")\n\n    predictions = []\n    with torch.no_grad():\n        for i in tqdm.tqdm(range(0, len(tile_loader), batch_size)):\n            batch = tile_loader[i : i + batch_size]\n            embedding: torch.Tensor = model(batch.to(device))\n            assert len(embedding.shape) == 2, \"The model must have the signature (B, C, Y, X) -&gt; (B, C)\"\n\n            predictions.append(embedding.cpu())\n\n    predictions = torch.cat(predictions)\n    if len(predictions.shape) == 1:\n        predictions = torch.unsqueeze(predictions, 1)\n\n    patches = tile_loader.patches\n    patches.add_shapes(key_added=SopaKeys.EMBEDDINGS_PATCHES)\n\n    gdf = sdata[SopaKeys.EMBEDDINGS_PATCHES]\n\n    adata = AnnData(predictions.numpy())\n    adata.obs[\"region\"] = SopaKeys.EMBEDDINGS_PATCHES\n    adata.obs[\"instance\"] = gdf.index.values\n    adata = TableModel.parse(\n        adata,\n        region=SopaKeys.EMBEDDINGS_PATCHES,\n        region_key=\"region\",\n        instance_key=\"instance\",\n    )\n    adata.obsm[\"spatial\"] = patches.centroids()\n    adata.uns[\"embedding_config\"] = {\n        \"patch_width\": patch_width,\n        \"patch_overlap\": patch_overlap,\n        \"magnification\": magnification,\n        \"level\": tile_loader.level,\n        \"level_downsample\": tile_loader.level_downsample,\n        \"tile_resize_factor\": tile_loader.tile_resize_factor,\n        \"model_name\": model_name,\n    }\n\n    key_added = key_added or f\"{model_name}_embeddings\"\n    add_spatial_element(sdata, key_added, adata)\n\n    return key_added\n</code></pre>"},{"location":"api/patches/#sopa.patches.cluster_embeddings","title":"<code>sopa.patches.cluster_embeddings(sdata, element, method='leiden', key_added='cluster', **method_kwargs)</code>","text":"<p>Create clusters of the patches embeddings (obtained from sopa.patches.compute_embeddings).</p> Info <p>The clusters are added to the <code>key_added</code> column of the \"inference_patches\" shapes (<code>key_added='cluster'</code> by default).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData | None</code> <p>A <code>SpatialData</code> object. Can be <code>None</code> if element is an <code>AnnData</code> object.</p> required <code>element</code> <code>AnnData | str</code> <p>The <code>AnnData</code> containing the embeddings, or the name of the element</p> required <code>method</code> <code>Callable | str</code> <p>Callable that takes as an AnnData object and returns an array of clusters of size <code>n_obs</code>, or an available method name (<code>leiden</code> or <code>kmeans</code>)</p> <code>'leiden'</code> <code>key_added</code> <code>str</code> <p>The key containing the clusters to be added to the <code>element.obs</code></p> <code>'cluster'</code> <code>method_kwargs</code> <code>str</code> <p>kwargs provided to the method callable</p> <code>{}</code> Source code in <code>sopa/patches/cluster.py</code> <pre><code>def cluster_embeddings(\n    sdata: SpatialData | None,\n    element: AnnData | str,\n    method: Callable | str = \"leiden\",\n    key_added: str = \"cluster\",\n    **method_kwargs: str,\n) -&gt; None:\n    \"\"\"Create clusters of the patches embeddings (obtained from [sopa.patches.compute_embeddings][]).\n\n    Info:\n        The clusters are added to the `key_added` column of the \"inference_patches\" shapes (`key_added='cluster'` by default).\n\n    Args:\n        sdata: A `SpatialData` object. Can be `None` if element is an `AnnData` object.\n        element: The `AnnData` containing the embeddings, or the name of the element\n        method: Callable that takes as an AnnData object and returns an array of clusters of size `n_obs`, or an available method name (`leiden` or `kmeans`)\n        key_added: The key containing the clusters to be added to the `element.obs`\n        method_kwargs: kwargs provided to the method callable\n    \"\"\"\n    if isinstance(element, str):\n        element: AnnData = sdata.tables[element]\n\n    if isinstance(method, str):\n        assert method in METHODS_DICT, f\"Method {method} is not available. Use one of: {', '.join(METHODS_DICT.keys())}\"\n        method = METHODS_DICT[method]\n\n    element.obs[key_added] = method(element, **method_kwargs)\n    element.obs[key_added] = element.obs[key_added].astype(\"category\")\n</code></pre>"},{"location":"api/readers/","title":"Readers","text":"<p>The readers below are used to read your raw spatial data into a <code>SpatialData</code> object. Choose the right function below, according to your technology of interest.</p> <p>Warning</p> <p>Due to many updates in the data format provided by the different companies, you might have issues loading your data. In this case, consider opening an issue detailing the version of the machine you used and the error log, as well as an example of file names that you are trying to read.</p>"},{"location":"api/readers/#sopa.io.xenium","title":"<code>sopa.io.xenium(path, image_models_kwargs=None, imread_kwargs=None, cells_boundaries=False, cells_table=False, nucleus_labels=False, cells_labels=False, cells_as_circles=False, nucleus_boundaries=False, qv_threshold=None, **kwargs)</code>","text":"<p>Read Xenium data as a <code>SpatialData</code> object. For more information, refer to spatialdata-io.</p> This function reads the following files <ul> <li><code>transcripts.parquet</code>: transcripts locations and names</li> <li><code>experiment.xenium</code>: metadata file</li> <li><code>morphology_focus.ome.tif</code>: morphology image (or a directory, for recent versions of the Xenium)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the Xenium directory containing all the experiment files</p> required <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <code>cells_boundaries</code> <code>int</code> <p>Whether to read cell boundaries</p> <code>False</code> <code>cells_table</code> <code>int</code> <p>Whether to read cell table</p> <code>False</code> <code>nucleus_labels</code> <code>int</code> <p>Whether to read nucleus labels</p> <code>False</code> <code>cells_labels</code> <code>int</code> <p>Whether to read cell labels</p> <code>False</code> <code>cells_as_circles</code> <code>int</code> <p>Whether to read cells as circles</p> <code>False</code> <code>nucleus_boundaries</code> <code>int</code> <p>Whether to read nucleus boundaries</p> <code>False</code> <code>qv_threshold</code> <code>int | None</code> <p>Whether to add a \"low_quality_transcript\" column to transcripts. Transcripts with a QV value below <code>qv_threshold</code> will not be used during segmentation.</p> <code>None</code> <code>kwargs</code> <code>int</code> <p>Additional keyword arguments passed to `spatialdata_io.xenium</p> <code>{}</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the Xenium experiment</p> Source code in <code>sopa/io/reader/xenium.py</code> <pre><code>def xenium(\n    path: str | Path,\n    image_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n    cells_boundaries: int = False,\n    cells_table: int = False,\n    nucleus_labels: int = False,\n    cells_labels: int = False,\n    cells_as_circles: int = False,\n    nucleus_boundaries: int = False,\n    qv_threshold: int | None = None,\n    **kwargs: int,\n) -&gt; SpatialData:\n    \"\"\"Read Xenium data as a `SpatialData` object. For more information, refer to [spatialdata-io](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.xenium.html).\n\n    This function reads the following files:\n        - `transcripts.parquet`: transcripts locations and names\n        - `experiment.xenium`: metadata file\n        - `morphology_focus.ome.tif`: morphology image (or a directory, for recent versions of the Xenium)\n\n\n    Args:\n        path: Path to the Xenium directory containing all the experiment files\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n        cells_boundaries: Whether to read cell boundaries\n        cells_table: Whether to read cell table\n        nucleus_labels: Whether to read nucleus labels\n        cells_labels: Whether to read cell labels\n        cells_as_circles: Whether to read cells as circles\n        nucleus_boundaries: Whether to read nucleus boundaries\n        qv_threshold: Whether to add a \"low_quality_transcript\" column to transcripts. Transcripts with a QV value below `qv_threshold` will not be used during segmentation.\n        kwargs: Additional keyword arguments passed to `spatialdata_io.xenium\n\n    Returns:\n        A `SpatialData` object representing the Xenium experiment\n    \"\"\"\n    from spatialdata_io.readers.xenium import xenium as xenium_spatialdata_io\n\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    sdata: SpatialData = xenium_spatialdata_io(\n        path,\n        cells_table=cells_table,\n        nucleus_labels=nucleus_labels,\n        cells_labels=cells_labels,\n        cells_as_circles=cells_as_circles,\n        nucleus_boundaries=nucleus_boundaries,\n        cells_boundaries=cells_boundaries,\n        image_models_kwargs=image_models_kwargs,\n        imread_kwargs=imread_kwargs,\n        **kwargs,\n    )\n\n    if \"table\" in sdata.tables:\n        sdata[\"table\"].uns[ATTRS_KEY][\"region\"] = \"cell_boundaries\"\n        sdata[\"table\"].obs[\"region\"] = \"cell_boundaries\"\n        sdata[\"table\"].obs[\"region\"] = sdata[\"table\"].obs[\"region\"].astype(\"category\")\n\n    ensure_string_channel_names(sdata)\n\n    ### Add Sopa attributes to detect the spatial elements\n    if \"morphology_focus\" in sdata.images:\n        sdata.attrs[SopaAttrs.CELL_SEGMENTATION] = \"morphology_focus\"\n\n    if \"he_image\" in sdata.images:\n        sdata.attrs[SopaAttrs.TISSUE_SEGMENTATION] = \"he_image\"\n\n    if \"transcripts\" in sdata.points:\n        sdata.attrs[SopaAttrs.TRANSCRIPTS] = \"transcripts\"\n\n        if \"cell_id\" in sdata.points[\"transcripts\"].columns:\n            sdata.attrs[SopaAttrs.PRIOR_TUPLE_KEY] = [\"cell_id\", \"UNASSIGNED\"]\n\n        if qv_threshold is not None:\n            assert \"qv\" in sdata.points[\"transcripts\"].columns, \"QV column not found in `sdata['transcripts']`\"\n\n            sdata.points[\"transcripts\"][SopaKeys.LOW_QUALITY_TRANSCRIPT_KEY] = (\n                sdata.points[\"transcripts\"][\"qv\"] &lt; qv_threshold\n            )\n\n    sdata.attrs[SopaAttrs.XENIUM_OUTPUT_PATH] = str(Path(path).resolve())\n\n    return sdata\n</code></pre>"},{"location":"api/readers/#sopa.io.merscope","title":"<code>sopa.io.merscope(path, backend=None, z_layers=3, region_name=None, slide_name=None, cells_boundaries=False, cells_table=False, image_models_kwargs=None, imread_kwargs=None, **kwargs)</code>","text":"<p>Read MERSCOPE data as a <code>SpatialData</code> object. For more information, refer to spatialdata-io.</p> This function reads the following files <ul> <li><code>detected_transcripts.csv</code>: transcripts locations and names</li> <li>all the images under the <code>images</code> directory</li> <li><code>images/micron_to_mosaic_pixel_transform.csv</code>: affine transformation</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the MERSCOPE directory containing all the experiment files</p> required <code>backend</code> <code>Literal['dask_image', 'rioxarray'] | None</code> <p>Either <code>\"dask_image\"</code> or <code>\"rioxarray\"</code> (the latter uses less RAM, but requires <code>rioxarray</code> to be installed). By default, uses <code>\"rioxarray\"</code> if and only if the <code>rioxarray</code> library is installed.</p> <code>None</code> <code>z_layers</code> <code>int | list[int] | None</code> <p>Indices of the z-layers to consider. Either one <code>int</code> index, or a list of <code>int</code> indices. If <code>None</code>, then no image is loaded. By default, only the middle layer is considered (that is, layer 3).</p> <code>3</code> <code>region_name</code> <code>str | None</code> <p>Name of the region of interest, e.g., <code>'region_0'</code>. If <code>None</code> then the name of the <code>path</code> directory is used.</p> <code>None</code> <code>slide_name</code> <code>str | None</code> <p>Name of the slide/run. If <code>None</code> then the name of the parent directory of <code>path</code> is used (whose name starts with a date).</p> <code>None</code> <code>cells_boundaries</code> <code>bool</code> <p>Whether to read cell boundaries (polygons).</p> <code>False</code> <code>cells_table</code> <code>bool</code> <p>Whether to read the cells table.</p> <code>False</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <code>kwargs</code> <code>int</code> <p>Additional keyword arguments passed to <code>spatialdata_io.merscope</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the MERSCOPE experiment</p> Source code in <code>sopa/io/reader/merscope.py</code> <pre><code>def merscope(\n    path: str | Path,\n    backend: Literal[\"dask_image\", \"rioxarray\"] | None = None,\n    z_layers: int | list[int] | None = 3,\n    region_name: str | None = None,\n    slide_name: str | None = None,\n    cells_boundaries: bool = False,\n    cells_table: bool = False,\n    image_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n    **kwargs: int,\n) -&gt; SpatialData:\n    \"\"\"Read MERSCOPE data as a `SpatialData` object. For more information, refer to [spatialdata-io](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.merscope.html).\n\n    This function reads the following files:\n        - `detected_transcripts.csv`: transcripts locations and names\n        - all the images under the `images` directory\n        - `images/micron_to_mosaic_pixel_transform.csv`: affine transformation\n\n    Args:\n        path: Path to the MERSCOPE directory containing all the experiment files\n        backend: Either `\"dask_image\"` or `\"rioxarray\"` (the latter uses less RAM, but requires `rioxarray` to be installed). By default, uses `\"rioxarray\"` if and only if the `rioxarray` library is installed.\n        z_layers: Indices of the z-layers to consider. Either one `int` index, or a list of `int` indices. If `None`, then no image is loaded. By default, only the middle layer is considered (that is, layer 3).\n        region_name: Name of the region of interest, e.g., `'region_0'`. If `None` then the name of the `path` directory is used.\n        slide_name: Name of the slide/run. If `None` then the name of the parent directory of `path` is used (whose name starts with a date).\n        cells_boundaries: Whether to read cell boundaries (polygons).\n        cells_table: Whether to read the cells table.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n        kwargs: Additional keyword arguments passed to [`spatialdata_io.merscope`](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.merscope.html).\n\n    Returns:\n        A `SpatialData` object representing the MERSCOPE experiment\n    \"\"\"\n    from spatialdata_io.readers.merscope import merscope as merscope_spatialdata_io\n\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    sdata: SpatialData = merscope_spatialdata_io(\n        path,\n        backend=backend,\n        z_layers=z_layers,\n        region_name=region_name,\n        slide_name=slide_name,\n        image_models_kwargs=image_models_kwargs,\n        imread_kwargs=imread_kwargs,\n        cells_boundaries=cells_boundaries,\n        cells_table=cells_table,\n        **kwargs,\n    )\n\n    ### Add Sopa attributes to detect the spatial elements\n    if z_layers is not None:\n        if not isinstance(z_layers, int) and len(z_layers) == 1:\n            z_layers = z_layers[0]\n        if isinstance(z_layers, int):\n            for key in sdata.images:\n                if key.endswith(f\"_z{z_layers}\"):\n                    sdata.attrs[SopaAttrs.CELL_SEGMENTATION] = key\n        else:\n            log.warning(\n                f\"Multiple z-layers provided: {z_layers}. Not deciding which image should be used for cell segmentation.\"\n            )\n\n    for key in sdata.points:\n        if key.endswith(\"_transcripts\"):\n            sdata.attrs[SopaAttrs.TRANSCRIPTS] = key\n\n            if \"cell_id\" in sdata.points[key].columns:\n                sdata.attrs[SopaAttrs.PRIOR_TUPLE_KEY] = [\"cell_id\", -1]\n            break\n\n    return sdata\n</code></pre>"},{"location":"api/readers/#sopa.io.visium_hd","title":"<code>sopa.io.visium_hd(path, fullres_image_file=None, dataset_id=None, image_models_kwargs=None, imread_kwargs=None, var_names_make_unique=True, bins_as_squares=True, **kwargs)</code>","text":"<p>Read Visium HD data as a <code>SpatialData</code> object. For more information, refer to spatialdata-io.</p> <p>Info</p> <p>If your <code>fullres_image_file</code> is not in the <code>microscope_image</code> directory, you can specify the path to the image file using the <code>fullres_image_file</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the Visium HD directory containing all the experiment files</p> required <code>fullres_image_file</code> <code>str | Path | None</code> <p>Path to the full-resolution image. By default the image is searched in the <code>'microscope_image'</code> directory.</p> <code>None</code> <code>dataset_id</code> <code>str | None</code> <p>Identifier of the dataset. By default, inferred from the prefix of the input files. If the files have no prefix (e.g., <code>feature_slice.h5</code>), use <code>dataset_id=\"\"</code>.</p> <code>None</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <code>var_names_make_unique</code> <code>bool</code> <p>If True, ensure that the var names are unique.</p> <code>True</code> <code>bins_as_squares</code> <code>bool</code> <p>If <code>True</code>, the bins are represented as squares. If <code>False</code>, the bins are represented as circles. For a correct visualization one should use squares.</p> <code>True</code> <code>kwargs</code> <code>int</code> <p>Additional keyword arguments passed to <code>spatialdata_io.visium_hd</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the Xenium experiment</p> Source code in <code>sopa/io/reader/visium_hd.py</code> <pre><code>def visium_hd(\n    path: str | Path,\n    fullres_image_file: str | Path | None = None,\n    dataset_id: str | None = None,\n    image_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n    var_names_make_unique: bool = True,\n    bins_as_squares: bool = True,\n    **kwargs: int,\n) -&gt; SpatialData:\n    \"\"\"Read Visium HD data as a `SpatialData` object. For more information, refer to [spatialdata-io](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.visium_hd.html).\n\n    !!! info\n        If your `fullres_image_file` is not in the `microscope_image` directory, you can specify the path to the image file using the `fullres_image_file` argument.\n\n    Args:\n        path: Path to the Visium HD directory containing all the experiment files\n        fullres_image_file: Path to the full-resolution image. By default the image is searched in the `'microscope_image'` directory.\n        dataset_id: Identifier of the dataset. By default, inferred from the prefix of the input files. If the files have no prefix (e.g., `feature_slice.h5`), use `dataset_id=\"\"`.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n        var_names_make_unique: If True, ensure that the var names are unique.\n        bins_as_squares: If `True`, the bins are represented as squares. If `False`, the bins are represented as circles. For a correct visualization one should use squares.\n        kwargs: Additional keyword arguments passed to `spatialdata_io.visium_hd`.\n\n    Returns:\n        A `SpatialData` object representing the Xenium experiment\n    \"\"\"\n    from spatialdata_io.readers.visium_hd import visium_hd as visium_hd_spatialdata_io\n\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    del image_models_kwargs[\"scale_factors\"]  # already set in the spatialdata_io reader\n\n    sdata: SpatialData = visium_hd_spatialdata_io(\n        path,\n        dataset_id=dataset_id,\n        fullres_image_file=fullres_image_file,\n        image_models_kwargs=image_models_kwargs,\n        imread_kwargs=imread_kwargs,\n        bins_as_squares=bins_as_squares,\n        **kwargs,\n    )\n\n    ensure_string_channel_names(sdata)  # Ensure that channel names are strings\n\n    ### Add Sopa attributes to detect the spatial elements\n    for key in sdata.images:\n        if key.endswith(\"_full_image\"):\n            sdata.attrs[SopaAttrs.CELL_SEGMENTATION] = key\n        elif key.endswith(\"_hires_image\"):\n            sdata.attrs[SopaAttrs.TISSUE_SEGMENTATION] = key\n\n    for key, adata in sdata.tables.items():\n        if key.endswith(\"_002um\"):\n            sdata.attrs[SopaAttrs.BINS_TABLE] = key\n        if var_names_make_unique:\n            adata.var_names_make_unique()\n\n    _set_microns_coordinate_system(sdata, bins_as_squares=bins_as_squares)\n\n    for key in sdata.shapes:\n        if key.endswith(\"_cell_segmentations\"):\n            sdata.attrs[SopaAttrs.BOUNDARIES] = key\n            break\n\n    for key in sdata.shapes:\n        if key.endswith(\"_002um\"):\n            shapes_bounding_box(sdata, key)\n            break\n\n    _sanity_check_images(sdata)\n\n    return sdata\n</code></pre>"},{"location":"api/readers/#sopa.io.cosmx","title":"<code>sopa.io.cosmx(path, dataset_id=None, fov=None, read_image=True, read_proteins=False, cells_labels=False, cells_table=False, cells_polygons=False, image_models_kwargs=None, labels_models_kwargs=None, imread_kwargs=None, flip_image=False, fov_shift=None)</code>","text":"<p>Read CosMx Nanostring / Bruker data. The fields of view are stitched together, except if <code>fov</code> is provided.</p> This function reads the following files <ul> <li><code>*_fov_positions_file.csv</code> or <code>*_fov_positions_file.csv.gz</code>: FOV locations</li> <li><code>Morphology2D</code> directory: all the FOVs morphology images</li> <li><code>*_tx_file.csv.gz</code> or <code>*_tx_file.csv</code>: Transcripts location and names</li> <li>If <code>read_proteins</code> is <code>True</code>, all the images under the nested <code>ProteinImages</code> directories will be read</li> </ul> <p>These files must be exported as flat files in AtomX. That is: within a study, click on \"Export\" and then select files from the \"Flat CSV Files\" section (transcripts flat and FOV position flat).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the root directory containing Nanostring files.</p> required <code>dataset_id</code> <code>str | None</code> <p>Optional name of the dataset (needs to be provided if not inferred).</p> <code>None</code> <code>fov</code> <code>int | None</code> <p>Number of one single field of view to be read. If not provided, reads all FOVs and create a stitched image.</p> <code>None</code> <code>read_image</code> <code>bool</code> <p>Whether to read the images or not.</p> <code>True</code> <code>read_proteins</code> <code>bool</code> <p>Whether to read the proteins or the transcripts.</p> <code>False</code> <code>cells_labels</code> <code>bool</code> <p>Whether to read the cell labels or not.</p> <code>False</code> <code>cells_table</code> <code>bool</code> <p>Whether to read the cell table or not.</p> <code>False</code> <code>cells_polygons</code> <code>bool</code> <p>Whether to read the cell polygons or not.</p> <code>False</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <code>flip_image</code> <code>bool</code> <p>For some buggy exports of AtomX 1.3.2, <code>flip_image=True</code> has to be used for stitching. See this issue.</p> <code>False</code> <code>fov_shift</code> <code>bool | None</code> <p>Whether to apply FOV shift correction. For some datasets, there is a one-FOV shift in the y direction between the image and the polygons/transcripts. If <code>None</code>, it will be inferred automatically based on the FOV positions file and the polygons files.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the CosMx experiment</p> Source code in <code>sopa/io/reader/cosmx.py</code> <pre><code>def cosmx(\n    path: str | Path,\n    dataset_id: str | None = None,\n    fov: int | None = None,\n    read_image: bool = True,\n    read_proteins: bool = False,\n    cells_labels: bool = False,\n    cells_table: bool = False,\n    cells_polygons: bool = False,\n    image_models_kwargs: dict | None = None,\n    labels_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n    flip_image: bool = False,\n    fov_shift: bool | None = None,\n) -&gt; SpatialData:\n    \"\"\"\n    Read *CosMx Nanostring / Bruker* data. The fields of view are stitched together, except if `fov` is provided.\n\n    This function reads the following files:\n        - `*_fov_positions_file.csv` or `*_fov_positions_file.csv.gz`: FOV locations\n        - `Morphology2D` directory: all the FOVs morphology images\n        - `*_tx_file.csv.gz` or `*_tx_file.csv`: Transcripts location and names\n        - If `read_proteins` is `True`, all the images under the nested `ProteinImages` directories will be read\n\n        These files must be exported as flat files in AtomX. That is: within a study, click on \"Export\" and then select files from the \"Flat CSV Files\" section (transcripts flat and FOV position flat).\n\n    Args:\n        path: Path to the root directory containing *Nanostring* files.\n        dataset_id: Optional name of the dataset (needs to be provided if not inferred).\n        fov: Number of one single field of view to be read. If not provided, reads all FOVs and create a stitched image.\n        read_image: Whether to read the images or not.\n        read_proteins: Whether to read the proteins or the transcripts.\n        cells_labels: Whether to read the cell labels or not.\n        cells_table: Whether to read the cell table or not.\n        cells_polygons: Whether to read the cell polygons or not.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n        flip_image: For some buggy exports of AtomX 1.3.2, `flip_image=True` has to be used for stitching. See [this](https://github.com/gustaveroussy/sopa/issues/231) issue.\n        fov_shift: Whether to apply FOV shift correction. For some datasets, there is a one-FOV shift in the y direction between the image and the polygons/transcripts. If `None`, it will be inferred automatically based on the FOV positions file and the polygons files.\n\n    Returns:\n        A `SpatialData` object representing the CosMx experiment\n    \"\"\"\n    path = Path(path)\n\n    assert read_image or cells_labels, \"At least one of `read_image` or `cells_labels` must be True.\"\n\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n    labels_models_kwargs = {\"chunks\": (4256, 4256)} if labels_models_kwargs is None else labels_models_kwargs\n\n    dataset_id = _infer_dataset_id(path, dataset_id)\n\n    _reader = _CosMXReader(path, dataset_id, fov, flip_image, fov_shift)\n    attrs = {}\n\n    ### Read elements\n    region = _reader.shapes_key if cells_polygons else (_reader.labels_key if cells_labels else None)\n    tables = _reader.read_tables(region) if cells_table else {}\n\n    images = {}\n    if read_image:\n        images = _reader.read_images(\n            read_proteins=read_proteins,\n            imread_kwargs=imread_kwargs,\n            image_models_kwargs=image_models_kwargs,\n        )\n        attrs[SopaAttrs.CELL_SEGMENTATION] = next(iter(images))\n\n    labels = (\n        _reader.read_labels(imread_kwargs=imread_kwargs, labels_models_kwargs=labels_models_kwargs)\n        if cells_labels\n        else {}\n    )\n    shapes = _reader.read_shapes() if cells_polygons else {}\n\n    points = _reader.read_transcripts() if not read_proteins else {}\n    if points:\n        attrs[SopaAttrs.TRANSCRIPTS] = next(iter(points.keys()))\n        attrs[SopaAttrs.PRIOR_TUPLE_KEY] = (\"global_cell_id\", 0)\n\n    return SpatialData(images=images, labels=labels, points=points, tables=tables, shapes=shapes, attrs=attrs)\n</code></pre>"},{"location":"api/readers/#sopa.io.molecular_cartography","title":"<code>sopa.io.molecular_cartography(path, region, image_models_kwargs=None, imread_kwargs=None)</code>","text":"<p>Read Molecular Cartography data from Resolve Bioscience as a <code>SpatialData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the directory containing the <code>.tiff</code> images and <code>_results.txt</code> files.</p> required <code>region</code> <code>str</code> <p>Name of the region to read. The region name can be found before the <code>_results.txt</code> file, e.g. <code>A2-1</code>.</p> required <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the Resolve Bioscience experiment</p> Source code in <code>sopa/io/reader/molecular_cartography.py</code> <pre><code>def molecular_cartography(\n    path: str | Path,\n    region: str,\n    image_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n) -&gt; SpatialData:\n    \"\"\"Read *Molecular Cartography* data from *Resolve Bioscience* as a `SpatialData` object.\n\n    Args:\n        path: Path to the directory containing the `.tiff` images and `_results.txt` files.\n        region: Name of the region to read. The region name can be found before the `_results.txt` file, e.g. `A2-1`.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n\n    Returns:\n        A `SpatialData` object representing the *Resolve Bioscience* experiment\n    \"\"\"\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    path = Path(path)\n    dataset_id = _get_dataset_id(path, region)\n\n    # Read the points\n    transcripts = pd.read_csv(path / f\"{dataset_id}_results.txt\", sep=\"\\t\", header=None)\n    transcripts.columns = [\"x\", \"y\", \"z\", \"target_name\", \"unnamed\"]\n\n    transcripts = PointsModel.parse(transcripts, feature_key=\"target_name\")\n    transcripts_name = f\"{dataset_id}_points\"\n\n    # Read the images\n    images_paths = list(path.glob(f\"{dataset_id}_*.tiff\"))\n    c_coords = [image_path.stem.split(\"_\")[-1] for image_path in images_paths]\n\n    image = Image2DModel.parse(\n        da.concatenate([imread(image_path, **imread_kwargs) for image_path in images_paths], axis=0),\n        dims=(\"c\", \"y\", \"x\"),\n        c_coords=c_coords,\n        rgb=None,\n        **image_models_kwargs,\n    )\n    image_name = f\"{dataset_id}_image\"\n\n    return SpatialData(\n        images={image_name: image},\n        points={transcripts_name: transcripts},\n        attrs={\n            SopaAttrs.CELL_SEGMENTATION: image_name,\n            SopaAttrs.TRANSCRIPTS: transcripts_name,\n        },\n    )\n</code></pre>"},{"location":"api/readers/#sopa.io.macsima","title":"<code>sopa.io.macsima(path, **kwargs)</code>","text":"<p>Read MACSIMA data as a <code>SpatialData</code> object</p> Notes <p>For all dulicated name, their index will be added in brackets after, for instance you may find <code>DAPI (1)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the directory containing the MACSIMA <code>.tif</code> images</p> required <code>kwargs</code> <code>int</code> <p>Kwargs for the <code>_general_tif_directory_reader</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/macsima.py</code> <pre><code>def macsima(path: Path, **kwargs: int) -&gt; SpatialData:\n    \"\"\"Read MACSIMA data as a `SpatialData` object\n\n    Notes:\n        For all dulicated name, their index will be added in brackets after, for instance you may find `DAPI (1)`.\n\n    Args:\n        path: Path to the directory containing the MACSIMA `.tif` images\n        kwargs: Kwargs for the `_general_tif_directory_reader`\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    files = list(Path(path).glob(\"*.tif\"))\n\n    if any(\"A-\" in file.name for file in files):  # non-ome.tif format\n        return _general_tif_directory_reader(path, files_to_channels=_get_channel_names_macsima, **kwargs)\n\n    return _general_tif_directory_reader(path, **kwargs)\n</code></pre>"},{"location":"api/readers/#sopa.io.phenocycler","title":"<code>sopa.io.phenocycler(path, channels_renaming=None, image_models_kwargs=None)</code>","text":"<p>Read Phenocycler data as a <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to a <code>.qptiff</code> file, or a <code>.tif</code> file (if exported from QuPath)</p> required <code>channels_renaming</code> <code>dict | None</code> <p>A dictionnary whose keys correspond to channels and values to their corresponding new name. Not all channels need to be renamed.</p> <code>None</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/phenocycler.py</code> <pre><code>def phenocycler(\n    path: str | Path, channels_renaming: dict | None = None, image_models_kwargs: dict | None = None\n) -&gt; SpatialData:\n    \"\"\"Read Phenocycler data as a `SpatialData` object\n\n    Args:\n        path: Path to a `.qptiff` file, or a `.tif` file (if exported from QuPath)\n        channels_renaming: A dictionnary whose keys correspond to channels and values to their corresponding new name. Not all channels need to be renamed.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs, _ = _default_image_kwargs(image_models_kwargs)\n\n    path = Path(path)\n    image_name = path.absolute().stem\n\n    if path.suffix == \".qptiff\":\n        with tf.TiffFile(path) as tif:\n            series = tif.series[0]\n            names = _deduplicate_names([_get_channel_name_qptiff(page.description) for page in series])\n\n            delayed_image = delayed(lambda series: series.asarray())(tif)\n            image = da.from_delayed(delayed_image, dtype=series.dtype, shape=series.shape)\n    elif path.suffix == \".tif\":\n        image = imread(path)\n        names = _get_IJ_channel_names(path)\n    else:\n        raise ValueError(f\"Unsupported file extension {path.suffix}. Must be '.qptiff' or '.tif'.\")\n\n    names = _rename_channels(names, channels_renaming)\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        c_coords=names,\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image}, attrs={SopaAttrs.CELL_SEGMENTATION: image_name})\n</code></pre>"},{"location":"api/readers/#sopa.io.hyperion","title":"<code>sopa.io.hyperion(path, image_models_kwargs=None, imread_kwargs=None)</code>","text":"<p>Read Hyperion data as a <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the directory containing the Hyperion <code>.tiff</code> images</p> required <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/hyperion.py</code> <pre><code>def hyperion(path: Path, image_models_kwargs: dict | None = None, imread_kwargs: dict | None = None) -&gt; SpatialData:\n    \"\"\"Read Hyperion data as a `SpatialData` object\n\n    Args:\n        path: Path to the directory containing the Hyperion `.tiff` images\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    files = [file for file in Path(path).iterdir() if file.suffix == \".tiff\"]\n\n    names = _get_channel_names_hyperion(files)\n    image = da.concatenate(\n        [imread(file, **imread_kwargs) for file in files],\n        axis=0,\n    )\n\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    log.info(f\"Found channel names {names}\")\n\n    image_name = Path(path).absolute().stem\n\n    image = DataArray(image, dims=[\"c\", \"y\", \"x\"], name=image_name, coords={\"c\": names})\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        image = _clip_intensity_values(image)\n\n    image = Image2DModel.parse(\n        image,\n        c_coords=image.coords[\"c\"].values,\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image}, attrs={SopaAttrs.CELL_SEGMENTATION: image_name})\n</code></pre>"},{"location":"api/readers/#sopa.io.bioio","title":"<code>sopa.io.bioio(path, z_stack=0, image_models_kwargs=None, bioio_kwargs=None)</code>","text":"<p>Read an image using bioio. It supports special formats such as <code>ND2</code>, <code>CZI</code>, <code>LIF</code>, or <code>DV</code>.</p> <p>Extra dependencies</p> <p>To use this reader, you'll need the <code>bioio</code> dependency (<code>pip install bioio</code>). You may need extra dependencies specific to your format, see their documentation.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the image file</p> required <code>z_stack</code> <code>int</code> <p>(Only for 3D images) Index of the stack in the z-axis to use.</p> <code>0</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>bioio_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>bioio.BioImage</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/generic.py</code> <pre><code>def bioio(\n    path: Path,\n    z_stack: int = 0,\n    image_models_kwargs: dict | None = None,\n    bioio_kwargs: dict | None = None,\n) -&gt; SpatialData:\n    \"\"\"Read an image using [bioio](https://github.com/bioio-devs/bioio). It supports special formats such as `ND2`, `CZI`, `LIF`, or `DV`.\n\n    !!! note \"Extra dependencies\"\n        To use this reader, you'll need the `bioio` dependency (`pip install bioio`). You may need extra dependencies specific to your format, see their [documentation](https://bioio-devs.github.io/bioio/OVERVIEW.html#reader-installation).\n\n    Args:\n        path: Path to the image file\n        z_stack: (Only for 3D images) Index of the stack in the z-axis to use.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        bioio_kwargs: Keyword arguments passed to `bioio.BioImage`.\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs, _ = _default_image_kwargs(image_models_kwargs, None)\n    bioio_kwargs = {} if bioio_kwargs is None else bioio_kwargs\n\n    try:\n        from bioio import BioImage\n    except ImportError:\n        raise ImportError(\"You need to install bioio, e.g. by running `pip install bioio`\")\n\n    xarr: xr.DataArray = BioImage(path, **bioio_kwargs).xarray_dask_data\n\n    assert len(xarr.coords[\"T\"]) == 1, f\"Only one time dimension is supported, found {len(xarr.coords['T'])}.\"\n\n    if len(xarr.coords[\"Z\"]) &gt; 1:\n        log.info(f\"3D image found, only reading {z_stack:=}\")\n\n    xarr = xarr.isel(T=0, Z=z_stack).rename({\"C\": \"c\", \"Y\": \"y\", \"X\": \"x\"})\n    xarr = _image_int_dtype(xarr)\n\n    image = Image2DModel.parse(xarr, c_coords=xarr.coords[\"c\"].values, **image_models_kwargs)\n\n    return SpatialData(images={\"image\": image}, attrs={SopaAttrs.CELL_SEGMENTATION: \"image\"})\n</code></pre>"},{"location":"api/readers/#sopa.io.aicsimageio","title":"<code>sopa.io.aicsimageio(path, z_stack=0, image_models_kwargs=None, aics_kwargs=None)</code>","text":"<p>Read an image using AICSImageIO. It supports special formats such as <code>ND2</code>, <code>CZI</code>, <code>LIF</code>, or <code>DV</code>.</p> <p>Extra dependencies</p> <p>To use this reader, you'll need the <code>aicsimageio</code> dependency (<code>pip install aicsimageio</code>). To read <code>.czi</code> images, you'll also need to install <code>aicspylibczi</code> (for instance <code>pip install aicspylibczi</code>).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the image file</p> required <code>z_stack</code> <code>int</code> <p>(Only for 3D images) Index of the stack in the z-axis to use.</p> <code>0</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>aics_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>aicsimageio.AICSImage</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/generic.py</code> <pre><code>def aicsimageio(\n    path: Path,\n    z_stack: int = 0,\n    image_models_kwargs: dict | None = None,\n    aics_kwargs: dict | None = None,\n) -&gt; SpatialData:\n    \"\"\"Read an image using [AICSImageIO](https://github.com/AllenCellModeling/aicsimageio). It supports special formats such as `ND2`, `CZI`, `LIF`, or `DV`.\n\n    !!! note \"Extra dependencies\"\n        To use this reader, you'll need the `aicsimageio` dependency (`pip install aicsimageio`). To read `.czi` images, you'll also need to install `aicspylibczi` (for instance `pip install aicspylibczi`).\n\n    Args:\n        path: Path to the image file\n        z_stack: (Only for 3D images) Index of the stack in the z-axis to use.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        aics_kwargs: Keyword arguments passed to `aicsimageio.AICSImage`.\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    log.warning(\"The `aicsimageio` reader is deprecated. Use `sopa.io.bioio` instead.\")\n    image_models_kwargs, _ = _default_image_kwargs(image_models_kwargs, None)\n    aics_kwargs = {} if aics_kwargs is None else aics_kwargs\n\n    try:\n        from aicsimageio import AICSImage\n    except ImportError:\n        raise ImportError(\"You need to install aicsimageio, e.g. by running `pip install aicsimageio`\")\n\n    xarr: xr.DataArray = AICSImage(path, **aics_kwargs).xarray_dask_data\n\n    assert len(xarr.coords[\"T\"]) == 1, f\"Only one time dimension is supported, found {len(xarr.coords['T'])}.\"\n\n    if len(xarr.coords[\"Z\"]) &gt; 1:\n        log.info(f\"3D image found, only reading {z_stack:=}\")\n\n    xarr = xarr.isel(T=0, Z=z_stack).rename({\"C\": \"c\", \"Y\": \"y\", \"X\": \"x\"})\n    xarr = _image_int_dtype(xarr)\n\n    image = Image2DModel.parse(xarr, c_coords=xarr.coords[\"c\"].values, **image_models_kwargs)\n\n    return SpatialData(images={\"image\": image}, attrs={SopaAttrs.CELL_SEGMENTATION: \"image\"})\n</code></pre>"},{"location":"api/readers/#sopa.io.ome_tif","title":"<code>sopa.io.ome_tif(path, as_image=False)</code>","text":"<p>Read an <code>.ome.tif</code> image. This image should be a 2D image (with possibly multiple channels). Typically, this function can be used to open Xenium IF images.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the <code>.ome.tif</code> image</p> required <code>as_image</code> <code>bool</code> <p>If <code>True</code>, will return a <code>DataArray</code> object</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray | SpatialData</code> <p>A <code>DataArray</code> or a <code>SpatialData</code> object</p> Source code in <code>sopa/io/reader/utils.py</code> <pre><code>def ome_tif(path: str | Path, as_image: bool = False) -&gt; DataArray | SpatialData:\n    \"\"\"Read an `.ome.tif` image. This image should be a 2D image (with possibly multiple channels).\n    Typically, this function can be used to open Xenium IF images.\n\n    Args:\n        path: Path to the `.ome.tif` image\n        as_image: If `True`, will return a `DataArray` object\n\n    Returns:\n        A `DataArray` or a `SpatialData` object\n    \"\"\"\n    image_models_kwargs, _ = _default_image_kwargs()\n    image_name = Path(path).absolute().name.split(\".\")[0]\n    image: da.Array = imread(path)\n\n    if image.ndim == 4:\n        assert image.shape[0] == 1, \"4D images not supported\"\n        image = da.moveaxis(image[0], 2, 0)\n        log.info(f\"Transformed 4D image into a 3D image of shape (c, y, x) = {image.shape}\")\n    elif image.ndim != 3:\n        raise ValueError(f\"Number of dimensions not supported: {image.ndim}\")\n\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    try:\n        channel_names = _ome_channels_names(path)\n    except:\n        channel_names = []\n    if len(channel_names) != len(image):\n        channel_names = [str(i) for i in range(len(image))]\n        log.warning(f\"Channel names couldn't be read. Using {channel_names} instead.\")\n\n    image = DataArray(image, dims=[\"c\", \"y\", \"x\"], name=image_name, coords={\"c\": channel_names})\n    image = _image_int_dtype(image)\n\n    if as_image:\n        return image\n\n    image = Image2DModel.parse(\n        image,\n        c_coords=channel_names,\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image}, attrs={SopaAttrs.CELL_SEGMENTATION: image_name})\n</code></pre>"},{"location":"api/readers/#sopa.io.wsi","title":"<code>sopa.io.wsi(path, chunks=(3, 512, 512), as_image=False, backend='tiffslide')</code>","text":"<p>Read a WSI into a <code>SpatialData</code> object.</p> <p>Supported backends</p> <p>Multiple backends are supported to read WSIs. To use <code>openslide</code>, you will need to install <code>openslide-python</code> and <code>openslide-bin</code>. If you want to use <code>slideio</code>, you will need to install <code>slideio</code>. The <code>tiffslide</code> backend is supported out-of-the-box.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WSI</p> required <code>chunks</code> <code>tuple[int, int, int]</code> <p>Tuple representing the chunksize for the dimensions <code>(C, Y, X)</code>.</p> <code>(3, 512, 512)</code> <code>as_image</code> <code>bool</code> <p>If <code>True</code>, returns a, image instead of a <code>SpatialData</code> object</p> <code>False</code> <code>backend</code> <code>Literal['tiffslide', 'openslide', 'slideio']</code> <p>The library to use as a backend in order to load the WSI. One of: <code>\"openslide\"</code>, <code>\"tiffslide\"</code>, <code>\"slideio\"</code>.</p> <code>'tiffslide'</code> <p>Returns:</p> Type Description <code>SpatialData | DataTree</code> <p>A <code>SpatialData</code> object with a multiscale 2D-image of shape <code>(C, Y, X)</code>, or just the DataTree if <code>as_image=True</code></p> Source code in <code>sopa/io/reader/wsi.py</code> <pre><code>def wsi(\n    path: str | Path,\n    chunks: tuple[int, int, int] = (3, 512, 512),\n    as_image: bool = False,\n    backend: Literal[\"tiffslide\", \"openslide\", \"slideio\"] = \"tiffslide\",\n) -&gt; SpatialData | DataTree:\n    \"\"\"Read a WSI into a `SpatialData` object.\n\n    !!! info \"Supported backends\"\n        Multiple backends are supported to read WSIs. To use `openslide`, you will need to install `openslide-python` and `openslide-bin`.\n        If you want to use `slideio`, you will need to install `slideio`. The `tiffslide` backend is supported out-of-the-box.\n\n    Args:\n        path: Path to the WSI\n        chunks: Tuple representing the chunksize for the dimensions `(C, Y, X)`.\n        as_image: If `True`, returns a, image instead of a `SpatialData` object\n        backend: The library to use as a backend in order to load the WSI. One of: `\"openslide\"`, `\"tiffslide\"`, `\"slideio\"`.\n\n    Returns:\n        A `SpatialData` object with a multiscale 2D-image of shape `(C, Y, X)`, or just the DataTree if `as_image=True`\n    \"\"\"\n    image_name, img, slide_metadata = _open_wsi(path, backend=backend)\n\n    images = {}\n    for level, key in enumerate(sorted(img.keys(), key=int)):\n        suffix = key if key != \"0\" else \"\"\n\n        scale_image = DataArray(\n            img[key].transpose(\"S\", f\"Y{suffix}\", f\"X{suffix}\"),\n            dims=(\"c\", \"y\", \"x\"),\n        ).chunk(chunks)\n\n        scale_factor = slide_metadata[\"level_downsamples\"][level]\n\n        scale_image = Image2DModel.parse(\n            scale_image[:3, :, :],\n            transformations={\"global\": _get_scale_transformation(scale_factor)},\n            c_coords=(\"r\", \"g\", \"b\"),\n        )\n        scale_image.coords[\"y\"] = scale_factor * scale_image.coords[\"y\"]\n        scale_image.coords[\"x\"] = scale_factor * scale_image.coords[\"x\"]\n\n        images[f\"scale{key}\"] = Dataset({\"image\": scale_image})\n\n    multiscale_image = DataTree.from_dict(images)\n    sdata = SpatialData(images={image_name: multiscale_image}, attrs={SopaAttrs.TISSUE_SEGMENTATION: image_name})\n    sdata[image_name].attrs[\"metadata\"] = slide_metadata\n    sdata[image_name].attrs[\"backend\"] = backend\n    sdata[image_name].attrs[\"path\"] = str(path)\n    sdata[image_name].name = image_name\n\n    if as_image:\n        return multiscale_image\n\n    return sdata\n</code></pre>"},{"location":"api/readers/#sopa.io.toy_dataset","title":"<code>sopa.io.toy_dataset(*_, length=2048, cell_density=0.0001, n_points_per_cell=100, c_coords=['DAPI', 'CK', 'CD3', 'CD20'], genes=['EPCAM', 'CD3E', 'CD20', 'CXCL4', 'CXCL10'], sigma_factor=0.05, pixel_size=0.1, seed=0, include_vertices=False, include_image=True, include_he_image=True, apply_blur=True, as_output=False, transcript_cell_id_as_merscope=False, add_nan_gene_name=False, continuous_z_stack=False, add_second_points_key=False, points_3d=False)</code>","text":"<p>Generate a dummy dataset composed of cells generated uniformly in a square. It also has transcripts.</p> <p>Parameters:</p> Name Type Description Default <code>length</code> <code>int</code> <p>Size of the square, in pixels</p> <code>2048</code> <code>cell_density</code> <code>float</code> <p>Density of cells per pixel^2</p> <code>0.0001</code> <code>n_points_per_cell</code> <code>int</code> <p>Mean number of transcripts per cell</p> <code>100</code> <code>c_coords</code> <code>list[str]</code> <p>Channel names</p> <code>['DAPI', 'CK', 'CD3', 'CD20']</code> <code>genes</code> <code>int | list[str]</code> <p>Number of different genes, or list of gene names</p> <code>['EPCAM', 'CD3E', 'CD20', 'CXCL4', 'CXCL10']</code> <code>sigma_factor</code> <code>float</code> <p>Factor used to determine <code>sigma</code> for the gaussian blur.</p> <code>0.05</code> <code>pixel_size</code> <code>float</code> <p>Number of microns in one pixel.</p> <code>0.1</code> <code>seed</code> <code>int</code> <p>Numpy random seed</p> <code>0</code> <code>include_vertices</code> <code>bool</code> <p>Whether to include the vertices of the cells (as points) in the spatialdata object</p> <code>False</code> <code>include_image</code> <code>bool</code> <p>Whether to include the image in the spatialdata object</p> <code>True</code> <code>apply_blur</code> <code>bool</code> <p>Whether to apply gaussian blur on the image (without blur, cells are just one pixel)</p> <code>True</code> <code>as_output</code> <code>bool</code> <p>If <code>True</code>, the data will have the same format than an output of Sopa</p> <code>False</code> <code>transcript_cell_id_as_merscope</code> <code>bool</code> <p>If <code>True</code>, the cell IDs in the transcripts will start from 0, as in MERSCOPE</p> <code>False</code> <code>add_nan_gene_name</code> <code>bool</code> <p>If <code>True</code>, a NaN value will be added to the gene names for testing purposes</p> <code>False</code> <code>continuous_z_stack</code> <code>bool</code> <p>If <code>True</code>, the z-stack values will be continuous (not integers)</p> <code>False</code> <code>add_second_points_key</code> <code>bool</code> <p>If <code>True</code>, a second points key will be added to the dataset with dummy data for testing purposes</p> <code>False</code> <code>points_3d</code> <code>bool</code> <p>If <code>True</code>, the points will be 3D points instead of 2D points.</p> <code>False</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A SpatialData object with a 2D image (<code>sdata[\"image\"]</code>), the cells polygon boundaries (<code>sdata[\"cells\"]</code>), the transcripts (<code>sdata[\"transcripts\"]</code>), and optional cell vertices (<code>sdata[\"vertices\"]</code>) if <code>include_vertices</code> is <code>True</code>.</p> Source code in <code>sopa/utils/data.py</code> <pre><code>def toy_dataset(\n    *_,\n    length: int = 2_048,\n    cell_density: float = 1e-4,\n    n_points_per_cell: int = 100,\n    c_coords: list[str] = [\"DAPI\", \"CK\", \"CD3\", \"CD20\"],  # noqa: B006\n    genes: int | list[str] = [\"EPCAM\", \"CD3E\", \"CD20\", \"CXCL4\", \"CXCL10\"],  # noqa: B006\n    sigma_factor: float = 0.05,\n    pixel_size: float = 0.1,\n    seed: int = 0,\n    include_vertices: bool = False,\n    include_image: bool = True,\n    include_he_image: bool = True,\n    apply_blur: bool = True,\n    as_output: bool = False,\n    transcript_cell_id_as_merscope: bool = False,\n    add_nan_gene_name: bool = False,\n    continuous_z_stack: bool = False,\n    add_second_points_key: bool = False,\n    points_3d: bool = False,\n) -&gt; SpatialData:\n    \"\"\"Generate a dummy dataset composed of cells generated uniformly in a square. It also has transcripts.\n\n    Args:\n        length: Size of the square, in pixels\n        cell_density: Density of cells per pixel^2\n        n_points_per_cell: Mean number of transcripts per cell\n        c_coords: Channel names\n        genes: Number of different genes, or list of gene names\n        sigma_factor: Factor used to determine `sigma` for the gaussian blur.\n        pixel_size: Number of microns in one pixel.\n        seed: Numpy random seed\n        include_vertices: Whether to include the vertices of the cells (as points) in the spatialdata object\n        include_image: Whether to include the image in the spatialdata object\n        apply_blur: Whether to apply gaussian blur on the image (without blur, cells are just one pixel)\n        as_output: If `True`, the data will have the same format than an output of Sopa\n        transcript_cell_id_as_merscope: If `True`, the cell IDs in the transcripts will start from 0, as in MERSCOPE\n        add_nan_gene_name: If `True`, a NaN value will be added to the gene names for testing purposes\n        continuous_z_stack: If `True`, the z-stack values will be continuous (not integers)\n        add_second_points_key: If `True`, a second points key will be added to the dataset with dummy data for testing purposes\n        points_3d: If `True`, the points will be 3D points instead of 2D points.\n\n    Returns:\n        A SpatialData object with a 2D image (`sdata[\"image\"]`), the cells polygon boundaries (`sdata[\"cells\"]`), the transcripts (`sdata[\"transcripts\"]`), and optional cell vertices (`sdata[\"vertices\"]`) if `include_vertices` is `True`.\n    \"\"\"\n    np.random.seed(seed)\n\n    grid_width = max(1, int(length * np.sqrt(cell_density)))\n    dx = length / grid_width\n    sigma = dx * sigma_factor\n    n_cells = grid_width**2\n    radius = int(dx) // 4\n    cell_types_index = np.random.randint(0, max(1, len(c_coords) - 1), n_cells)\n\n    log.info(\n        f\"Image of size {(len(c_coords), length, length)} with {n_cells} cells and {n_points_per_cell} transcripts per cell\"\n    )\n\n    ### Compute cell vertices (xy array)\n    vertices_x = dx / 2 + np.arange(grid_width) * dx\n    x, y = np.meshgrid(vertices_x, vertices_x)\n    xy = np.stack([x.ravel(), y.ravel()], axis=1)\n    xy += np.random.uniform(-dx / 2, dx / 2, size=xy.shape)\n    xy = xy.clip(0, length - 1).astype(int)\n\n    vertices = pd.DataFrame(xy, columns=[\"x\", \"y\"])\n\n    ### Create images\n    images = {}\n\n    if include_image:\n        x_circle, y_circle = _circle_coords(radius)\n\n        image = np.zeros((len(c_coords), length, length))\n        for i, (x, y) in enumerate(xy):\n            y_coords = (y + y_circle).clip(0, image.shape[1] - 1)\n            x_coords = (x + x_circle).clip(0, image.shape[2] - 1)\n            image[0, y_coords, x_coords] = 1\n            if len(c_coords) &gt; 1:\n                image[cell_types_index[i] + 1, y_coords, x_coords] = 1\n        if apply_blur:\n            image = gaussian_filter(image, sigma=sigma, axes=(1, 2))\n        image = (image / image.max() * 255).astype(np.uint8)\n        image = da.from_array(image, chunks=(1, 1024, 1024))\n        images[\"image\"] = Image2DModel.parse(image, c_coords=c_coords, dims=[\"c\", \"y\", \"x\"])\n\n    if include_he_image:\n        he_image = _he_image(length // 2)\n        scale = length / (length // 2)\n        images[\"he_image\"] = Image2DModel.parse(\n            he_image,\n            dims=[\"c\", \"y\", \"x\"],\n            transformations={\"global\": Scale([scale, scale], axes=[\"x\", \"y\"])},\n            scale_factors=[2, 2],\n        )\n\n    ### Create cell boundaries\n    cells = [Point(vertex).buffer(radius).simplify(tolerance=1) for vertex in xy]\n    bbox = box(0, 0, length - 1, length - 1)\n    cells = [cell.intersection(bbox) for cell in cells]\n    gdf = gpd.GeoDataFrame(geometry=cells)\n    shapes_key = \"cellpose_boundaries\" if as_output else \"cells\"\n    shapes = {shapes_key: ShapesModel.parse(gdf)}\n\n    ### Create transcripts\n    n_genes = n_cells * n_points_per_cell\n    point_cell_index = np.arange(n_cells).repeat(n_points_per_cell)\n    points_coords = radius / 2 * np.random.randn(n_genes, 2) + xy[point_cell_index]\n    points_coords = points_coords.clip(0, length - 1)\n\n    if isinstance(genes, int):\n        gene_names = np.random.choice([f\"gene_{i}\" for i in range(genes)], size=n_genes)\n    elif len(genes) and len(genes) &gt;= len(c_coords) - 1:\n        gene_names = np.full(n_genes, \"\", dtype=\"&lt;U5\")\n        for i in range(len(genes)):\n            where_cell_type = np.where(cell_types_index[point_cell_index] == i)[0]\n            probabilities = np.full(len(genes), 0.2 / (len(genes) - 1))\n            probabilities[i] = 0.8\n            gene_names[where_cell_type] = np.random.choice(genes, len(where_cell_type), p=probabilities)\n    else:\n        gene_names = np.random.choice(genes, size=n_genes)\n\n    gene_names = gene_names.astype(object)\n    if add_nan_gene_name:\n        gene_names[3] = np.nan  # Add a nan value for tests\n        gene_names[4] = \"blank\"  # Add a blank value for tests\n\n    z_stack = seed + np.random.randint(-1, 2, len(points_coords))\n    if continuous_z_stack:\n        z_stack = z_stack + np.random.randn(len(points_coords)) / 10\n\n    df = pd.DataFrame({\n        \"x\": points_coords[:, 0],\n        \"y\": points_coords[:, 1],\n        (\"z\" if points_3d else \"z_stack\"): z_stack,\n        \"genes\": gene_names,\n    })\n\n    # apply an arbritrary transformation for a more complete test case\n    affine = np.array([[pixel_size, 0, 100], [0, pixel_size, 600], [0, 0, 1]])\n    df[[\"x\", \"y\"]] = df[[\"x\", \"y\"]] @ affine[:2, :2].T + affine[:2, 2]\n    affine = Affine(affine, input_axes=[\"x\", \"y\"], output_axes=[\"x\", \"y\"]).inverse()\n\n    df = dd.from_pandas(df, chunksize=2_000_000)\n\n    points = {\n        \"transcripts\": PointsModel.parse(\n            df, transformations={\"global\": affine, \"microns\": Identity()}, feature_key=\"genes\"\n        ),\n    }\n\n    if add_second_points_key:\n        misc_df = pd.DataFrame({\"x\": [0, 1], \"y\": [0, 1]})  # dummy dataframe for testing purposes\n        points[\"misc\"] = PointsModel.parse(misc_df, transformations={\"global\": Identity()})\n\n    if include_vertices:\n        points[\"vertices\"] = PointsModel.parse(vertices)\n\n    sdata = SpatialData(\n        images=images,\n        points=points,\n        shapes=shapes,\n        attrs={SopaAttrs.TRANSCRIPTS: \"transcripts\", SopaAttrs.PRIOR_TUPLE_KEY: (\"cell_id\", 0)},\n    )\n\n    if include_image:\n        sdata.attrs[SopaAttrs.CELL_SEGMENTATION] = \"image\"\n\n    if include_he_image:\n        sdata.attrs[SopaAttrs.TISSUE_SEGMENTATION] = \"he_image\"\n\n    from ..spatial import assign_transcript_to_cell\n\n    assign_transcript_to_cell(sdata, \"transcripts\", shapes_key, \"cell_id\", unassigned_value=0)\n\n    sdata[\"transcripts\"][\"cell_id\"] = sdata[\"transcripts\"][\"cell_id\"].astype(int) - int(transcript_cell_id_as_merscope)\n\n    if as_output:\n        _add_table(sdata)\n\n    return sdata\n</code></pre>"},{"location":"api/segmentation/","title":"Segmentation","text":""},{"location":"api/segmentation/#cell-segmentation","title":"Cell segmentation","text":""},{"location":"api/segmentation/#sopa.segmentation.cellpose","title":"<code>sopa.segmentation.cellpose(sdata, channels, diameter, model_type='cyto3', pretrained_model=None, gpu=False, image_key=None, min_area=None, delete_cache=True, recover=False, flow_threshold=2, cellprob_threshold=-6, clip_limit=0.2, clahe_kernel_size=None, gaussian_sigma=1, key_added=SopaKeys.CELLPOSE_BOUNDARIES, cellpose_model_kwargs=None, **cellpose_eval_kwargs)</code>","text":"<p>Run Cellpose segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.</p> <p>Cellpose installation</p> <p>Make sure to install the cellpose extra (<code>pip install 'sopa[cellpose]'</code>) for this method to work.</p> <p>Diameter parameter</p> <p>The <code>diameter</code> parameter is used to estimate the expected cell diameter (in pixels). This is a crucial parameter for the segmentation.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>channels</code> <code>list[str] | str</code> <p>Name of the channel(s) to be used for segmentation. If one channel, must be a nucleus channel. If a <code>list</code> of channels, it must be a cytoplasmic channel and then a nucleus channel.</p> required <code>diameter</code> <code>int</code> <p>The Cellpose parameter for the expected cell diameter (in pixel).</p> required <code>model_type</code> <code>str</code> <p>Cellpose model type.</p> <code>'cyto3'</code> <code>pretrained_model</code> <code>str | None</code> <p>Path to the pretrained model to be loaded, or <code>None</code></p> <code>None</code> <code>gpu</code> <code>bool</code> <p>Whether to use GPU for segmentation.</p> <code>False</code> <code>image_key</code> <code>str | None</code> <p>Name of the image in <code>sdata</code> to be used for segmentation.</p> <code>None</code> <code>min_area</code> <code>int | None</code> <p>Minimum area of a cell to be considered. By default, it is calculated based on the <code>diameter</code> parameter.</p> <code>None</code> <code>delete_cache</code> <code>bool</code> <p>Whether to delete the cache after segmentation.</p> <code>True</code> <code>recover</code> <code>bool</code> <p>If <code>True</code>, recover the cache from a failed segmentation, and continue.</p> <code>False</code> <code>flow_threshold</code> <code>float</code> <p>Cellpose <code>flow_threshold</code> parameter.</p> <code>2</code> <code>cellprob_threshold</code> <code>float</code> <p>Cellpose <code>cellprob_threshold</code> parameter.</p> <code>-6</code> <code>clip_limit</code> <code>float</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)</p> <code>0.2</code> <code>clahe_kernel_size</code> <code>int | list[int] | None</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)</p> <code>None</code> <code>gaussian_sigma</code> <code>float</code> <p>Parameter for scipy gaussian_filter (applied before running cellpose)</p> <code>1</code> <code>key_added</code> <code>str</code> <p>Name of the shapes element to be added to <code>sdata</code>.</p> <code>CELLPOSE_BOUNDARIES</code> <code>cellpose_model_kwargs</code> <code>dict | None</code> <p>Dictionary of kwargs to be provided to the <code>cellpose.models.CellposeModel</code> object.</p> <code>None</code> <code>**cellpose_eval_kwargs</code> <code>int</code> <p>Kwargs to be provided to <code>model.eval</code> (where <code>model</code> is a <code>cellpose.models.CellposeModel</code> object)</p> <code>{}</code> Source code in <code>sopa/segmentation/methods/_cellpose.py</code> <pre><code>def cellpose(\n    sdata: SpatialData,\n    channels: list[str] | str,\n    diameter: int,\n    model_type: str = \"cyto3\",\n    pretrained_model: str | None = None,\n    gpu: bool = False,\n    image_key: str | None = None,\n    min_area: int | None = None,\n    delete_cache: bool = True,\n    recover: bool = False,\n    flow_threshold: float = 2,\n    cellprob_threshold: float = -6,\n    clip_limit: float = 0.2,\n    clahe_kernel_size: int | list[int] | None = None,\n    gaussian_sigma: float = 1,\n    key_added: str = SopaKeys.CELLPOSE_BOUNDARIES,\n    cellpose_model_kwargs: dict | None = None,\n    **cellpose_eval_kwargs: int,\n):\n    \"\"\"Run [Cellpose](https://cellpose.readthedocs.io/en/latest/) segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.\n\n    !!! warning \"Cellpose installation\"\n        Make sure to install the cellpose extra (`pip install 'sopa[cellpose]'`) for this method to work.\n\n    !!! info \"Diameter parameter\"\n        The `diameter` parameter is used to estimate the expected cell diameter (in pixels). This is a crucial parameter for the segmentation.\n\n    Args:\n        sdata: A `SpatialData` object\n        channels: Name of the channel(s) to be used for segmentation. If one channel, must be a nucleus channel. If a `list` of channels, it must be a cytoplasmic channel and then a nucleus channel.\n        diameter: The Cellpose parameter for the expected cell diameter (in pixel).\n        model_type: Cellpose model type.\n        pretrained_model: Path to the pretrained model to be loaded, or `None`\n        gpu: Whether to use GPU for segmentation.\n        image_key: Name of the image in `sdata` to be used for segmentation.\n        min_area: Minimum area of a cell to be considered. By default, it is calculated based on the `diameter` parameter.\n        delete_cache: Whether to delete the cache after segmentation.\n        recover: If `True`, recover the cache from a failed segmentation, and continue.\n        flow_threshold: Cellpose `flow_threshold` parameter.\n        cellprob_threshold: Cellpose `cellprob_threshold` parameter.\n        clip_limit: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)\n        clahe_kernel_size: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)\n        gaussian_sigma: Parameter for scipy gaussian_filter (applied before running cellpose)\n        key_added: Name of the shapes element to be added to `sdata`.\n        cellpose_model_kwargs: Dictionary of kwargs to be provided to the `cellpose.models.CellposeModel` object.\n        **cellpose_eval_kwargs: Kwargs to be provided to `model.eval` (where `model` is a `cellpose.models.CellposeModel` object)\n    \"\"\"\n    channels = channels if isinstance(channels, list) else [channels]\n\n    method = cellpose_patch(\n        diameter=diameter,\n        channels=channels,\n        model_type=model_type,\n        pretrained_model=pretrained_model,\n        gpu=gpu,\n        flow_threshold=flow_threshold,\n        cellprob_threshold=cellprob_threshold,\n        cellpose_model_kwargs=cellpose_model_kwargs,\n        **cellpose_eval_kwargs,\n    )\n\n    if min_area is None:\n        min_area = (diameter / 2) ** 2  # by default, about 15% of the \"normal cell\" area\n\n    custom_staining_based(\n        sdata,\n        method,\n        channels,\n        image_key=image_key,\n        min_area=min_area,\n        delete_cache=delete_cache,\n        recover=recover,\n        clip_limit=clip_limit,\n        clahe_kernel_size=clahe_kernel_size,\n        gaussian_sigma=gaussian_sigma,\n        cache_dir_name=key_added,\n        key_added=key_added,\n    )\n</code></pre>"},{"location":"api/segmentation/#sopa.segmentation.stardist","title":"<code>sopa.segmentation.stardist(sdata, model_type='2D_versatile_he', image_key=None, channels=None, min_area=0, delete_cache=True, recover=False, prob_thresh=0.2, nms_thresh=0.6, clip_limit=0, clahe_kernel_size=None, gaussian_sigma=0, key_added=SopaKeys.STARDIST_BOUNDARIES, **stardist_eval_kwargs)</code>","text":"<p>Run Stardist segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.</p> <p>Stardist installation</p> <p>Make sure to install the stardist extra (<code>pip install 'sopa[stardist]'</code>) for this method to work.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>model_type</code> <code>str</code> <p>Stardist model name.</p> <code>'2D_versatile_he'</code> <code>image_key</code> <code>str | None</code> <p>Name of the image in <code>sdata</code> to be used for segmentation.</p> <code>None</code> <code>channels</code> <code>list[str] | str | None</code> <p>One or a list of channel names used for segmentation. None assumes RGB image.</p> <code>None</code> <code>min_area</code> <code>int</code> <p>Minimum area of a cell to be considered.</p> <code>0</code> <code>delete_cache</code> <code>bool</code> <p>Whether to delete the cache after segmentation.</p> <code>True</code> <code>recover</code> <code>bool</code> <p>If <code>True</code>, recover the cache from a failed segmentation, and continue.</p> <code>False</code> <code>prob_thresh</code> <code>float</code> <p>Stardist <code>prob_thresh</code> parameter.</p> <code>0.2</code> <code>nms_thresh</code> <code>float</code> <p>Stardist <code>nms_thresh</code> parameter.</p> <code>0.6</code> <code>clip_limit</code> <code>float</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running stardist)</p> <code>0</code> <code>clahe_kernel_size</code> <code>int | list[int] | None</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running stardist)</p> <code>None</code> <code>gaussian_sigma</code> <code>float</code> <p>Parameter for scipy gaussian_filter (applied before running stardist)</p> <code>0</code> <code>key_added</code> <code>str</code> <p>Name of the shapes element to be added to <code>sdata</code>.</p> <code>STARDIST_BOUNDARIES</code> <code>**stardist_eval_kwargs</code> <code>int</code> <p>Kwargs to be provided to <code>model.predict_instances</code> (where <code>model</code> is a <code>stardist.models.StarDist2D</code> object)</p> <code>{}</code> Source code in <code>sopa/segmentation/methods/_stardist.py</code> <pre><code>def stardist(\n    sdata: SpatialData,\n    model_type: str = \"2D_versatile_he\",\n    image_key: str | None = None,\n    channels: list[str] | str | None = None,\n    min_area: int = 0,\n    delete_cache: bool = True,\n    recover: bool = False,\n    prob_thresh: float = 0.2,\n    nms_thresh: float = 0.6,\n    clip_limit: float = 0,\n    clahe_kernel_size: int | list[int] | None = None,\n    gaussian_sigma: float = 0,\n    key_added: str = SopaKeys.STARDIST_BOUNDARIES,\n    **stardist_eval_kwargs: int,\n):\n    \"\"\"Run [Stardist](https://github.com/stardist/stardist) segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.\n\n    !!! warning \"Stardist installation\"\n        Make sure to install the stardist extra (`pip install 'sopa[stardist]'`) for this method to work.\n\n    Args:\n        sdata: A `SpatialData` object\n        model_type: Stardist model name.\n        image_key: Name of the image in `sdata` to be used for segmentation.\n        channels: One or a list of channel names used for segmentation. None assumes RGB image.\n        min_area: Minimum area of a cell to be considered.\n        delete_cache: Whether to delete the cache after segmentation.\n        recover: If `True`, recover the cache from a failed segmentation, and continue.\n        prob_thresh: Stardist `prob_thresh` parameter.\n        nms_thresh: Stardist `nms_thresh` parameter.\n        clip_limit: Parameter for skimage.exposure.equalize_adapthist (applied before running stardist)\n        clahe_kernel_size: Parameter for skimage.exposure.equalize_adapthist (applied before running stardist)\n        gaussian_sigma: Parameter for scipy gaussian_filter (applied before running stardist)\n        key_added: Name of the shapes element to be added to `sdata`.\n        **stardist_eval_kwargs: Kwargs to be provided to `model.predict_instances` (where `model` is a `stardist.models.StarDist2D` object)\n    \"\"\"\n    method = stardist_patch(\n        model_type=model_type,\n        prob_thresh=prob_thresh,\n        nms_thresh=nms_thresh,\n        **stardist_eval_kwargs,\n    )\n\n    custom_staining_based(\n        sdata,\n        method,\n        channels=channels,\n        image_key=image_key,\n        min_area=min_area,\n        delete_cache=delete_cache,\n        recover=recover,\n        clip_limit=clip_limit,\n        clahe_kernel_size=clahe_kernel_size,\n        gaussian_sigma=gaussian_sigma,\n        cache_dir_name=key_added,\n        key_added=key_added,\n    )\n</code></pre>"},{"location":"api/segmentation/#sopa.segmentation.baysor","title":"<code>sopa.segmentation.baysor(sdata, config=None, min_area=0, delete_cache=True, recover=False, force=False, scale=None, key_added=SopaKeys.BAYSOR_BOUNDARIES, patch_index=None)</code>","text":"<p>Run Baysor segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.</p> <p>Baysor installation</p> <p>Make sure to install Baysor, and either have the executable at <code>~/.julia/bin/baysor</code>, or create an alias called <code>baysor</code> that points to the binary executable. Also, you'll need to install sopa with the baysor extra: <code>pip install 'sopa[baysor]'</code> (basically, this installs <code>toml</code> and <code>loompy</code>).</p> <p>Inferred config</p> <p>If the <code>config</code> argument is not provided, the configuration is inferred. If sopa.make_transcript_patches was run with a <code>prior_shapes_key</code>, the configuration is inferred based on the prior segmentation. Otherwise, the configuration is inferred based on the <code>scale</code> parameter (you'll need to provide it).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>config</code> <code>dict | str | None</code> <p>Optional configuration dictionary or path to a TOML file containing a valid Baysor config. By default, a configuration is inferred based on the cell area of the prior segmentation, or based on the <code>scale</code> parameter.</p> <code>None</code> <code>min_area</code> <code>int</code> <p>Minimal area (in microns^2) of a cell to be considered.</p> <code>0</code> <code>delete_cache</code> <code>bool</code> <p>Whether to delete the cache after segmentation.</p> <code>True</code> <code>recover</code> <code>bool</code> <p>If <code>True</code>, recover the cache from a failed segmentation, and continue.</p> <code>False</code> <code>force</code> <code>bool</code> <p>If <code>True</code>, ignore failed patches and continue with the successful ones.</p> <code>False</code> <code>scale</code> <code>float | None</code> <p>The typical cell radius in microns. If <code>config</code> is not provided, the configuration is inferred based on this parameter. Else, it will overwrite the existing scale in the config.</p> <code>None</code> <code>key_added</code> <code>str</code> <p>Name of the shapes element to be added to <code>sdata.shapes</code>.</p> <code>BAYSOR_BOUNDARIES</code> <code>patch_index</code> <code>int | None</code> <p>Index of the patch to segment (we do not recommend to set this argument). By default, segment all patches.</p> <code>None</code> Source code in <code>sopa/segmentation/methods/_baysor.py</code> <pre><code>def baysor(\n    sdata: SpatialData,\n    config: dict | str | None = None,\n    min_area: int = 0,\n    delete_cache: bool = True,\n    recover: bool = False,\n    force: bool = False,\n    scale: float | None = None,\n    key_added: str = SopaKeys.BAYSOR_BOUNDARIES,\n    patch_index: int | None = None,\n):\n    \"\"\"Run [Baysor](https://kharchenkolab.github.io/Baysor/dev/) segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.\n\n    !!! warning \"Baysor installation\"\n        Make sure to install [Baysor](https://kharchenkolab.github.io/Baysor/dev/installation/), and either have the executable at `~/.julia/bin/baysor`, or create an alias called\n        `baysor` that points to the binary executable. Also, you'll need to install\n        sopa with the baysor extra: `pip install 'sopa[baysor]'` (basically, this installs `toml` and `loompy`).\n\n    !!! info \"Inferred config\"\n        If the `config` argument is not provided, the configuration is inferred.\n        If [sopa.make_transcript_patches][] was run with a `prior_shapes_key`, the configuration is inferred based on the prior segmentation.\n        Otherwise, the configuration is inferred based on the `scale` parameter (you'll need to provide it).\n\n    Args:\n        sdata: A `SpatialData` object.\n        config: Optional configuration dictionary or path to a TOML file containing a valid Baysor config. By default, a configuration is inferred based on the cell area of the prior segmentation, or based on the `scale` parameter.\n        min_area: Minimal area (in microns^2) of a cell to be considered.\n        delete_cache: Whether to delete the cache after segmentation.\n        recover: If `True`, recover the cache from a failed segmentation, and continue.\n        force: If `True`, ignore failed patches and continue with the successful ones.\n        scale: The typical cell radius in microns. If `config` is not provided, the configuration is inferred based on this parameter. Else, it will overwrite the existing scale in the config.\n        key_added: Name of the shapes element to be added to `sdata.shapes`.\n        patch_index: Index of the patch to segment (we do not recommend to set this argument). By default, segment all patches.\n    \"\"\"\n    _check_transcript_patches(sdata)\n\n    prior_shapes_key = (\n        SopaKeys.SOPA_PRIOR if SopaKeys.PRIOR_SHAPES_KEY in sdata.shapes[SopaKeys.TRANSCRIPTS_PATCHES] else None\n    )\n\n    if config is None or not len(config):\n        config = _get_default_config(sdata, prior_shapes_key, scale)\n    elif scale is not None:\n        assert \"segmentation\" in config, \"The provided config should contain a 'segmentation' key\"\n        config[\"segmentation\"][\"scale\"] = scale\n\n    assert \"data\" in config, \"The provided config should contain a 'data' key\"\n\n    if \"gene\" not in config[\"data\"]:\n        config[\"data\"][\"gene\"] = str(get_feature_key(sdata, raise_error=True))\n\n    if \"scale\" in config[\"segmentation\"] and config[\"segmentation\"][\"scale\"] &gt;= 20:\n        log.warning(\n            f\"The provided scale ({config['segmentation']['scale']}) seems large. Make sure the scale is in microns, and not in pixels. If you are using CosMX data, note that the transcripts coordinates are now in microns.\"\n        )\n\n    baysor_command = _get_baysor_command(prior_shapes_key)\n\n    baysor_patch = BaysorPatch(baysor_command, config, force=force, capture_output=patch_index is None)\n\n    if patch_index is not None:\n        patch_dir = get_transcripts_patches_dirs(sdata, patch_index)\n        baysor_patch(patch_dir)\n        return\n\n    patches_dirs = get_transcripts_patches_dirs(sdata)\n\n    remaining_patches_dirs = (\n        [patch_dir for patch_dir in patches_dirs if not (patch_dir / \"segmentation_counts.loom\").exists()]\n        if recover\n        else patches_dirs\n    )\n\n    settings._run_with_backend([partial(baysor_patch, patch_dir) for patch_dir in remaining_patches_dirs])\n\n    if force:\n        patches_dirs = [patch_dir for patch_dir in patches_dirs if (patch_dir / \"segmentation_counts.loom\").exists()]\n        assert patches_dirs, \"Baysor failed on all patches\"\n\n    resolve(sdata, patches_dirs, gene_column=config[\"data\"][\"gene\"], min_area=min_area, key_added=key_added)\n\n    set_boundaries_attrs(sdata, key_added)\n\n    if delete_cache:\n        delete_transcripts_patches_dirs(sdata)\n</code></pre>"},{"location":"api/segmentation/#sopa.segmentation.comseg","title":"<code>sopa.segmentation.comseg(sdata, config=None, min_area=0, delete_cache=True, recover=False, key_added=SopaKeys.COMSEG_BOUNDARIES, patch_index=None)</code>","text":"<p>Run ComSeg segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.</p> <p>ComSeg installation</p> <p>Make sure to install ComSeg (<code>pip install comseg</code>) for this method to work.</p> <p>Transcript patches</p> <p>To use ComSeg, make sure to run sopa.make_transcript_patches with a <code>prior_shapes_key</code> and <code>write_cells_centroids=True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>config</code> <code>dict | str | None</code> <p>Optional configuration dictionary or path to a JSON file containing a valid ComSeg config. By default, a configuration is inferred based on the cell area of the prior segmentation.</p> <code>None</code> <code>min_area</code> <code>float</code> <p>Minimal area (in microns^2) of a cell to be considered.</p> <code>0</code> <code>delete_cache</code> <code>bool</code> <p>Whether to delete the cache after segmentation.</p> <code>True</code> <code>recover</code> <code>bool</code> <p>If <code>True</code>, recover the cache from a failed segmentation, and continue.</p> <code>False</code> <code>key_added</code> <code>str</code> <p>Name of the shapes element to be added to <code>sdata</code>.</p> <code>COMSEG_BOUNDARIES</code> <code>patch_index</code> <code>int | None</code> <p>Index of the patch to segment (we do not recommend to set this argument). By default, segment all patches.</p> <code>None</code> Source code in <code>sopa/segmentation/methods/_comseg.py</code> <pre><code>def comseg(\n    sdata: SpatialData,\n    config: dict | str | None = None,\n    min_area: float = 0,\n    delete_cache: bool = True,\n    recover: bool = False,\n    key_added: str = SopaKeys.COMSEG_BOUNDARIES,\n    patch_index: int | None = None,\n):\n    \"\"\"Run [ComSeg](https://comseg.readthedocs.io/en/latest/) segmentation on a SpatialData object, and add a GeoDataFrame containing the cell boundaries.\n\n    !!! warning \"ComSeg installation\"\n        Make sure to install ComSeg (`pip install comseg`) for this method to work.\n\n    !!! info \"Transcript patches\"\n        To use ComSeg, make sure to run [sopa.make_transcript_patches][] with a `prior_shapes_key` and `write_cells_centroids=True`.\n\n    Args:\n        sdata: A `SpatialData` object.\n        config: Optional configuration dictionary or path to a JSON file containing a valid ComSeg config. By default, a configuration is inferred based on the cell area of the prior segmentation.\n        min_area: Minimal area (in microns^2) of a cell to be considered.\n        delete_cache: Whether to delete the cache after segmentation.\n        recover: If `True`, recover the cache from a failed segmentation, and continue.\n        key_added: Name of the shapes element to be added to `sdata`.\n        patch_index: Index of the patch to segment (we do not recommend to set this argument). By default, segment all patches.\n    \"\"\"\n    _check_transcript_patches(sdata, with_prior=True)\n\n    if config is None or not len(config):\n        config = _get_default_config(sdata, sdata.shapes[SopaKeys.TRANSCRIPTS_PATCHES])\n    elif isinstance(config, str):\n        with open(config) as f:\n            config = json.load(f)\n\n    if \"gene_column\" not in config:\n        config[\"gene_column\"] = str(get_feature_key(sdata, raise_error=True))\n\n    config[\"prior_name\"] = SopaKeys.SOPA_PRIOR\n\n    if patch_index is not None:\n        patch_dir = get_transcripts_patches_dirs(sdata, patch_index)\n        comseg_patch(patch_dir, config, recover)\n        return\n\n    patches_dirs = get_transcripts_patches_dirs(sdata)\n\n    _functions = [partial(comseg_patch, patch_dir, config, recover) for patch_dir in patches_dirs]\n    settings._run_with_backend(_functions)\n\n    resolve(sdata, patches_dirs, config[\"gene_column\"], min_area=min_area, key_added=key_added)\n\n    set_boundaries_attrs(sdata, key_added)\n\n    if delete_cache:\n        delete_transcripts_patches_dirs(sdata)\n</code></pre>"},{"location":"api/segmentation/#sopa.segmentation.proseg","title":"<code>sopa.segmentation.proseg(sdata, delete_cache=True, command_line_suffix='', infer_presets=True, prior_shapes_key=None, bins_key=None, key_added=SopaKeys.PROSEG_BOUNDARIES)</code>","text":"<p>Run <code>proseg</code> segmentation on a SpatialData object, and add the corresponding cell boundaries and <code>AnnData</code> table with counts.</p> <p>Proseg installation</p> <p>Make sure to install <code>proseg</code> separately before running this function.</p> <p>Proseg usage specificities</p> <p>If you are using Visium HD data, provide the <code>prior_shapes_key</code> corresponding to the prior cell boundaries (e.g., <code>\"stardist_boundaries\"</code>).</p> <p>If you're using non-Visium HD data, note that <code>proseg</code> will only run on one patch. I.e., you need to run <code>sopa.make_transcript_patches</code> with <code>patch_width=None</code> and a <code>prior_shapes_key</code> before running <code>proseg</code>.</p> <p>Also, note that aggregation is not necessary after running <code>proseg</code> (but can be useful if you want e.g. channel aggregation).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>delete_cache</code> <code>bool</code> <p>Whether to delete the cache after segmentation.</p> <code>True</code> <code>command_line_suffix</code> <code>str</code> <p>Optional suffix to add to the proseg command line.</p> <code>''</code> <code>infer_presets</code> <code>bool</code> <p>Whether to infer the proseg presets based on the columns of the transcripts dataframe.</p> <code>True</code> <code>prior_shapes_key</code> <code>str | None</code> <p>Only for Visium HD data. Key of <code>sdata</code> containing the prior cell boundaries. If <code>\"auto\"</code>, use the latest performed segmentation (e.g., stardist or the 10X Genomics segmentation).</p> <code>None</code> <code>bins_key</code> <code>str | None</code> <p>Only for Visium HD data. Key of <code>sdata</code> with the table corresponding to the bin-by-gene table of gene counts (e.g., for Visium HD data). Inferred by default.</p> <code>None</code> <code>key_added</code> <code>str</code> <p>Name of the shapes element to be added to <code>sdata.shapes</code>.</p> <code>PROSEG_BOUNDARIES</code> Source code in <code>sopa/segmentation/methods/_proseg.py</code> <pre><code>def proseg(\n    sdata: SpatialData,\n    delete_cache: bool = True,\n    command_line_suffix: str = \"\",\n    infer_presets: bool = True,\n    prior_shapes_key: str | None = None,\n    bins_key: str | None = None,\n    key_added: str = SopaKeys.PROSEG_BOUNDARIES,\n):\n    \"\"\"Run [`proseg`](https://github.com/dcjones/proseg) segmentation on a SpatialData object, and add the corresponding cell boundaries and `AnnData` table with counts.\n\n    !!! warning \"Proseg installation\"\n        Make sure to install [`proseg`](https://github.com/dcjones/proseg) separately before running this function.\n\n    !!! info \"Proseg usage specificities\"\n        If you are using Visium HD data, provide the `prior_shapes_key` corresponding to the prior cell boundaries (e.g., `\"stardist_boundaries\"`).\n\n        If you're using non-Visium HD data, note that `proseg` will only run on one patch. I.e., you need\n        to run [`sopa.make_transcript_patches`](../patches/#sopa.make_transcript_patches) with `patch_width=None` and a `prior_shapes_key` before running `proseg`.\n\n        Also, note that aggregation is not necessary after running `proseg` (but can be useful if you want e.g. channel aggregation).\n\n    Args:\n        sdata: A `SpatialData` object.\n        delete_cache: Whether to delete the cache after segmentation.\n        command_line_suffix: Optional suffix to add to the proseg command line.\n        infer_presets: Whether to infer the proseg presets based on the columns of the transcripts dataframe.\n        prior_shapes_key: **Only for Visium HD data.** Key of `sdata` containing the prior cell boundaries. If `\"auto\"`, use the latest performed segmentation (e.g., stardist or the 10X Genomics segmentation).\n        bins_key: **Only for Visium HD data.** Key of `sdata` with the table corresponding to the bin-by-gene table of gene counts (e.g., for Visium HD data). Inferred by default.\n        key_added: Name of the shapes element to be added to `sdata.shapes`.\n    \"\"\"\n    if prior_shapes_key is not None:\n        bins_key = bins_key or sdata.attrs.get(SopaAttrs.BINS_TABLE)\n\n        assert bins_key is not None, (\n            \"Using `prior_shapes_key` is specific to Visium HD data, and a `bins_key` must be provided.\"\n        )\n\n        _proseg_bins(\n            sdata,\n            prior_shapes_key=prior_shapes_key,\n            bins_key=bins_key,\n            command_line_suffix=command_line_suffix,\n            infer_presets=infer_presets,\n            key_added=key_added,\n        )\n    else:\n        assert sdata.points, (\n            \"No points found in `sdata`. If you use Visium HD data, consider providing a `prior_shapes_key`.\"\n        )\n        assert bins_key is None, (\n            \"`bins_key` can only be provided when using `prior_shapes_key` (i.e., for Visium HD data).\"\n        )\n\n        _proseg_points(\n            sdata,\n            delete_cache=delete_cache,\n            command_line_suffix=command_line_suffix,\n            infer_presets=infer_presets,\n            key_added=key_added,\n        )\n\n    log.info(\"Proseg table and boundaries added (running `sopa.aggregate` is not mandatory).\")\n</code></pre>"},{"location":"api/segmentation/#sopa.segmentation.custom_staining_based","title":"<code>sopa.segmentation.custom_staining_based(sdata, method, channels, image_key=None, min_area=0, delete_cache=True, recover=False, clip_limit=0.2, clahe_kernel_size=None, gaussian_sigma=1, cache_dir_name=SopaKeys.CUSTOM_BOUNDARIES, key_added=SopaKeys.CUSTOM_BOUNDARIES, min_patch_size=10)</code>","text":"<p>Run a generic staining-based segmentation model, and add a GeoDataFrame containing the cell boundaries.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>method</code> <code>Callable</code> <p>A segmentation <code>callable</code> whose input is an image of shape <code>(C, Y, X)</code> and output is a cell mask of shape <code>(Y, X)</code>. Each mask value <code>&gt;0</code> represent a unique cell ID. The <code>C</code> channels is determined by the <code>channels</code> argument.</p> required <code>channels</code> <code>list[str] | str | None</code> <p>Name of the channels to be used for segmentation (or list of channel names).</p> required <code>image_key</code> <code>str | None</code> <p>Name of the image in <code>sdata</code> to be used for segmentation.</p> <code>None</code> <code>min_area</code> <code>float</code> <p>Minimum area of a cell to be considered.</p> <code>0</code> <code>delete_cache</code> <code>bool</code> <p>Whether to delete the cache after segmentation.</p> <code>True</code> <code>recover</code> <code>bool</code> <p>If <code>True</code>, recover the cache from a failed segmentation, and continue.</p> <code>False</code> <code>clip_limit</code> <code>float</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running segmentation)</p> <code>0.2</code> <code>clahe_kernel_size</code> <code>int | list[int] | None</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running segmentation)</p> <code>None</code> <code>gaussian_sigma</code> <code>float</code> <p>Parameter for scipy gaussian_filter (applied before running segmentation)</p> <code>1</code> <code>cache_dir_name</code> <code>str</code> <p>Name of the cache directory.</p> <code>CUSTOM_BOUNDARIES</code> <code>key_added</code> <code>str</code> <p>Name of the key to be added to <code>sdata.shapes</code>.</p> <code>CUSTOM_BOUNDARIES</code> <code>min_patch_size</code> <code>int</code> <p>Minimum patch size (in pixels) for both width and height. Patches smaller than this will be skipped to avoid segmentation errors.</p> <code>10</code> Source code in <code>sopa/segmentation/methods/_custom.py</code> <pre><code>def custom_staining_based(\n    sdata: SpatialData,\n    method: Callable,\n    channels: list[str] | str | None,\n    image_key: str | None = None,\n    min_area: float = 0,\n    delete_cache: bool = True,\n    recover: bool = False,\n    clip_limit: float = 0.2,\n    clahe_kernel_size: int | list[int] | None = None,\n    gaussian_sigma: float = 1,\n    cache_dir_name: str = SopaKeys.CUSTOM_BOUNDARIES,\n    key_added: str = SopaKeys.CUSTOM_BOUNDARIES,\n    min_patch_size: int = 10,\n):\n    \"\"\"Run a generic staining-based segmentation model, and add a GeoDataFrame containing the cell boundaries.\n\n    Args:\n        sdata: A `SpatialData` object.\n        method: A segmentation `callable` whose input is an image of shape `(C, Y, X)` and output is a cell mask of shape `(Y, X)`. Each mask value `&gt;0` represent a unique cell ID. The `C` channels is determined by the `channels` argument.\n        channels: Name of the channels to be used for segmentation (or list of channel names).\n        image_key: Name of the image in `sdata` to be used for segmentation.\n        min_area: Minimum area of a cell to be considered.\n        delete_cache: Whether to delete the cache after segmentation.\n        recover: If `True`, recover the cache from a failed segmentation, and continue.\n        clip_limit: Parameter for skimage.exposure.equalize_adapthist (applied before running segmentation)\n        clahe_kernel_size: Parameter for skimage.exposure.equalize_adapthist (applied before running segmentation)\n        gaussian_sigma: Parameter for scipy gaussian_filter (applied before running segmentation)\n        cache_dir_name: Name of the cache directory.\n        key_added: Name of the key to be added to `sdata.shapes`.\n        min_patch_size: Minimum patch size (in pixels) for both width and height. Patches smaller than this will be skipped to avoid segmentation errors.\n    \"\"\"\n    temp_dir = get_cache_dir(sdata) / cache_dir_name\n\n    segmentation = StainingSegmentation(\n        sdata,\n        method,\n        channels,\n        min_area=min_area,\n        image_key=image_key,\n        clip_limit=clip_limit,\n        clahe_kernel_size=clahe_kernel_size,\n        gaussian_sigma=gaussian_sigma,\n        min_patch_size=min_patch_size,\n    )\n    segmentation.write_patches_cells(temp_dir, recover=recover)\n\n    cells = StainingSegmentation.read_patches_cells(temp_dir)\n    cells = solve_conflicts(cells)\n\n    StainingSegmentation.add_shapes(sdata, cells, image_key=segmentation.image_key, key_added=key_added)\n\n    set_boundaries_attrs(sdata, key_added)\n\n    if delete_cache:\n        shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"api/segmentation/#tissue-segmentation","title":"Tissue segmentation","text":""},{"location":"api/segmentation/#sopa.segmentation.tissue","title":"<code>sopa.segmentation.tissue(sdata, image_key=None, level=-1, mode=None, expand_radius_ratio=0.05, channel=None, clip_parameters=(0.9, 5), blur_kernel_size=5, open_kernel_size=5, close_kernel_size=5, drop_threshold=0.01, allow_holes=True, key_added=SopaKeys.ROI)</code>","text":"<p>Perform a contouring of the tissue (i.e., \"tissue-segmentation\"). The resulting regions-of-interest(s) are saved as shapes in the <code>SpatialData</code> object. There are two modes available: <code>saturation</code> and <code>staining</code>. The <code>saturation</code> mode is used for H&amp;E data, while the <code>staining</code> mode is used on staining images (more details below).</p> <p>Saturation mode</p> <p>This segmentation method first transforms the image from RBG color space to HSV. Then, on the basis of the saturation channel, a median blurring is applied with an element of size <code>blur_kernel_size</code> before running the Otsu method. Then a morphological opening and closing are applied as a prostprocessing step with square elements of size <code>open_kernel_size</code> and <code>close_kernel_size</code>. Lastly, the connected components with size less than <code>drop_threshold * number_of_pixel_of_the_image</code> are removed, and the rest are converted into polygons.</p> <p>Staining mode</p> <p>Instead of extracting the saturation channel, the image is converted to a grayscale image by taking the maximum value of all channels (or the specified channel, if <code>\"channel\"</code> is given). The rest of the steps are the same as in the saturation mode.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object representing an H&amp;E image</p> required <code>image_key</code> <code>str | None</code> <p>Optional key of the H&amp;E image</p> <code>None</code> <code>level</code> <code>int</code> <p>Level of the multiscale image on which the segmentation will be performed (if the image is a <code>DataTree</code>)</p> <code>-1</code> <code>mode</code> <code>str | None</code> <p>Two modes are available: <code>saturation</code> (for H&amp;E data) and <code>staining</code>. By default, <code>saturation</code> is used only if there are exactly 3 channels.</p> <code>None</code> <code>expand_radius_ratio</code> <code>float</code> <p>The ratio of the radius of the polygons that will be expanded.</p> <code>0.05</code> <code>channel</code> <code>str | None</code> <p>The channel to use for the <code>staining</code> mode. If <code>None</code>, the maximum value of all channels is used.</p> <code>None</code> <code>clip_parameters</code> <code>tuple[float, float]</code> <p>Parameters used to get the threshold used to clip the image before converting it to an 8-bit image (only used in \"staining\" mode). The first parameter is the quantile, and the second is the divisor. By default, the threshold is the 90th quantile divided by 5.</p> <code>(0.9, 5)</code> <code>blur_kernel_size</code> <code>int</code> <p>The kernel size of the median bluring operation</p> <code>5</code> <code>open_kernel_size</code> <code>int</code> <p>The kernel size of the morphological openning operation</p> <code>5</code> <code>close_kernel_size</code> <code>int</code> <p>The kernel size of the morphological closing operation</p> <code>5</code> <code>drop_threshold</code> <code>float</code> <p>Segments that cover less area than a ratio of <code>drop_threshold</code> of the number of pixels of the image will be removed</p> <code>0.01</code> <code>allow_holes</code> <code>bool</code> <p>If <code>True</code>, the holes in the polygons will be kept. If <code>False</code>, the holes will be removed.</p> <code>True</code> <code>key_added</code> <code>str</code> <p>Name of the spatial element that will be added, containing the segmented tissue polygons.</p> <code>ROI</code> Source code in <code>sopa/segmentation/_tissue.py</code> <pre><code>def tissue(\n    sdata: SpatialData,\n    image_key: str | None = None,\n    level: int = -1,\n    mode: str | None = None,\n    expand_radius_ratio: float = 0.05,\n    channel: str | None = None,\n    clip_parameters: tuple[float, float] = (0.9, 5),\n    blur_kernel_size: int = 5,\n    open_kernel_size: int = 5,\n    close_kernel_size: int = 5,\n    drop_threshold: float = 0.01,\n    allow_holes: bool = True,\n    key_added: str = SopaKeys.ROI,\n):\n    \"\"\"Perform a contouring of the tissue (i.e., \"tissue-segmentation\"). The resulting regions-of-interest(s) are saved as shapes in the `SpatialData` object. There are two\n    modes available: `saturation` and `staining`. The `saturation` mode is used for H&amp;E data, while the `staining` mode\n    is used on staining images (more details below).\n\n    !!! info \"Saturation mode\"\n        This segmentation method first transforms the image from RBG color space to HSV. Then,\n        on the basis of the saturation channel, a median blurring is applied with an element of size `blur_kernel_size`\n        before running the Otsu method. Then a morphological opening and closing are applied as a prostprocessing\n        step with square elements of size `open_kernel_size` and `close_kernel_size`. Lastly, the connected components\n        with size less than `drop_threshold * number_of_pixel_of_the_image` are removed, and the\n        rest are converted into polygons.\n\n    !!! info \"Staining mode\"\n        Instead of extracting the saturation channel, the image is converted to a grayscale image by taking the maximum\n        value of all channels (or the specified channel, if `\"channel\"` is given). The rest of the steps are the same as in the saturation mode.\n\n    Args:\n        sdata: A `SpatialData` object representing an H&amp;E image\n        image_key: Optional key of the H&amp;E image\n        level: Level of the multiscale image on which the segmentation will be performed (if the image is a `DataTree`)\n        mode: Two modes are available: `saturation` (for H&amp;E data) and `staining`. By default, `saturation` is used only if there are exactly 3 channels.\n        expand_radius_ratio: The ratio of the radius of the polygons that will be expanded.\n        channel: The channel to use for the `staining` mode. If `None`, the maximum value of all channels is used.\n        clip_parameters: Parameters used to get the threshold used to clip the image before converting it to an 8-bit image (only used in \"staining\" mode). The first parameter is the quantile, and the second is the divisor. By default, the threshold is the 90th quantile divided by 5.\n        blur_kernel_size: The kernel size of the median bluring operation\n        open_kernel_size: The kernel size of the morphological openning operation\n        close_kernel_size: The kernel size of the morphological closing operation\n        drop_threshold: Segments that cover less area than a ratio of `drop_threshold` of the number of pixels of the image will be removed\n        allow_holes: If `True`, the holes in the polygons will be kept. If `False`, the holes will be removed.\n        key_added: Name of the spatial element that will be added, containing the segmented tissue polygons.\n    \"\"\"\n    image, mode = _get_image_and_mode(sdata, image_key, mode, channel)\n\n    if key_added in sdata.shapes:\n        log.warning(f\"sdata['{key_added}'] was already existing, but tissue segmentation is run on top\")\n\n    if isinstance(image, DataTree):\n        level_keys = list(image.keys())\n        image: DataArray = next(iter(image[level_keys[level]].values()))\n\n    geo_df = TissueSegmentation(\n        image=image,\n        blur_kernel_size=blur_kernel_size,\n        open_kernel_size=open_kernel_size,\n        close_kernel_size=close_kernel_size,\n        drop_threshold=drop_threshold,\n        channel=channel,\n        clip_parameters=clip_parameters,\n        allow_holes=allow_holes,\n    ).get_polygons(mode)\n\n    if not len(geo_df):\n        log.warning(\n            \"No polygon has been found after tissue segmentation. \"\n            \"Check that there is some tissue in the image, or consider updating the function parameters.\"\n        )\n        return\n\n    geo_df = expand_radius(geo_df, expand_radius_ratio)\n    geo_df = geo_df.explode(index_parts=False, ignore_index=True)\n    geo_df = to_valid_polygons(geo_df, simple_polygon=not allow_holes)\n\n    geo_df = ShapesModel.parse(geo_df, transformations=copy_transformations(image))\n\n    add_spatial_element(sdata, key_added, geo_df)\n</code></pre>"},{"location":"api/segmentation/#segmentation-utils","title":"Segmentation utils","text":""},{"location":"api/segmentation/#sopa.segmentation.combine","title":"<code>sopa.segmentation.combine(sdata, elements, key_added, threshold=0.5)</code>","text":"<p>Combine multiple segmentation boundaries into a single one.</p> Example <p>On the example below, we run Cellpose twice, once for nuclei and once for tumor cells. We then combine the two segmentations into a single one. <pre><code>import sopa\n\nsdata = sopa.io.toy_dataset(length=1000)\nsopa.make_image_patches(sdata)\n\nsopa.segmentation.cellpose(sdata, \"DAPI\", diameter=35, key_added=\"nuclei\")\nsopa.segmentation.cellpose(sdata, [\"DAPI\", \"CK\"], diameter=35, key_added=\"tumor_cells\")\n\nsopa.segmentation.combine(sdata, [\"nuclei\", \"tumor_cells\"], key_added=\"combined_cells\")\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>elements</code> <code>list[str | GeoDataFrame]</code> <p>List of name of the keys in <code>sdata.shapes</code> to be combined (or directly a list of <code>GeoDataFrame</code>).</p> required <code>key_added</code> <code>str</code> <p>The name of the new key to be added to <code>sdata.shapes</code>.</p> required <code>threshold</code> <code>float</code> <p>When two cells are overlapping, we look at the area of intersection over the area of the smallest cell. If this value is higher than the <code>threshold</code>, the cells are merged</p> <code>0.5</code> Source code in <code>sopa/segmentation/resolve.py</code> <pre><code>def combine(\n    sdata: SpatialData,\n    elements: list[str | gpd.GeoDataFrame],\n    key_added: str,\n    threshold: float = 0.5,\n):\n    \"\"\"Combine multiple segmentation boundaries into a single one.\n\n    Example:\n        On the example below, we run Cellpose twice, once for nuclei and once for tumor cells. We then combine the two segmentations into a single one.\n        ```python\n        import sopa\n\n        sdata = sopa.io.toy_dataset(length=1000)\n        sopa.make_image_patches(sdata)\n\n        sopa.segmentation.cellpose(sdata, \"DAPI\", diameter=35, key_added=\"nuclei\")\n        sopa.segmentation.cellpose(sdata, [\"DAPI\", \"CK\"], diameter=35, key_added=\"tumor_cells\")\n\n        sopa.segmentation.combine(sdata, [\"nuclei\", \"tumor_cells\"], key_added=\"combined_cells\")\n        ```\n\n    Args:\n        sdata: A `SpatialData` object.\n        elements: List of name of the keys in `sdata.shapes` to be combined (or directly a list of `GeoDataFrame`).\n        key_added: The name of the new key to be added to `sdata.shapes`.\n        threshold: When two cells are overlapping, we look at the area of intersection over the area of the smallest cell. If this value is higher than the `threshold`, the cells are merged\n    \"\"\"\n    assert len(elements) &gt; 1, \"At least two elements must be provided to combine\"\n\n    elements: list[gpd.GeoDataFrame] = [\n        element if isinstance(element, gpd.GeoDataFrame) else sdata.shapes[element] for element in elements\n    ]\n\n    reference = elements[0]\n    intrinsic_elements = [reference] + [to_intrinsic(sdata, element, reference) for element in elements[1:]]\n\n    combined_cells = list(pd.concat([element.geometry for element in intrinsic_elements], axis=0))\n    combined_cells = solve_conflicts(combined_cells, threshold=threshold)\n\n    combined_geo_df = ShapesModel.parse(combined_cells, transformations=get_transformation(reference, get_all=True))\n\n    sdata.shapes[key_added] = combined_geo_df\n</code></pre>"},{"location":"api/segmentation/#sopa.overlay_segmentation","title":"<code>sopa.overlay_segmentation(sdata, shapes_key, gene_column=None, area_ratio_threshold=0.25, image_key=None, table_key=SopaKeys.TABLE)</code>","text":"<p>Overlay a segmentation on top of an existing segmentation</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>shapes_key</code> <code>str</code> <p>The key of the new shapes to be added</p> required <code>gene_column</code> <code>str | None</code> <p>Key of the points dataframe containing the genes names</p> <code>None</code> <code>area_ratio_threshold</code> <code>float</code> <p>Threshold between 0 and 1. For each original cell overlapping with a new cell, we compute the overlap-area/cell-area, if above the threshold the cell is removed.</p> <code>0.25</code> <code>image_key</code> <code>str | None</code> <p>Optional key of the original image</p> <code>None</code> <code>table_key</code> <code>str</code> <p>Key of the table to be overlayed</p> <code>TABLE</code> Source code in <code>sopa/aggregation/overlay.py</code> <pre><code>def overlay_segmentation(\n    sdata: SpatialData,\n    shapes_key: str,\n    gene_column: str | None = None,\n    area_ratio_threshold: float = 0.25,\n    image_key: str | None = None,\n    table_key: str = SopaKeys.TABLE,\n):\n    \"\"\"Overlay a segmentation on top of an existing segmentation\n\n    Args:\n        sdata: A `SpatialData` object\n        shapes_key: The key of the new shapes to be added\n        gene_column: Key of the points dataframe containing the genes names\n        area_ratio_threshold: Threshold between 0 and 1. For each original cell overlapping with a new cell, we compute the overlap-area/cell-area, if above the threshold the cell is removed.\n        image_key: Optional key of the original image\n        table_key: Key of the table to be overlayed\n    \"\"\"\n    aggregate_genes, aggregate_channels = False, False\n\n    assert table_key in sdata.tables, f\"No table with name '{table_key}' found in the SpatialData object\"\n\n    old_table: AnnData = sdata.tables[table_key]\n\n    assert SopaKeys.UNS_KEY in old_table.uns, \"It seems the table was not aggregated using `sopa.aggregate`\"\n\n    sopa_attrs = old_table.uns[SopaKeys.UNS_KEY]\n\n    aggregate_genes = sopa_attrs[SopaKeys.UNS_HAS_TRANSCRIPTS]\n    aggregate_channels = sopa_attrs[SopaKeys.UNS_HAS_INTENSITIES]\n\n    if aggregate_genes and gene_column is None:\n        points = get_spatial_element(sdata.points, key=sdata.attrs.get(SopaAttrs.TRANSCRIPTS))\n        gene_column = get_feature_key(points, raise_error=True)\n\n    aggregator = Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)\n    aggregator.sdata.tables[f\"{SopaKeys.OLD_TABLE_PREFFIX}{table_key}\"] = old_table\n    del aggregator.sdata.tables[table_key]\n\n    old_shapes_key = old_table.uns[\"spatialdata_attrs\"][\"region\"]\n    instance_key = old_table.uns[\"spatialdata_attrs\"][\"instance_key\"]\n\n    if isinstance(old_shapes_key, list):\n        assert len(old_shapes_key) == 1, \"Can't overlap segmentation on multi-region SpatialData object\"\n        old_shapes_key = old_shapes_key[0]\n\n    old_geo_df = aggregator.sdata[old_shapes_key]\n    geo_df = to_intrinsic(aggregator.sdata, aggregator.geo_df, old_geo_df)\n\n    geo_df.index.name = None\n    gdf_join = gpd.sjoin(old_geo_df, geo_df)\n    gdf_join[\"geometry_right\"] = gdf_join[\"index_right\"].map(lambda i: geo_df.geometry.iloc[i])\n    gdf_join[\"overlap_ratio\"] = gdf_join.apply(_overlap_area_ratio, axis=1)\n    gdf_join: gpd.GeoDataFrame = gdf_join[gdf_join.overlap_ratio &gt;= area_ratio_threshold]\n\n    table_crop = old_table[~np.isin(old_table.obs[instance_key], gdf_join.index)].copy()\n    table_crop.obs[SopaKeys.CELL_OVERLAY_KEY] = False\n\n    aggregator.compute_table(\n        aggregate_channels=aggregate_channels,\n        aggregate_genes=aggregate_genes,\n        gene_column=gene_column,\n        key_added=table_key,\n    )\n    aggregator.table.obs[SopaKeys.CELL_OVERLAY_KEY] = True\n\n    aggregator.table = anndata.concat(\n        [table_crop, aggregator.table],\n        uns_merge=\"first\",\n        join=\"outer\",\n    )\n\n    aggregator.shapes_key = f\"{old_shapes_key}_overlay_{aggregator.shapes_key}\"\n\n    geo_df_cropped = old_geo_df.loc[~old_geo_df.index.isin(gdf_join.index)]\n    aggregator.geo_df = pd.concat([geo_df_cropped, geo_df], join=\"outer\", axis=0)\n    aggregator.geo_df.attrs = old_geo_df.attrs\n\n    aggregator.add_standardized_table(table_key)\n</code></pre>"},{"location":"api/spatial/","title":"Spatial operations","text":""},{"location":"api/spatial/#sopa.spatial.sjoin","title":"<code>sopa.spatial.sjoin(sdata, left_element, right_element, how='left', target_coordinate_system=None, **kwargs)</code>","text":"<p>Spatial join of two <code>shapes</code> GeoDataFrames, as in geopandas.sjoin.</p> <p>Shapes are automatically aligned on the same coordinate system (which can be chosen using the <code>target_coordinate_system</code> argument).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>left_element</code> <code>str | GeoDataFrame</code> <p>The name of a GeoDataFrame in <code>sdata</code>, or the GeoDataFrame itself</p> required <code>right_element</code> <code>str | GeoDataFrame</code> <p>The name of a GeoDataFrame in <code>sdata</code>, or the GeoDataFrame itself</p> required <code>how</code> <code>str</code> <p>The GeoPandas type of join. By default, left geometries are retained.</p> <code>'left'</code> <code>target_coordinate_system</code> <code>str | None</code> <p>The name of the coordinate system on which the shapes will be transformed. By default, uses the intrinsic coordinate system of the <code>left_element</code>.</p> <code>None</code> <code>**kwargs</code> <code>int</code> <p>Kwargs provided to the geopandas.sjoin function</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>The joined <code>GeoDataFrame</code></p> Source code in <code>sopa/spatial/join.py</code> <pre><code>def sjoin(\n    sdata: SpatialData,\n    left_element: str | gpd.GeoDataFrame,\n    right_element: str | gpd.GeoDataFrame,\n    how: str = \"left\",\n    target_coordinate_system: str | None = None,\n    **kwargs: int,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Spatial join of two `shapes` GeoDataFrames, as in [geopandas.sjoin](https://geopandas.org/en/stable/docs/reference/api/geopandas.sjoin.html).\n\n    Shapes are automatically aligned on the same coordinate system (which can be chosen using the `target_coordinate_system` argument).\n\n    Args:\n        sdata: A `SpatialData` object\n        left_element: The name of a GeoDataFrame in `sdata`, or the GeoDataFrame itself\n        right_element: The name of a GeoDataFrame in `sdata`, or the GeoDataFrame itself\n        how: The GeoPandas type of join. By default, left geometries are retained.\n        target_coordinate_system: The name of the coordinate system on which the shapes will be transformed. By default, uses the intrinsic coordinate system of the `left_element`.\n        **kwargs: Kwargs provided to the [geopandas.sjoin](https://geopandas.org/en/stable/docs/reference/api/geopandas.sjoin.html) function\n\n    Returns:\n        The joined `GeoDataFrame`\n    \"\"\"\n    if isinstance(left_element, str):\n        left_element = sdata[left_element]\n    if isinstance(right_element, str):\n        right_element = sdata[right_element]\n\n    if target_coordinate_system is None:\n        right_element = to_intrinsic(sdata, right_element, left_element)\n    else:\n        left_element = sdata.transform_element_to_coordinate_system(left_element, target_coordinate_system)\n        right_element = sdata.transform_element_to_coordinate_system(right_element, target_coordinate_system)\n\n    return gpd.sjoin(left_element, right_element, how=how, **kwargs)\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.assign_transcript_to_cell","title":"<code>sopa.spatial.assign_transcript_to_cell(sdata, points_key=None, shapes_key=None, key_added='cell_index', unassigned_value=None)</code>","text":"<p>Assign each transcript to a cell based on the cell boundaries. It updates the transcript dataframe by adding a new column.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>points_key</code> <code>str | None</code> <p>Key of the spatialdata object containing the transcript dataframe.</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Key of the spatialdata object containing the cell boundaries.</p> <code>None</code> <code>key_added</code> <code>str</code> <p>Key that will be added to the transcript dataframe containing the cell ID</p> <code>'cell_index'</code> <code>unassigned_value</code> <code>int | None</code> <p>If <code>None</code>, transcripts that are not inside any cell will be assigned to NaN. If an integer, this value will be used as the unassigned value.</p> <code>None</code> Source code in <code>sopa/spatial/join.py</code> <pre><code>def assign_transcript_to_cell(\n    sdata: SpatialData,\n    points_key: str | None = None,\n    shapes_key: str | None = None,\n    key_added: str = \"cell_index\",\n    unassigned_value: int | None = None,\n):\n    \"\"\"Assign each transcript to a cell based on the cell boundaries. It updates the transcript dataframe by adding a new column.\n\n    Args:\n        sdata: A `SpatialData` object\n        points_key: Key of the spatialdata object containing the transcript dataframe.\n        shapes_key: Key of the spatialdata object containing the cell boundaries.\n        key_added: Key that will be added to the transcript dataframe containing the cell ID\n        unassigned_value: If `None`, transcripts that are not inside any cell will be assigned to NaN. If an integer, this value will be used as the unassigned value.\n    \"\"\"\n    df = get_spatial_element(sdata.points, points_key or sdata.attrs.get(SopaAttrs.TRANSCRIPTS))\n    geo_df = get_boundaries(sdata, key=shapes_key)\n\n    geo_df = to_intrinsic(sdata, geo_df, df)\n    geo_df = geo_df.reset_index(drop=True)\n\n    get_cell_id = partial(_get_cell_id, geo_df, unassigned_value=unassigned_value)\n\n    if isinstance(df, dd.DataFrame):\n        df[key_added] = df.map_partitions(get_cell_id)\n    else:\n        raise TypeError(f\"Invalid dataframe type: {type(df)}\")\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.mean_distance","title":"<code>sopa.spatial.mean_distance(adata, group_key, target_group_key=None, ignore_zeros=False, correction=False, relative_change=False)</code>","text":"<p>Mean distance between two groups (typically, between cell-types, or between cell-types and domains).</p> <p>Warning</p> <p>When computing distances for multiple slides, differences in cell-type proportions can introduce bias. For example, if group G is more abundant in one slide, the average distance from other groups to G will naturally appear smaller in that slide, simply due to higher local density. If you want to perform fair comparisons across samples, consider using the <code>correction</code> argument to adjust for this bias.</p> Note <p>The distance is a number of hops, i.e. a distance of 10 between a pDC and a T cell means that there are 10 cells on the closest path from one to the other cell.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>group_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the groups</p> required <code>target_group_key</code> <code>str | None</code> <p>Key of <code>adata.obs</code> containing the target groups (by default, uses <code>group_key</code>)</p> <code>None</code> <code>ignore_zeros</code> <code>bool</code> <p>If <code>True</code>, a cell distance to its own group is not 0, but the distance to the closest other cell of the same group.</p> <code>False</code> <code>correction</code> <code>bool</code> <p>If <code>True</code>, the computed distance is corrected by subtracting the expected distance under a null model where target labels are randomly distributed on a grid. This correction accounts for uneven label representation, which could otherwise deflate distances to more abundant target cell types.</p> <code>False</code> <code>relative_change</code> <code>bool</code> <p>Only used if <code>correction</code> is <code>True</code>. If <code>True</code>, the correction is applied as a relative change, i.e. the distance difference is also divided by the expected distance under the null model defined previously.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p><code>DataFrame</code> of shape <code>n_groups * n_groups_target</code> of mean hop-distances</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def mean_distance(\n    adata: AnnData,\n    group_key: str,\n    target_group_key: str | None = None,\n    ignore_zeros: bool = False,\n    correction: bool = False,\n    relative_change: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Mean distance between two groups (typically, between cell-types, or between cell-types and domains).\n\n    !!! warning\n        When computing distances for multiple slides, differences in cell-type proportions can introduce bias. For example, if group G is more abundant in one slide, the average distance from other groups to G will naturally appear smaller in that slide, simply due to higher local density. If you want to perform fair comparisons across samples, consider using the `correction` argument to adjust for this bias.\n\n    Note:\n        The distance is a number of hops, i.e. a distance of 10 between a pDC and a T cell means that there are 10 cells on the closest path from one to the other cell.\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        group_key: Key of `adata.obs` containing the groups\n        target_group_key: Key of `adata.obs` containing the target groups (by default, uses `group_key`)\n        ignore_zeros: If `True`, a cell distance to its own group is not 0, but the distance to the closest other cell of the same group.\n        correction: If `True`, the computed distance is corrected by subtracting the expected distance under a null model where target labels are randomly distributed on a grid. This correction accounts for uneven label representation, which could otherwise deflate distances to more abundant target cell types.\n        relative_change: Only used if `correction` is `True`. If `True`, the correction is applied as a relative change, i.e. the distance difference is also divided by the expected distance under the null model defined previously.\n\n    Returns:\n        `DataFrame` of shape `n_groups * n_groups_target` of mean hop-distances\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    target_group_key = group_key if target_group_key is None else target_group_key\n\n    df_distances = cells_to_groups(adata, target_group_key, None, ignore_zeros=ignore_zeros)\n\n    if ignore_zeros:\n        df_distances.replace(0, np.nan, inplace=True)\n\n    df_distances[group_key] = adata.obs[group_key]\n    df_distances = df_distances.groupby(group_key, observed=False).mean()\n    df_distances.columns.name = target_group_key\n\n    if correction:\n        log.info(\"Correcting the distances is still experimental, don't hesitate to report issues or feedback\")\n        proportions = adata.obs[target_group_key].value_counts(normalize=True)\n        likelihood = proportions.map(lambda p: _random_distance_likelihood(p, ignore_zeros))\n\n        df_distances -= likelihood\n        if relative_change:\n            df_distances /= likelihood\n\n        if (not ignore_zeros) and (group_key == target_group_key):\n            # distance to cell to same group is 0, we don't correct it\n            df_distances.values[np.diag_indices_from(df_distances)] = 0\n\n    return df_distances\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.vectorize_niches","title":"<code>sopa.spatial.vectorize_niches(adata, niche_key, buffer='auto', perc_area_th=0.05)</code>","text":"<p>Converts the niches to shapely polygons, and put into a <code>GeoDataFrame</code>. Note that each niche can appear multiple times, as they can be separated by other niches ; in this case, we call them different \"components\" of the same niche ID.</p> Plot components <p>You can show niches components with GeoPandas <pre><code>gdf = vectorize_niches(adata, niche_key)\ngdf.plot(column=niche_key)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>buffer</code> <code>int | str</code> <p>Expansion radius applied on components. By default, <code>3 * mean_distance_neighbors</code></p> <code>'auto'</code> <code>perc_area_th</code> <code>float</code> <p>For each niche, components whose area is less than <code>perc_area_th * max_component_area</code> will be removed</p> <code>0.05</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A <code>GeoDataFrame</code> with geometries for each niche component. We also compute the area/perimeter/roundness of each component.</p> Source code in <code>sopa/spatial/morpho.py</code> <pre><code>def vectorize_niches(\n    adata: AnnData | SpatialData,\n    niche_key: str,\n    buffer: int | str = \"auto\",\n    perc_area_th: float = 0.05,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Converts the niches to shapely polygons, and put into a `GeoDataFrame`. Note that each niche can appear multiple times, as they can be separated by other niches ; in this case, we call them different \"components\" of the same niche ID.\n\n    Plot components:\n        You can show niches components with GeoPandas\n        ```py\n        gdf = vectorize_niches(adata, niche_key)\n        gdf.plot(column=niche_key)\n        ```\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        niche_key: Key of `adata.obs` containing the niches\n        buffer: Expansion radius applied on components. By default, `3 * mean_distance_neighbors`\n        perc_area_th: For each niche, components whose area is less than `perc_area_th * max_component_area` will be removed\n\n    Returns:\n        A `GeoDataFrame` with geometries for each niche component. We also compute the area/perimeter/roundness of each component.\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    _check_has_delaunay(adata)\n    data = {\"geometry\": [], niche_key: []}\n\n    delaunay = Delaunay(adata.obsm[\"spatial\"])\n    connectivities = adata.obsp[\"spatial_connectivities\"]\n    values = adata.obs[niche_key].values\n\n    keep = (\n        (connectivities[delaunay.simplices[:, 0], delaunay.simplices[:, 1]].A1 == 1)\n        &amp; (connectivities[delaunay.simplices[:, 0], delaunay.simplices[:, 2]].A1 == 1)\n        &amp; (connectivities[delaunay.simplices[:, 1], delaunay.simplices[:, 2]].A1 == 1)\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 1]])\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 2]])\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 2]])\n    )  # Keep simplices that are in the original Delaunay graph, and which are not in between different value categories\n\n    neighbors = np.where(np.isin(delaunay.neighbors, np.where(~keep)[0]), -1, delaunay.neighbors)\n\n    simplices_to_visit = set(np.where(keep)[0])\n\n    while simplices_to_visit:\n        component = Component(adata, delaunay, neighbors)\n        component.visit(simplices_to_visit)\n\n        data[\"geometry\"].append(component.polygon)\n        data[niche_key].append(values[component.first_vertex_index()])\n\n    gdf = gpd.GeoDataFrame(data)\n\n    if buffer is not None and buffer != 0:\n        gdf = _clean_components(adata, gdf, niche_key, buffer)\n\n    gdf[SopaKeys.GEOMETRY_LENGTH] = gdf.length\n    gdf[SopaKeys.GEOMETRY_AREA] = gdf.area\n    gdf[SopaKeys.GEOMETRY_ROUNDNESS] = 4 * np.pi * gdf[SopaKeys.GEOMETRY_AREA] / gdf[SopaKeys.GEOMETRY_LENGTH] ** 2\n\n    # Remove minor components (compared to the largest component of its corresponding niche)\n    gdf = gdf[gdf.area &gt;= gdf[niche_key].map(gdf.groupby(niche_key).area.max() * perc_area_th)]\n\n    return gdf\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.niches_geometry_stats","title":"<code>sopa.spatial.niches_geometry_stats(adata, niche_key, aggregation='min', key_added_suffix='_distance_to_niche_', **vectorize_niches_kwargs)</code>","text":"<p>Computes statistics over niches geometries</p> Details <ul> <li><code>n_components</code>: Number of connected component of a niche (a component is a group of neighbor cells with the same niche attribute)</li> <li><code>length</code>: Mean distance of the exterior/boundary of the components of a niche</li> <li><code>area</code>: Mean area of the components of a niche</li> <li><code>roundness</code>: Float value between 0 and 1. The higher the value, the closer to a circle. Computed via <code>4 * pi * area / length**2</code></li> <li><code>mean_distance_to_niche_X</code>: mean distance to the niche (between the two closest points of the niches)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>aggregation</code> <code>str | list[str]</code> <p>Aggregation mode. Either one string such as <code>\"min\"</code>, or a list such as <code>[\"mean\", \"min\"]</code>.</p> <code>'min'</code> <code>key_added_suffix</code> <code>str</code> <p>Suffix added in the DataFrame columns. Defaults to \"distance_to_niche\".</p> <code>'_distance_to_niche_'</code> <code>vectorize_niches_kwargs</code> <code>str</code> <p>Kwargs to the <code>sopa.spatial.vectorize_niches</code> function</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A <code>DataFrame</code> of shape <code>n_niches * n_statistics</code></p> Source code in <code>sopa/spatial/morpho.py</code> <pre><code>def niches_geometry_stats(\n    adata: AnnData | SpatialData,\n    niche_key: str,\n    aggregation: str | list[str] = \"min\",\n    key_added_suffix: str = \"_distance_to_niche_\",\n    **vectorize_niches_kwargs: str,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Computes statistics over niches geometries\n\n    Details:\n        - `n_components`: Number of connected component of a niche (a component is a group of neighbor cells with the same niche attribute)\n        - `length`: Mean distance of the exterior/boundary of the components of a niche\n        - `area`: Mean area of the components of a niche\n        - `roundness`: Float value between 0 and 1. The higher the value, the closer to a circle. Computed via `4 * pi * area / length**2`\n        - `mean_distance_to_niche_X`: mean distance to the niche (between the two closest points of the niches)\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        niche_key: Key of `adata.obs` containing the niches\n        aggregation: Aggregation mode. Either one string such as `\"min\"`, or a list such as `[\"mean\", \"min\"]`.\n        key_added_suffix: Suffix added in the DataFrame columns. Defaults to \"_distance_to_niche_\".\n        vectorize_niches_kwargs: Kwargs to the `sopa.spatial.vectorize_niches` function\n\n    Returns:\n        A `DataFrame` of shape `n_niches * n_statistics`\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    gdf = vectorize_niches(adata, niche_key, **vectorize_niches_kwargs)\n    value_counts = gdf[niche_key].value_counts()\n\n    assert len(gdf), \"No niche geometry found, stats can't be computed\"\n\n    log.info(f\"Computing pairwise distances between {len(gdf)} components\")\n    pairwise_distances: pd.DataFrame = gdf.geometry.apply(lambda g: gdf.distance(g))\n    pairwise_distances[niche_key] = gdf[niche_key]\n\n    if isinstance(aggregation, str):\n        aggregation = [aggregation]\n\n    for aggr in aggregation:\n        df = pairwise_distances.groupby(niche_key).aggregate(aggr).T\n        df.columns = [f\"{aggr}{key_added_suffix}{c}\" for c in df.columns]\n        gdf[df.columns] = df\n\n    df_stats: pd.DataFrame = gdf.groupby(niche_key)[gdf.columns[2:]].mean()\n    df_stats.insert(0, SopaKeys.GEOMETRY_COUNT, value_counts)\n\n    return df_stats\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.cells_to_groups","title":"<code>sopa.spatial.cells_to_groups(adata, group_key, key_added_prefix=None, ignore_zeros=False)</code>","text":"<p>Compute the hop-distance between each cell and a cell category/group.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>group_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the groups</p> required <code>key_added_prefix</code> <code>str | None</code> <p>Prefix to the key added in <code>adata.obsm</code>. If <code>None</code>, will return the <code>DataFrame</code> instead of saving it.</p> <code>None</code> <code>ignore_zeros</code> <code>bool</code> <p>If <code>True</code>, a cell distance to its own group is not 0, but the distance to the closest other cell of the same group.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>A <code>Dataframe</code> of shape <code>n_obs * n_groups</code>, or <code>None</code> if <code>key_added_prefix</code> was provided (in this case, the dataframe is saved in <code>\"{key_added_prefix}{group_key}\"</code>)</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def cells_to_groups(\n    adata: AnnData,\n    group_key: str,\n    key_added_prefix: str | None = None,\n    ignore_zeros: bool = False,\n) -&gt; pd.DataFrame | None:\n    \"\"\"Compute the hop-distance between each cell and a cell category/group.\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        group_key: Key of `adata.obs` containing the groups\n        key_added_prefix: Prefix to the key added in `adata.obsm`. If `None`, will return the `DataFrame` instead of saving it.\n        ignore_zeros: If `True`, a cell distance to its own group is not 0, but the distance to the closest other cell of the same group.\n\n    Returns:\n        A `Dataframe` of shape `n_obs * n_groups`, or `None` if `key_added_prefix` was provided (in this case, the dataframe is saved in `\"{key_added_prefix}{group_key}\"`)\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    _check_has_delaunay(adata)\n\n    distances_to_groups = {}\n\n    if adata.obs[group_key].dtype.name != \"category\":\n        log.info(f\"Converting adata.obs['{group_key}'] to category\")\n        adata.obs[group_key] = adata.obs[group_key].astype(\"category\")\n\n    for group_id in tqdm(adata.obs[group_key].cat.categories):\n        group_nodes = np.where(adata.obs[group_key] == group_id)[0]\n\n        distances = np.full(adata.n_obs, np.nan)\n\n        if not ignore_zeros:\n            distances[group_nodes] = 0\n            visited = set(group_nodes)\n        else:\n            visited = set()\n\n        queue = group_nodes\n        current_distance = 0\n\n        while len(queue):\n            distances[queue] = current_distance\n\n            neighbors = set(adata.obsp[\"spatial_connectivities\"][queue].indices)\n            queue = np.array(list(neighbors - visited))\n            visited |= neighbors\n\n            current_distance += 1\n\n        distances_to_groups[group_id] = distances\n\n    df_distances = pd.DataFrame(distances_to_groups, index=adata.obs_names)\n\n    if key_added_prefix is None:\n        return df_distances\n    adata.obsm[f\"{key_added_prefix}{group_key}\"] = df_distances\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.spatial_neighbors","title":"<code>sopa.spatial.spatial_neighbors(adata, radius, library_key=None, percentile=None, set_diag=False)</code>","text":"<p>Create a Delaunay graph from spatial coordinates. This function comes from squidpy.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>AnnData object</p> required <code>radius</code> <code>tuple[float, float] | None</code> <p>tuple that prunes the final graph to only contain edges in interval <code>[min(radius), max(radius)]</code>. If <code>None</code>, all edges are kept.</p> required <code>library_key</code> <code>str | None</code> <p>Optional batch key in adata.obs</p> <code>None</code> <code>percentile</code> <code>float | None</code> <p>Percentile of the distances to use as threshold.</p> <code>None</code> <code>set_diag</code> <code>bool</code> <p>Whether to set the diagonal of the spatial connectivities to <code>1.0</code>.</p> <code>False</code> Source code in <code>sopa/spatial/build.py</code> <pre><code>def spatial_neighbors(\n    adata: AnnData | SpatialData,\n    radius: tuple[float, float] | None,\n    library_key: str | None = None,\n    percentile: float | None = None,\n    set_diag: bool = False,\n):\n    \"\"\"Create a Delaunay graph from spatial coordinates. This function comes from [squidpy](https://squidpy.readthedocs.io/en/latest/api/squidpy.gr.spatial_neighbors.html#squidpy.gr.spatial_neighbors).\n\n    Args:\n        adata: AnnData object\n        radius: tuple that prunes the final graph to only contain edges in interval `[min(radius), max(radius)]`. If `None`, all edges are kept.\n        library_key: Optional batch key in adata.obs\n        percentile: Percentile of the distances to use as threshold.\n        set_diag: Whether to set the diagonal of the spatial connectivities to `1.0`.\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    assert radius is None or len(radius) == 2, \"Radius is expected to be a tuple (min_radius, max_radius)\"\n\n    log.info(\"Computing delaunay graph\")\n\n    if library_key is not None:\n        assert adata.obs[library_key].dtype == \"category\"\n        libs = adata.obs[library_key].cat.categories\n        make_index_unique(adata.obs_names)\n    else:\n        libs = [None]\n\n    _build_fun = partial(\n        _spatial_neighbor,\n        set_diag=set_diag,\n        radius=radius,\n        percentile=percentile,\n    )\n\n    if library_key is not None:\n        mats: list[tuple[spmatrix, spmatrix]] = []\n        ixs = []  # type: ignore[var-annotated]\n        for lib in libs:\n            ixs.extend(np.where(adata.obs[library_key] == lib)[0])\n            mats.append(_build_fun(adata[adata.obs[library_key] == lib]))\n        ixs = np.argsort(ixs)  # type: ignore[assignment] # invert\n        Adj = block_diag([m[0] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n        Dst = block_diag([m[1] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n    else:\n        Adj, Dst = _build_fun(adata)\n\n    adata.obsp[\"spatial_connectivities\"] = Adj\n    adata.obsp[\"spatial_distances\"] = Dst\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.prepare_network","title":"<code>sopa.spatial.prepare_network(adata, cell_type_key, niche_key, clip_weight=3, node_colors=('#5c7dc4', '#f05541'), node_sizes=(1.3, 5))</code>","text":"<p>Create a dataframe representing weights between cell-types and/or niches. This can be later use to plot a cell-type/niche represention of a whole slide using the netgraph library.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the cell types</p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>clip_weight</code> <code>float</code> <p>Maximum weight</p> <code>3</code> <code>node_colors</code> <code>tuple[str]</code> <p>Tuple of (cell-type color, niche color)</p> <code>('#5c7dc4', '#f05541')</code> <code>node_sizes</code> <code>tuple[float | int]</code> <p>Tuple of (cell-type size, niche size)</p> <code>(1.3, 5)</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict, dict, dict]</code> <p>A DataFrame of weights between cell-types and/or niches, and three dict for netgraph display</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def prepare_network(\n    adata: AnnData,\n    cell_type_key: str,\n    niche_key: str,\n    clip_weight: float = 3,\n    node_colors: tuple[str] = (\"#5c7dc4\", \"#f05541\"),\n    node_sizes: tuple[float | int] = (1.3, 5),\n) -&gt; tuple[pd.DataFrame, dict, dict, dict]:\n    \"\"\"Create a dataframe representing weights between cell-types and/or niches.\n    This can be later use to plot a cell-type/niche represention of a whole slide\n    using the netgraph library.\n\n    Args:\n        adata: An `AnnData` object\n        cell_type_key: Key of `adata.obs` containing the cell types\n        niche_key: Key of `adata.obs` containing the niches\n        clip_weight: Maximum weight\n        node_colors: Tuple of (cell-type color, niche color)\n        node_sizes: Tuple of (cell-type size, niche size)\n\n    Returns:\n        A DataFrame of weights between cell-types and/or niches, and three dict for netgraph display\n    \"\"\"\n    node_color, node_size, node_shape = {}, {}, {}\n\n    log.info(\"Computing all distances for the 4 pairs of categories\")\n    weights = mean_distance(adata, cell_type_key)\n    top_right = mean_distance(adata, cell_type_key, niche_key)\n    bottom_left = mean_distance(adata, niche_key, cell_type_key)\n    bottom_right = mean_distance(adata, niche_key, niche_key)\n\n    for pop in weights.index:\n        node_color[pop] = node_colors[0]\n        node_size[pop] = node_sizes[0]\n        node_shape[pop] = \"o\"\n\n    for niche in bottom_right.index:\n        node_color[niche] = node_colors[1]\n        node_size[niche] = node_sizes[1]\n        node_shape[niche] = \"h\"\n\n    # assemble dataframe per-block\n    bottom_left[bottom_right.columns] = bottom_right\n    weights[top_right.columns] = top_right\n    weights = pd.concat([weights, bottom_left], axis=0).copy()\n\n    # convert distances to symmetric weights\n    weights = 1 / weights\n    np.fill_diagonal(weights.values, 0)\n    weights = weights.clip(0, clip_weight)\n    weights = (weights.T + weights) / 2\n\n    return weights, node_color, node_size, node_shape\n</code></pre>"},{"location":"api/utils/","title":"Utils","text":""},{"location":"api/utils/#cache-operations","title":"Cache operations","text":""},{"location":"api/utils/#sopa.utils.get_cache_dir","title":"<code>sopa.utils.get_cache_dir(sdata)</code>","text":"<p>Get the cache directory for a SpatialData object.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>A <code>Path</code> to the cache directory.</p> Source code in <code>sopa/utils/utils.py</code> <pre><code>def get_cache_dir(sdata: SpatialData) -&gt; Path:\n    \"\"\"Get the cache directory for a SpatialData object.\n\n    Args:\n        sdata: A `SpatialData` object.\n\n    Returns:\n        A `Path` to the cache directory.\n    \"\"\"\n    if sdata.is_backed():  # inside the zarr directory\n        cache_dir = sdata.path.resolve() / SopaFiles.SOPA_CACHE_DIR\n    elif SopaAttrs.UID in sdata.attrs:  # existing cache in the home directory\n        cache_dir = HOME_CACHE_DIR / sdata.attrs[SopaAttrs.UID]\n    else:  # create a new cache directory in the home directory\n        import uuid\n\n        uid = str(uuid.uuid4())\n        sdata.attrs[SopaAttrs.UID] = uid\n        cache_dir = HOME_CACHE_DIR / str(uid)\n\n    cache_dir.mkdir(exist_ok=True, parents=True)\n\n    return cache_dir\n</code></pre>"},{"location":"api/utils/#sopa.utils.delete_cache","title":"<code>sopa.utils.delete_cache(sdata=None)</code>","text":"<p>Delete the cache directory (the entire cache, or the cache of one specific SpatialData object).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData | None</code> <p>The SpatialData object whose cache is to be deleted. If None, the entire cache is deleted.</p> <code>None</code> Source code in <code>sopa/utils/utils.py</code> <pre><code>def delete_cache(sdata: SpatialData | None = None) -&gt; None:\n    \"\"\"Delete the cache directory (the entire cache, or the cache of one specific SpatialData object).\n\n    Args:\n        sdata: The SpatialData object whose cache is to be deleted. If None, the entire cache is deleted.\n    \"\"\"\n    import shutil\n\n    if sdata is not None:\n        cache_dir = get_cache_dir(sdata)\n        shutil.rmtree(cache_dir)\n        return\n\n    for sub_dir in list(HOME_CACHE_DIR.iterdir()):\n        if sub_dir.is_dir():\n            shutil.rmtree(sub_dir)\n</code></pre>"},{"location":"api/utils/#sopa.utils.delete_transcripts_patches_dirs","title":"<code>sopa.utils.delete_transcripts_patches_dirs(sdata)</code>","text":"<p>Delete the cache directories containing the transcript patches (for instance, for Baysor or ComSeg)</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required Source code in <code>sopa/utils/utils.py</code> <pre><code>def delete_transcripts_patches_dirs(sdata: SpatialData):\n    \"\"\"Delete the cache directories containing the transcript patches (for instance, for Baysor or ComSeg)\n\n    Args:\n        sdata: A `SpatialData` object.\n    \"\"\"\n    import shutil\n\n    for patch_dir in get_transcripts_patches_dirs(sdata):\n        shutil.rmtree(patch_dir)\n</code></pre>"},{"location":"api/utils/#accessing-the-elements","title":"Accessing the elements","text":""},{"location":"api/utils/#sopa.utils.get_spatial_element","title":"<code>sopa.utils.get_spatial_element(element_dict, key=None, return_key=False, as_spatial_image=False)</code>","text":"<p>Gets an element from a SpatialData object.</p> <p>Parameters:</p> Name Type Description Default <code>element_dict</code> <code>dict[str, SpatialElement]</code> <p>Dictionnary whose values are spatial elements (e.g., <code>sdata.images</code>).</p> required <code>key</code> <code>str | None</code> <p>Optional element key. If <code>None</code>, returns the only element (if only one).</p> <code>None</code> <code>return_key</code> <code>bool</code> <p>Whether to also return the key of the element.</p> <code>False</code> <code>as_spatial_image</code> <code>bool</code> <p>Whether to return the element as a <code>SpatialImage</code> (if it is a <code>DataTree</code>)</p> <code>False</code> <p>Returns:</p> Type Description <code>SpatialElement | tuple[str, SpatialElement]</code> <p>If <code>return_key</code> is False, only the element is returned, else a tuple <code>(element_key, element)</code></p> Source code in <code>sopa/utils/utils.py</code> <pre><code>def get_spatial_element(\n    element_dict: dict[str, SpatialElement],\n    key: str | None = None,\n    return_key: bool = False,\n    as_spatial_image: bool = False,\n) -&gt; SpatialElement | tuple[str, SpatialElement]:\n    \"\"\"Gets an element from a SpatialData object.\n\n    Args:\n        element_dict: Dictionnary whose values are spatial elements (e.g., `sdata.images`).\n        key: Optional element key. If `None`, returns the only element (if only one).\n        return_key: Whether to also return the key of the element.\n        as_spatial_image: Whether to return the element as a `SpatialImage` (if it is a `DataTree`)\n\n    Returns:\n        If `return_key` is False, only the element is returned, else a tuple `(element_key, element)`\n    \"\"\"\n    assert len(element_dict), \"No spatial element was found in the dict.\"\n\n    if key is not None:\n        assert key in element_dict, f\"Spatial element '{key}' not found.\"\n        return _return_element(element_dict, key, return_key, as_spatial_image)\n\n    assert len(element_dict) &gt; 0, (\n        \"No spatial element found. Provide an element key to denote which element you want to use.\"\n    )\n    assert len(element_dict) == 1, (\n        f\"Multiple valid elements found: {', '.join(element_dict.keys())}. Provide an element key to denote which element you want to use.\"\n    )\n\n    key = next(iter(element_dict.keys()))\n\n    return _return_element(element_dict, key, return_key, as_spatial_image)\n</code></pre>"},{"location":"api/utils/#sopa.utils.get_spatial_image","title":"<code>sopa.utils.get_spatial_image(sdata, key=None, return_key=False, valid_attr=SopaAttrs.CELL_SEGMENTATION)</code>","text":"<p>Gets a DataArray from a SpatialData object (if the image has multiple scale, the <code>scale0</code> is returned)</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>SpatialData object.</p> required <code>key</code> <code>str | None</code> <p>Optional image key. If <code>None</code>, returns the only image (if only one), or tries to find an image with <code>valid_attr</code>.</p> <code>None</code> <code>return_key</code> <code>bool</code> <p>Whether to also return the key of the image.</p> <code>False</code> <code>valid_attr</code> <code>str</code> <p>Attribute that the image must have to be considered valid.</p> <code>CELL_SEGMENTATION</code> <p>Returns:</p> Type Description <code>DataArray | tuple[str, DataArray]</code> <p>If <code>return_key</code> is False, only the image is returned, else a tuple <code>(image_key, image)</code></p> Source code in <code>sopa/utils/utils.py</code> <pre><code>def get_spatial_image(\n    sdata: SpatialData,\n    key: str | None = None,\n    return_key: bool = False,\n    valid_attr: str = SopaAttrs.CELL_SEGMENTATION,\n) -&gt; DataArray | tuple[str, DataArray]:\n    \"\"\"Gets a DataArray from a SpatialData object (if the image has multiple scale, the `scale0` is returned)\n\n    Args:\n        sdata: SpatialData object.\n        key: Optional image key. If `None`, returns the only image (if only one), or tries to find an image with `valid_attr`.\n        return_key: Whether to also return the key of the image.\n        valid_attr: Attribute that the image must have to be considered valid.\n\n    Returns:\n        If `return_key` is False, only the image is returned, else a tuple `(image_key, image)`\n    \"\"\"\n    return get_spatial_element(\n        sdata.images,\n        key=key or sdata.attrs.get(valid_attr),\n        return_key=return_key,\n        as_spatial_image=True,\n    )\n</code></pre>"},{"location":"api/utils/#sopa.utils.get_boundaries","title":"<code>sopa.utils.get_boundaries(sdata, return_key=False, warn=False, key=None, table_key=None)</code>","text":"<p>Gets cell segmentation boundaries of a SpatialData object after running Sopa.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>return_key</code> <code>bool</code> <p>Whether to return the key of the shapes or not.</p> <code>False</code> <code>warn</code> <code>bool</code> <p>If <code>True</code>, prints a warning if no boundary is found. Else, raises an error.</p> <code>False</code> <code>key</code> <code>str | None</code> <p>A valid <code>shapes_key</code> or None.</p> <code>None</code> <code>table_key</code> <code>str | None</code> <p>Name of the table used to find the corresponding boundaries.</p> <code>None</code> <p>Returns:</p> Type Description <code>GeoDataFrame | tuple[str, GeoDataFrame] | None</code> <p>A <code>GeoDataFrame</code> containing the boundaries, or a tuple <code>(shapes_key, geo_df)</code></p> Source code in <code>sopa/utils/utils.py</code> <pre><code>def get_boundaries(\n    sdata: SpatialData,\n    return_key: bool = False,\n    warn: bool = False,\n    key: str | None = None,\n    table_key: str | None = None,\n) -&gt; gpd.GeoDataFrame | tuple[str, gpd.GeoDataFrame] | None:\n    \"\"\"Gets cell segmentation boundaries of a SpatialData object after running Sopa.\n\n    Args:\n        sdata: A SpatialData object\n        return_key: Whether to return the key of the shapes or not.\n        warn: If `True`, prints a warning if no boundary is found. Else, raises an error.\n        key: A valid `shapes_key` or None.\n        table_key: Name of the table used to find the corresponding boundaries.\n\n    Returns:\n        A `GeoDataFrame` containing the boundaries, or a tuple `(shapes_key, geo_df)`\n    \"\"\"\n    assert key is None or table_key is None, \"Provide only one of `key` or `table_key`\"\n\n    if table_key is not None:\n        key = sdata.tables[table_key].uns[ATTRS_KEY][\"region\"]\n        assert isinstance(key, str)\n        return get_spatial_element(sdata.shapes, key=key, return_key=return_key)\n\n    key = key or sdata.attrs.get(SopaAttrs.BOUNDARIES)\n\n    if key is not None:\n        return get_spatial_element(sdata.shapes, key=key, return_key=return_key)\n\n    VALID_BOUNDARIES = [\n        SopaKeys.PROSEG_BOUNDARIES,\n        SopaKeys.BAYSOR_BOUNDARIES,\n        SopaKeys.STARDIST_BOUNDARIES,\n        SopaKeys.COMSEG_BOUNDARIES,\n        SopaKeys.CELLPOSE_BOUNDARIES,\n    ]\n    for key in VALID_BOUNDARIES:\n        res = _try_get_boundaries(sdata, key, return_key)\n        if res is not None:\n            return res\n\n    error_message = \"sdata object has no valid segmentation boundary. Consider running Sopa segmentation first.\"\n\n    if not warn:\n        raise ValueError(error_message)\n\n    log.warning(error_message)\n    return (None, None) if return_key else None\n</code></pre>"},{"location":"api/utils/#sopa.utils.get_intensities","title":"<code>sopa.utils.get_intensities(sdata, table_key=SopaKeys.TABLE)</code>","text":"<p>Gets the intensity dataframe of shape <code>n_obs x n_channels</code></p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>table_key</code> <code>str</code> <p>Key of <code>sdata</code> containing to table from which intensities will be extracted.</p> <code>TABLE</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>A pandas DataFrame containing the intensities, or <code>None</code> if no intensities are found.</p> Source code in <code>sopa/utils/utils.py</code> <pre><code>def get_intensities(sdata: SpatialData, table_key: str = SopaKeys.TABLE) -&gt; pd.DataFrame | None:\n    \"\"\"Gets the intensity dataframe of shape `n_obs x n_channels`\n\n    Args:\n        sdata: A `SpatialData` object.\n        table_key: Key of `sdata` containing to table from which intensities will be extracted.\n\n    Returns:\n        A pandas DataFrame containing the intensities, or `None` if no intensities are found.\n    \"\"\"\n    assert table_key in sdata.tables, f\"No '{table_key}' found in sdata.tables\"\n\n    adata = sdata.tables[table_key]\n\n    if not adata.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_HAS_INTENSITIES]:\n        return None\n\n    if adata.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_HAS_TRANSCRIPTS]:\n        return adata.obsm[SopaKeys.INTENSITIES_OBSM]\n\n    return adata.to_df()\n</code></pre>"},{"location":"api/utils/#sopa.utils.get_channel_names","title":"<code>sopa.utils.get_channel_names(image, image_key=None)</code>","text":"<p>Get the channel names of an image or a SpatialData object.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>DataArray | DataTree | SpatialData</code> <p>Either a <code>DataArray</code>, a <code>DataTree</code>, or a <code>SpatialData</code> object. If a <code>SpatialData</code> object, the <code>image_key</code> argument can be used.</p> required <code>image_key</code> <code>str | None</code> <p>If <code>image</code> is a SpatialData object, the key of the image to get the channel names from. If <code>None</code>, tries to get it automatically.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of channel names.</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def get_channel_names(image: DataArray | DataTree | SpatialData, image_key: str | None = None) -&gt; np.ndarray:\n    \"\"\"Get the channel names of an image or a SpatialData object.\n\n    Args:\n        image: Either a `DataArray`, a `DataTree`, or a `SpatialData` object. If a `SpatialData` object, the `image_key` argument can be used.\n        image_key: If `image` is a SpatialData object, the key of the image to get the channel names from. If `None`, tries to get it automatically.\n\n    Returns:\n        An array of channel names.\n    \"\"\"\n    if isinstance(image, SpatialData):\n        image = get_spatial_image(image, key=image_key)\n\n    if isinstance(image, DataArray):\n        return image.coords[\"c\"].values\n    if isinstance(image, DataTree):\n        return image[\"scale0\"].coords[\"c\"].values\n    raise ValueError(f\"Image must be a DataTree or a DataArray. Found: {type(image)}\")\n</code></pre>"},{"location":"api/utils/#sopa.utils.set_sopa_attrs","title":"<code>sopa.utils.set_sopa_attrs(sdata, cell_segmentation_key=None, tissue_segmentation_key=None, transcripts_key=None, boundaries_key=None, bins_table_key=None)</code>","text":"<p>Stores in the <code>SpatialData</code> object the keys of the main elements used in Sopa. This allows Sopa to retreive with elements should be used for each operation.</p> <p>Info</p> <p>The attrs are already stored in <code>sdata.attrs</code> when reading data with <code>sopa.io</code>. Use this function only if you already stored on disk a SpatialData object without the attrs (with <code>sopa&lt;2.0.0</code>).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object.</p> required <code>cell_segmentation_key</code> <code>str | None</code> <p>Name of the image to be used for cell segmentation (highest resolution image).</p> <code>None</code> <code>tissue_segmentation_key</code> <code>str | None</code> <p>Name of the image to be used for tissue segmentation (medium/low resolution image).</p> <code>None</code> <code>transcripts_key</code> <code>str | None</code> <p>Name of the points containing the transcripts.</p> <code>None</code> <code>boundaries_key</code> <code>str | None</code> <p>Name of the shapes containing the cell boundaries.</p> <code>None</code> <code>bins_table_key</code> <code>str | None</code> <p>Name of the table containing the bins (e.g., for Visium HD data).</p> <code>None</code> Source code in <code>sopa/utils/utils.py</code> <pre><code>def set_sopa_attrs(\n    sdata: SpatialData,\n    cell_segmentation_key: str | None = None,\n    tissue_segmentation_key: str | None = None,\n    transcripts_key: str | None = None,\n    boundaries_key: str | None = None,\n    bins_table_key: str | None = None,\n):\n    \"\"\"Stores in the `SpatialData` object the keys of the main elements used in Sopa.\n    This allows Sopa to retreive with elements should be used for each operation.\n\n    !!! info\n        The attrs are already stored in `sdata.attrs` when reading data with `sopa.io`.\n        Use this function only if you already stored on disk a SpatialData object without the attrs (with `sopa&lt;2.0.0`).\n\n    Args:\n        sdata: A `SpatialData` object.\n        cell_segmentation_key: Name of the image to be used for cell segmentation (highest resolution image).\n        tissue_segmentation_key: Name of the image to be used for tissue segmentation (medium/low resolution image).\n        transcripts_key: Name of the points containing the transcripts.\n        boundaries_key: Name of the shapes containing the cell boundaries.\n        bins_table_key: Name of the table containing the bins (e.g., for Visium HD data).\n    \"\"\"\n    if cell_segmentation_key is not None:\n        assert cell_segmentation_key in sdata.images\n        sdata.attrs[SopaAttrs.CELL_SEGMENTATION] = cell_segmentation_key\n\n    if tissue_segmentation_key is not None:\n        assert tissue_segmentation_key in sdata.images\n        sdata.attrs[SopaAttrs.TISSUE_SEGMENTATION] = tissue_segmentation_key\n\n    if transcripts_key is not None:\n        assert transcripts_key in sdata.points\n        sdata.attrs[SopaAttrs.TRANSCRIPTS] = transcripts_key\n\n    if boundaries_key is not None:\n        assert boundaries_key in sdata.shapes\n        sdata.attrs[SopaAttrs.BOUNDARIES] = boundaries_key\n\n    if bins_table_key is not None:\n        assert bins_table_key in sdata.tables\n        sdata.attrs[SopaAttrs.BINS_TABLE] = bins_table_key\n\n    _save_attrs(sdata)\n</code></pre>"},{"location":"api/utils/#transformations-and-scaling","title":"Transformations and scaling","text":""},{"location":"api/utils/#sopa.utils.to_intrinsic","title":"<code>sopa.utils.to_intrinsic(sdata, element, target_element)</code>","text":"<p>Transforms a <code>SpatialElement</code> into the intrinsic coordinate system of another <code>SpatialElement</code></p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>element</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code> to transform, or its key. We recommend it to choose a vector element (for instance, points or shapes).</p> required <code>target_element</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code> of the target coordinate system, or its key.</p> required <p>Returns:</p> Type Description <code>SpatialElement</code> <p>The <code>element</code> with coordinates transformed to the intrinsic coordinate system of <code>target_element</code>.</p> Source code in <code>sopa/utils/utils.py</code> <pre><code>def to_intrinsic(\n    sdata: SpatialData, element: SpatialElement | str, target_element: SpatialElement | str\n) -&gt; SpatialElement:\n    \"\"\"Transforms a `SpatialElement` into the intrinsic coordinate system of another `SpatialElement`\n\n    Args:\n        sdata: A SpatialData object\n        element: `SpatialElement` to transform, or its key. We recommend it to choose a vector element (for instance, points or shapes).\n        target_element: `SpatialElement` of the target coordinate system, or its key.\n\n    Returns:\n        The `element` with coordinates transformed to the intrinsic coordinate system of `target_element`.\n    \"\"\"\n    element = sdata[element] if isinstance(element, str) else element\n    target_element = sdata[target_element] if isinstance(target_element, str) else target_element\n\n    for cs, transformation in get_transformation(element, get_all=True).items():\n        if isinstance(transformation, Identity):\n            target_transformations = get_transformation(target_element, get_all=True)\n            if isinstance(target_transformations.get(cs), Identity):\n                return element  # no transformation needed\n            break\n\n    try:\n        transformation = get_transformation_between_coordinate_systems(sdata, element, target_element)\n    except:\n        transformations1 = get_transformation(element, get_all=True)\n        transformations2 = get_transformation(target_element, get_all=True)\n\n        common_keys = list(set(transformations1.keys()) &amp; set(transformations2.keys()))\n\n        if not common_keys:\n            raise ValueError(\"No common coordinate system found between the two elements\")\n\n        cs = \"global\" if \"global\" in common_keys else common_keys.pop()\n\n        transformation = Sequence([transformations1[cs], transformations2[cs].inverse()])\n\n    return spatialdata.transform(element, transformation=transformation, maintain_positioning=True)\n</code></pre>"},{"location":"api/utils/#sopa.utils.scale_dtype","title":"<code>sopa.utils.scale_dtype(arr, dtype)</code>","text":"<p>Change the dtype of an array but keep the scale compared to the type maximum value.</p> <p>Example</p> <p>For an array of dtype <code>uint8</code> being transformed to <code>np.uint16</code>, the value <code>255</code> will become <code>65535</code></p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>A <code>numpy</code> array</p> required <code>dtype</code> <code>dtype</code> <p>Target <code>numpy</code> data type</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A scaled <code>numpy</code> array with the dtype provided.</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def scale_dtype(arr: np.ndarray, dtype: np.dtype) -&gt; np.ndarray:\n    \"\"\"Change the dtype of an array but keep the scale compared to the type maximum value.\n\n    !!! note \"Example\"\n        For an array of dtype `uint8` being transformed to `np.uint16`, the value `255` will become `65535`\n\n    Args:\n        arr: A `numpy` array\n        dtype: Target `numpy` data type\n\n    Returns:\n        A scaled `numpy` array with the dtype provided.\n    \"\"\"\n    assert_is_integer_dtype(arr.dtype)\n    assert_is_integer_dtype(dtype)\n\n    if arr.dtype == dtype:\n        return arr\n\n    factor = np.iinfo(dtype).max / np.iinfo(arr.dtype).max\n    return (arr * factor).astype(dtype)\n</code></pre>"},{"location":"api/utils/#sopa.utils.resize_numpy","title":"<code>sopa.utils.resize_numpy(arr, scale_factor, dims, output_shape)</code>","text":"<p>Resize a numpy image</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>a <code>numpy</code> array</p> required <code>scale_factor</code> <code>float</code> <p>Scale factor of resizing, e.g. <code>2</code> will decrease the width by 2</p> required <code>dims</code> <code>list[str]</code> <p>List of dimension names. Only <code>\"x\"</code> and <code>\"y\"</code> are resized.</p> required <code>output_shape</code> <code>list[int]</code> <p>Size of the output array</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Resized array</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def resize_numpy(arr: np.ndarray, scale_factor: float, dims: list[str], output_shape: list[int]) -&gt; np.ndarray:\n    \"\"\"Resize a numpy image\n\n    Args:\n        arr: a `numpy` array\n        scale_factor: Scale factor of resizing, e.g. `2` will decrease the width by 2\n        dims: List of dimension names. Only `\"x\"` and `\"y\"` are resized.\n        output_shape: Size of the output array\n\n    Returns:\n        Resized array\n    \"\"\"\n    resize_dims = [dim in [\"x\", \"y\"] for dim in dims]\n    transform = np.diag([scale_factor if resize_dim else 1 for resize_dim in resize_dims])\n\n    return dask_image.ndinterp.affine_transform(arr, matrix=transform, output_shape=output_shape).compute()\n</code></pre>"},{"location":"api/utils/#cell-type-annotation","title":"Cell-type annotation","text":""},{"location":"api/utils/#sopa.utils.tangram_annotate","title":"<code>sopa.utils.tangram_annotate(sdata, adata_sc, cell_type_key, reference_preprocessing=None, bag_size=10000, max_obs_reference=10000, density_prior='uniform', clip_percentile=0.95)</code>","text":"<p>Tangram multi-level annotation. Tangram is run on multiple bags of cells to decrease the RAM usage.</p> <p>Info</p> <p>You need to install <code>tangram-sc</code> to use this function. You can install it via <code>pip install tangram-sc</code>.</p> <p>Multi-level annotation</p> <p>If multi-level annotation is used (see <code>cell_type_key</code> argument), Tangram is first run on level 0. Then, for each cell-type, Tangram is run again within its annotated subset to assign subtypes. This process continues recursively, with each level processed within the cells labeled at the previous level.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData | AnnData</code> <p>A <code>SpatialData</code> object containing an AnnData table, or the AnnData table itself.</p> required <code>adata_sc</code> <code>AnnData</code> <p>A scRNAseq annotated reference containing cell types in <code>adata_sc.obs[cell_type_key]</code>. If it has been pre-processed, you can provide the <code>reference_preprocessing</code> argument to apply the same preprocessing on the spatial data. If containing raw counts, the spatial table should also contain raw counts.</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata_sc.obs</code> containing the cell types. For multi-level annotation, provide other levels like such: if <code>cell_type_key = \"ct\"</code>, then <code>\"ct_level1\"</code> and <code>\"ct_level2\"</code> are the two next levels.</p> required <code>reference_preprocessing</code> <code>str | None</code> <p>Preprocessing method that was already applied on the reference. Can be <code>\"log1p\"</code> (normalize_total + log1p) or <code>\"normalized\"</code> (just normalize_total). If provided, it will apply the same preprocessing on the spatial data before running Tangram. By default, no preprocessing is applied.</p> <code>None</code> <code>bag_size</code> <code>int</code> <p>Size of each bag on which tangram will be run. Use smaller bags to lower the RAM usage. If <code>bag_size</code> is too small, it might create less consistent results across bags.</p> <code>10000</code> <code>max_obs_reference</code> <code>int</code> <p>Maximum number of cells used in <code>adata_sc</code> at each level. Decrease it to lower the RAM usage.</p> <code>10000</code> <code>density_prior</code> <code>str</code> <p>Density prior used in Tangram. Can be <code>\"uniform\"</code> or <code>\"rna_count_based\"</code>.</p> <code>'uniform'</code> <code>clip_percentile</code> <code>float</code> <p>Percentile used to clip the probabilities before taking the maximum (to obtain hard cell-type labels from probabilities).</p> <code>0.95</code> Source code in <code>sopa/utils/annotation.py</code> <pre><code>def tangram_annotate(\n    sdata: SpatialData | AnnData,\n    adata_sc: AnnData,\n    cell_type_key: str,\n    reference_preprocessing: str | None = None,\n    bag_size: int = 10_000,\n    max_obs_reference: int = 10_000,\n    density_prior: str = \"uniform\",\n    clip_percentile: float = 0.95,\n):\n    \"\"\"Tangram multi-level annotation. Tangram is run on multiple bags of cells to decrease the RAM usage.\n\n    !!! info\n        You need to install `tangram-sc` to use this function. You can install it via `pip install tangram-sc`.\n\n    !!! info \"Multi-level annotation\"\n        If multi-level annotation is used (see `cell_type_key` argument), Tangram is first run on level 0. Then, for each cell-type, Tangram is run again within its annotated subset to assign subtypes. This process continues recursively, with each level processed within the cells labeled at the previous level.\n\n    Args:\n        sdata: A `SpatialData` object containing an AnnData table, or the AnnData table itself.\n        adata_sc: A scRNAseq annotated reference containing cell types in `adata_sc.obs[cell_type_key]`. If it has been pre-processed, you can provide the `reference_preprocessing` argument to apply the same preprocessing on the spatial data. If containing raw counts, the spatial table should also contain raw counts.\n        cell_type_key: Key of `adata_sc.obs` containing the cell types. For multi-level annotation, provide other levels like such: if `cell_type_key = \"ct\"`, then `\"ct_level1\"` and `\"ct_level2\"` are the two next levels.\n        reference_preprocessing: Preprocessing method that was already applied on the reference. Can be `\"log1p\"` (normalize_total + log1p) or `\"normalized\"` (just normalize_total). If provided, it will apply the same preprocessing on the spatial data before running Tangram. By default, no preprocessing is applied.\n        bag_size: Size of each bag on which tangram will be run. Use smaller bags to lower the RAM usage. If `bag_size` is too small, it might create less consistent results across bags.\n        max_obs_reference: Maximum number of cells used in `adata_sc` at each level. Decrease it to lower the RAM usage.\n        density_prior: Density prior used in Tangram. Can be `\"uniform\"` or `\"rna_count_based\"`.\n        clip_percentile: Percentile used to clip the probabilities before taking the maximum (to obtain hard cell-type labels from probabilities).\n    \"\"\"\n    if isinstance(sdata, SpatialData):\n        assert SopaKeys.TABLE in sdata.tables, f\"No '{SopaKeys.TABLE}' table found in sdata.tables\"\n        ad_sp = sdata.tables[SopaKeys.TABLE]\n    else:\n        assert isinstance(sdata, AnnData), \"sdata must be a SpatialData object or an AnnData object\"\n        ad_sp = sdata\n\n    if reference_preprocessing is None and sum(adata.X.max() &gt; 10 for adata in [ad_sp, adata_sc]) == 1:\n        log.warning(\n            \"It seems that the spatial data is not pre-processed the same way as the reference, but `reference_preprocessing` is not set. \"\n            \"Either provide the `reference_preprocessing` argument or pre-process both AnnData the same way before running Tangram.\"\n        )\n\n    MultiLevelAnnotation(\n        ad_sp,\n        adata_sc,\n        cell_type_key,\n        reference_preprocessing,\n        bag_size,\n        max_obs_reference,\n        density_prior,\n        clip_percentile,\n    ).run()\n</code></pre>"},{"location":"api/utils/#sopa.utils.higher_z_score","title":"<code>sopa.utils.higher_z_score(adata, marker_cell_dict, cell_type_key='cell_type')</code>","text":"<p>Simple channel-based segmentation using a marker-to-population dictionary</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>marker_cell_dict</code> <code>dict</code> <p>Dictionary whose keys are channels, and values are the corresponding populations.</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata.obs</code> where annotations will be stored</p> <code>'cell_type'</code> Source code in <code>sopa/utils/annotation.py</code> <pre><code>def higher_z_score(adata: AnnData, marker_cell_dict: dict, cell_type_key: str = \"cell_type\"):\n    \"\"\"Simple channel-based segmentation using a marker-to-population dictionary\n\n    Args:\n        adata: An `AnnData` object\n        marker_cell_dict: Dictionary whose keys are channels, and values are the corresponding populations.\n        cell_type_key: Key of `adata.obs` where annotations will be stored\n    \"\"\"\n    adata.obsm[SopaKeys.Z_SCORES] = preprocess_fluo(adata)\n\n    markers, cell_types = list(marker_cell_dict.keys()), np.array(list(marker_cell_dict.values()))\n    ct_indices = adata.obsm[SopaKeys.Z_SCORES][markers].values.argmax(1)\n\n    adata.obs[cell_type_key] = cell_types[ct_indices]\n    adata.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_CELL_TYPES] = [cell_type_key]\n\n    log.info(f\"Annotation counts: {adata.obs[cell_type_key].value_counts()}\")\n</code></pre>"},{"location":"api/utils/#sopa.utils.preprocess_fluo","title":"<code>sopa.utils.preprocess_fluo(adata)</code>","text":"<p>Preprocess fluorescence data. For each column \\(X\\), we compute \\(asinh(\\frac{X}{5Q(0.2, X)})\\) and apply standardization</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A dataframe of preprocessed channels intensities</p> Source code in <code>sopa/utils/annotation.py</code> <pre><code>def preprocess_fluo(adata: AnnData) -&gt; pd.DataFrame:\n    \"\"\"Preprocess fluorescence data. For each column $X$, we compute $asinh(\\\\frac{X}{5Q(0.2, X)})$ and apply standardization\n\n    Args:\n        adata: An `AnnData` object\n\n    Returns:\n        A dataframe of preprocessed channels intensities\n    \"\"\"\n    df = adata.obsm[SopaKeys.INTENSITIES_OBSM] if SopaKeys.INTENSITIES_OBSM in adata.obsm else adata.to_df()\n\n    divider = 5 * np.quantile(df, 0.2, axis=0)\n    divider[divider == 0] = df.max(axis=0)[divider == 0]\n\n    scaled = np.arcsinh(df / divider)\n    return (scaled - scaled.mean(0)) / scaled.std(0)\n</code></pre>"},{"location":"tutorials/align/","title":"Align","text":"In\u00a0[1]: Copied! <pre>import sopa\n</pre> import sopa <pre>/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/numba/core/decorators.py:246: RuntimeWarning: nopython is set for njit and is ignored\n  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n</pre> In\u00a0[2]: Copied! <pre>sdata = sopa.io.toy_dataset(as_output=True)\n</pre> sdata = sopa.io.toy_dataset(as_output=True) <pre>[INFO] (sopa.utils.data) Image of size ((4, 2048, 2048)) with 400 cells and 100 transcripts per cell\n[INFO] (sopa.aggregation.transcripts) Aggregating transcripts over 400 cells\n</pre> <pre>[########################################] | 100% Completed | 243.12 ms\n</pre> <pre>[INFO] (sopa.aggregation.channels) Averaging channels intensity over 400 cells with expansion expand_radius_ratio=0\n</pre> <pre>[########################################] | 100% Completed | 105.32 ms\n</pre> <pre>/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:96: UserWarning: Key `cellpose_boundaries` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n</pre> In\u00a0[3]: Copied! <pre>sopa.io.explorer.write(\"data.explorer\", sdata)\n</pre> sopa.io.explorer.write(\"data.explorer\", sdata) <pre>[INFO] (sopa.io.explorer.table) Writing table with 6 columns\n[INFO] (sopa.io.explorer.table) Writing 2 cell categories: region, slide\n[INFO] (sopa.io.explorer.shapes) Writing 400 cell polygons\n[INFO] (sopa.io.explorer.points) Writing 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 0: 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 1: 10000 transcripts\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (4, 2048, 2048)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 2048, 2048)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 1024, 1024)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 512, 512)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 256, 256)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 128, 128)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 64, 64)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: data.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open data.explorer/experiment.xenium'\n</pre> In\u00a0[4]: Copied! <pre>image = sopa.io.ome_tif(\"example_image.tif\", as_image=True)\nsopa.io.explorer.write_image(\"data.explorer/image.ome.tif\", image, is_dir=False)\n</pre> image = sopa.io.ome_tif(\"example_image.tif\", as_image=True) sopa.io.explorer.write_image(\"data.explorer/image.ome.tif\", image, is_dir=False) <pre>[WARNING] (sopa.io.reader.utils) Channel names couldn't be read. Using ['0'] instead.\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (1, 480, 640)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (1, 480, 640)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (1, 240, 320)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (1, 120, 160)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (1, 60, 80)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (1, 30, 40)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (1, 15, 20)\n</pre> In\u00a0[5]: Copied! <pre>sopa.io.explorer.align(sdata, image, \"image_test_matrix.csv\")\n</pre> sopa.io.explorer.align(sdata, image, \"image_test_matrix.csv\") <pre>[INFO] (sopa.io.explorer.images) Added image example_image - aligned with the Xenium Explorer\n</pre> In\u00a0[6]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[8]: Copied! <pre>sdata.pl.render_images(\"image\").pl.render_images(\"example_image\").pl.show(\"global\")\n</pre> sdata.pl.render_images(\"image\").pl.render_images(\"example_image\").pl.show(\"global\") <pre>INFO     Rasterizing image for faster rendering.                                                                   \n</pre> <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.9530949634755863].\n</pre> In\u00a0[10]: Copied! <pre>del sdata.images[\"example_image\"]\n</pre> del sdata.images[\"example_image\"] In\u00a0[11]: Copied! <pre>sdata.write(\"data.zarr\")\n</pre> sdata.write(\"data.zarr\") <pre>INFO     The Zarr backing store has been changed from None the new file path: data.zarr                            \n</pre> In\u00a0[\u00a0]: Copied! <pre># command to test it\n\"\"\"\nsopa explorer add-aligned data.zarr example_image.tif image_test_matrix.csv\n\"\"\"\n</pre> # command to test it \"\"\" sopa explorer add-aligned data.zarr example_image.tif image_test_matrix.csv \"\"\""},{"location":"tutorials/align/","title":"Landmark-based alignment","text":"<p>You can align any omic layer by defining manual landmark annotations. This can either be done via the Xenium Explorer, or <code>napari-spatialdata</code>.</p>"},{"location":"tutorials/align/#via-the-xenium-explorer","title":"Via the Xenium Explorer","text":"<p>You'll need two things for alignment with the Xenium Explorer:</p> <ul> <li>A <code>SpatialData</code> object (see <code>sopa.io</code>) and it's corresponding Xenium Explorer directory (see next section).</li> <li>An image (usually <code>.tif</code> or <code>.ome.tif</code>) that you want to align to the <code>SpatialData</code> object.</li> </ul> <p>Xenium Explorer is a registered trademark of 10x Genomics. The Xenium Explorer is licensed for usage on Xenium data (more details here).</p>"},{"location":"tutorials/align/#explorer-data","title":"Explorer data","text":"<p>If not done yet, convert your <code>SpatialData</code> object to the Xenium Explorer's inputs. This can be done as detailed in this tutorial. For instance:</p> <pre><code>import spatialdata\nimport sopa\n\nsdata = spatialdata.read_zarr(\"/path/to/your/data.zarr\")\n\nsopa.io.explorer.write(\"data.explorer\", sdata)\n</code></pre> <p>This will create a <code>experiment.xenium</code> file under <code>data.explorer</code> that you'll use later to open the data in the Xenium Explorer.</p>"},{"location":"tutorials/align/#image-conversion","title":"Image conversion","text":"<p>You need to have the right image format for the Xenium Explorer. Here, we convert the image you want to align to the right format.</p> <p>Xenium users</p> <p>If using the Xenium machine, then you don't need conversion; the images provided by the Xenium machine already have the correct format.</p> <p>You can convert the image with QuPath as written in this 10x genomics webpage. Otherwise, if you are not familiar with QuPath, you can also use our API to write the image: <pre><code># use sopa.io.ome_tif to read your image, or any reader from sopa.io, e.g. sopa.io.wsi\nimage = sopa.io.ome_tif(\"path/to/your/image.tif\", as_image=True)\n\n# write this image so that it can be open with the Xenium Explorer\nsopa.io.explorer.write_image(\"my_image.ome.tif\", image, is_dir=False)\n</code></pre></p>"},{"location":"tutorials/align/#keypoint-placement","title":"Keypoint placement","text":"<p>Warning</p> <p>Make sure your Xenium Explorer version is at least <code>1.3.0</code></p> <p>Double-click on the <code>experiment.xenium</code> file to open the Xenium Explorer, or select this file from the Xenium Explorer interface. It will display the data in the explorer.</p> <p>On the Xenium Explorer, under the \"Images\" panel, click \"Add image\" and follow the instructions on the screen (you'll need to choose the image you created in the previous section).</p> <p> </p> <p>Afterwards, the explorer will automatically align the images based on the key points you selected on both images.</p>"},{"location":"tutorials/align/#update-your-spatialdata-object","title":"Update your SpatialData object","text":"<p>After alignment, export the transformation matrix as a <code>.csv</code> file. For that, select your aligned image under the \"Images\" panel and click on \"Download Alignment File\":</p> <p> </p> <p>Then, select only the \"Transformation Matrix\" box and download it:</p> <p> </p> <p>Via the API, you can now update your <code>SpatialData</code> object as follows: <pre><code># specify below the location of the matrix.csv file:\nsopa.io.explorer.align(sdata, image, \"image_test_matrix.csv\")\n</code></pre></p> <p>Via the CLI, you'll need the path to the <code>.zarr</code> directory corresponding to your <code>SpatialData</code> object (<code>SDATA_PATH</code>), the path to the <code>.ome.tif</code> image that you converted above (<code>IMAGE_PATH</code>), and the <code>.csv</code> transformation matrix that you exported from the Xenium Explorer (<code>TRANSFORMATION_MATRIX_PATH</code>):</p> <pre><code>sopa explorer add-aligned &lt;SDATA_PATH&gt; &lt;IMAGE_PATH&gt; &lt;TRANSFORMATION_MATRIX_PATH&gt;\n</code></pre>"},{"location":"tutorials/align/#via-napari-spatialdata","title":"Via napari-spatialdata","text":"<p>Intead of the Xenium Explorer, you can also use <code>napari-spatialdata</code> to align images.</p> <p>Refer to this existing tutorial for more details.</p>"},{"location":"tutorials/api_usage/","title":"API usage","text":"In\u00a0[\u00a0]: Copied! <pre>import spatialdata\n\nimport sopa\n</pre> import spatialdata  import sopa In\u00a0[6]: Copied! <pre>sdata = sopa.io.toy_dataset(genes=500)  # you can use `sopa.io.merscope` / `sopa.io.xenium` / ...\n\nsdata\n</pre> sdata = sopa.io.toy_dataset(genes=500)  # you can use `sopa.io.merscope` / `sopa.io.xenium` / ...  sdata <pre>[INFO] (sopa.utils.data) Image of size (4, 2048, 2048) with 400 cells and 100 transcripts per cell\n</pre> Out[6]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 1024, 1024), (3, 512, 512), (3, 256, 256)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u2514\u2500\u2500 Shapes\n      \u2514\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), transcripts (Points), cells (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> In\u00a0[\u00a0]: Copied! <pre>sdata.write(\"tuto.zarr\")\n\nsdata = spatialdata.read_zarr(\"tuto.zarr\")  # we can read the data back\n</pre> sdata.write(\"tuto.zarr\")  sdata = spatialdata.read_zarr(\"tuto.zarr\")  # we can read the data back <p>Note that, when your data is saved on-disk, Sopa will automatically save on-disk any new spatial element such as the cells boundaries. To disable this behavior, you can use <code>sopa.settings.auto_save_on_disk = False</code>.</p> In\u00a0[4]: Copied! <pre>sopa.segmentation.tissue(sdata)\n</pre> sopa.segmentation.tissue(sdata) <pre>[INFO] (sopa.segmentation._tissue) Using image_key='he_image' and mode='saturation' as default\n</pre> <p>Now, we have a <code>\"region_of_interest\"</code> GeoDataFrame (see below) which contains the contour of the tissue.</p> In\u00a0[5]: Copied! <pre>sdata\n</pre> sdata Out[5]: <pre>SpatialData object, with associated Zarr store: /Users/quentinblampey/dev/sopa/docs/tutorials/tuto.zarr\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 1024, 1024), (3, 512, 512), (3, 256, 256)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u2514\u2500\u2500 Shapes\n      \u251c\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\n      \u2514\u2500\u2500 'region_of_interest': GeoDataFrame shape: (2, 1) (2D shapes)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), transcripts (Points), cells (Shapes), region_of_interest (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>On a real tissue, the <code>'region_of_interest'</code> could look like the black line below. This plot can be done via <code>spatialdata_plot</code> (see the end of this tutorial for more visualization approaches).</p> <p> </p> <p>Instead of segmenting the tissue, it's possible to select interactively a region of interest (ROI) via <code>napari-spatialdata</code>, as shown in this tutorial.</p> <p>Important: provide the name <code>region_of_interest</code> to your selection, and save it inside your SpatialData object with <code>Shift + E</code>.</p> <p>Later on, the segmentation will only be run inside the region of interest, and not outside.</p> In\u00a0[8]: Copied! <pre>sopa.make_image_patches(sdata, patch_width=1200, patch_overlap=50)\n</pre> sopa.make_image_patches(sdata, patch_width=1200, patch_overlap=50) <pre>[INFO] (sopa.patches._patches) Added 4 patch(es) to sdata['image_patches']\n</pre> <p>The following channels are available for segmentation. Choose one or two channels used by Cellpose.</p> In\u00a0[9]: Copied! <pre>sopa.utils.get_channel_names(sdata)\n</pre> sopa.utils.get_channel_names(sdata) Out[9]: <pre>array(['DAPI', 'CK', 'CD3', 'CD20'], dtype='&lt;U4')</pre> <p>Then, we run Cellpose via the <code>sopa.segmentation.cellpose</code> function.</p> <p>Here, we run segmentation using <code>\"DAPI\"</code> only, and we set the cell diameter to be about <code>35</code> pixels. Note that the diameter parameter is very important with <code>cellpose&lt;4.0.0</code>: you can refer to this guide to get default parameters according to your technology.</p> <p>If using <code>cellpose&gt;4.0.0</code>, we recommend passing the <code>gpu=True</code> argument to use CUDA/MPS, as the network is bigger than in earlier versions.</p> <p>NB: to make is faster, you can also set a parallelization backend as below. See here for more parallelization details.</p> In\u00a0[6]: Copied! <pre># optional: set the parallelization backend to use dask\nsopa.settings.parallelization_backend = \"dask\"\n</pre> # optional: set the parallelization backend to use dask sopa.settings.parallelization_backend = \"dask\" In\u00a0[\u00a0]: Copied! <pre># recommended: use gpu=True is you have a GPU and cellpose&gt;4.0.0\nsopa.segmentation.cellpose(sdata, channels=[\"DAPI\"], diameter=35, gpu=True)\n</pre> # recommended: use gpu=True is you have a GPU and cellpose&gt;4.0.0 sopa.segmentation.cellpose(sdata, channels=[\"DAPI\"], diameter=35, gpu=True) <p>Now, we see that we have the <code>\"cellpose_boundaries\"</code> inside the <code>sdata</code> object:</p> In\u00a0[11]: Copied! <pre>sdata\n</pre> sdata Out[11]: <pre>SpatialData object, with associated Zarr store: /Users/quentinblampey/dev/sopa/docs/tutorials/tuto.zarr\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 1024, 1024), (3, 512, 512), (3, 256, 256)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u2514\u2500\u2500 Shapes\n      \u251c\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (393, 1) (2D shapes)\n      \u251c\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\n      \u2514\u2500\u2500 'image_patches': GeoDataFrame shape: (4, 3) (2D shapes)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), transcripts (Points), cellpose_boundaries (Shapes), cells (Shapes), image_patches (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>To use Baysor, make sure you have correctly installed it, as in our getting started instructions.</p> <p>Baysor needs a config to be executed, but Sopa can create one for you if you use a <code>prior_shapes_key</code> (see below). You can find official Baysor config examples here, or reuse the Baysor parameter we have defined for each machine in our Snakemake config files.</p> <p>First, we generate the bounding boxes of the patches on which Baysor will be run. Here, the patches have a width and height of <code>500</code> microns and an overlap of <code>50</code> microns (default value). We advise bigger sizes for real datasets (see our default parameters in one of our config files).</p> <p>NB: in this example, we pass <code>prior_shapes_key=\"cellpose_boundaries\"</code>, which means that Baysor will use the cellpose segmentation as a prior. You can also remove the argument if you don't want it, or use <code>prior_shapes_key=\"auto\"</code> if your technology already has a prior. More details in the sopa.make_transcript_patches API.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.make_transcript_patches(sdata, patch_width=500, prior_shapes_key=\"cellpose_boundaries\")\n</pre> sopa.make_transcript_patches(sdata, patch_width=500, prior_shapes_key=\"cellpose_boundaries\") <pre>[########################################] | 100% Completed | 519.54 ms\n</pre> <pre>[INFO] (sopa.patches._transcripts) 1 patche(s) were added to sdata['transcripts_patches']\n</pre> <p>Then, we run Baysor via the <code>sopa.segmentation.baysor</code> function.</p> <p>NB: to make is faster, we can set a parallelization backend as below. See here for more parallelization details. If Baysor is too slow, you can also try <code>Proseg</code> in the next section.</p> In\u00a0[12]: Copied! <pre># optional: set the parallelization backend to use dask\nsopa.settings.parallelization_backend = \"dask\"\n</pre> # optional: set the parallelization backend to use dask sopa.settings.parallelization_backend = \"dask\" In\u00a0[11]: Copied! <pre>sopa.segmentation.baysor(sdata, min_area=10)\n</pre> sopa.segmentation.baysor(sdata, min_area=10) <pre>[INFO] (sopa.segmentation.methods._baysor) No config provided, inferring a default Baysor config.\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:46&lt;00:00, 46.64s/it]\n[INFO] (sopa.segmentation._transcripts) Cells whose area is less than 10 microns^2 will be removed\nReading transcript-segmentation outputs:   0%|          | 0/1 [00:00&lt;?, ?it/s]OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\nReading transcript-segmentation outputs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00,  1.60it/s]\nResolving conflicts: 0it [00:00, ?it/s]\n[INFO] (sopa.segmentation._transcripts) Added sdata.tables['table'], and 267 cell boundaries to sdata['baysor_boundaries']\n</pre> In\u00a0[8]: Copied! <pre>sopa.make_transcript_patches(sdata, patch_width=None, prior_shapes_key=\"auto\")\n</pre> sopa.make_transcript_patches(sdata, patch_width=None, prior_shapes_key=\"auto\") <pre>[########################################] | 100% Completed | 105.68 ms\n</pre> <pre>[INFO] (sopa.patches._transcripts) Added 1 patche(s) to sdata['transcripts_patches']\n</pre> <p>Then, we run Proseg via the <code>sopa.segmentation.proseg</code> function.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.segmentation.proseg(sdata)\n</pre> sopa.segmentation.proseg(sdata) In\u00a0[\u00a0]: Copied! <pre>sopa.aggregate(sdata)\n</pre> sopa.aggregate(sdata) <p>Now, in the <code>SpatialData</code> object, there is a <code>\"table\"</code> element (which is an <code>AnnData</code> object, see below).</p> In\u00a0[13]: Copied! <pre>adata = sdata[\"table\"]\nadata\n</pre> adata = sdata[\"table\"] adata Out[13]: <pre>AnnData object with n_obs \u00d7 n_vars = 393 \u00d7 500\n    obs: 'region', 'slide', 'cell_id', 'area'\n    uns: 'sopa_attrs', 'spatialdata_attrs'\n    obsm: 'intensities', 'spatial'</pre> <p>What's inside adata depends on your technology:</p> <ul> <li>If you have transcripts/bins, then <code>adata.X</code> are the raw counts</li> <li>Else, <code>adata.X</code> are the channels intensities</li> <li>If you both count the transcript/bins and average the intensities, then <code>adata.X</code> are the raw counts, and <code>adata.obsm[\"intensities\"]</code> are the channels intensities (as above)</li> </ul> In\u00a0[\u00a0]: Copied! <pre>import anndata\n\nadata_reference = anndata.read_h5ad(\"adata_reference.h5ad\")\n\nsopa.utils.tangram_annotate(sdata, adata_reference, \"cell_type\")\n</pre> import anndata  adata_reference = anndata.read_h5ad(\"adata_reference.h5ad\")  sopa.utils.tangram_annotate(sdata, adata_reference, \"cell_type\") In\u00a0[14]: Copied! <pre>marker_cell_dict = {\"CK\": \"Tumoral cell\", \"CD20\": \"B cell\", \"CD3\": \"T cell\"}\n\nsopa.utils.higher_z_score(sdata.tables[\"table\"], marker_cell_dict)\n</pre> marker_cell_dict = {\"CK\": \"Tumoral cell\", \"CD20\": \"B cell\", \"CD3\": \"T cell\"}  sopa.utils.higher_z_score(sdata.tables[\"table\"], marker_cell_dict) <pre>[INFO] (sopa.utils.annotation) Annotation counts: cell_type\nTumoral cell    138\nT cell          132\nB cell          123\nName: count, dtype: int64\n</pre> In\u00a0[25]: Copied! <pre>sopa.io.explorer.write(\"tuto.explorer\", sdata)\n</pre> sopa.io.explorer.write(\"tuto.explorer\", sdata) <pre>[INFO] (sopa.io.explorer.table) Writing table with 5 columns\n[INFO] (sopa.io.explorer.table) Writing 4 cell categories: image_name, region, slide, cell_type\n[INFO] (sopa.io.explorer.shapes) Writing 372 cell polygons\n[INFO] (sopa.io.explorer.points) Writing 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 0: 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 1: 10000 transcripts\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (4, 2048, 2048)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 2048, 2048)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 1024, 1024)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 512, 512)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 256, 256)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 128, 128)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 64, 64)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre> <p>If you have downloaded the Xenium Explorer, you can now open the results in the explorer: simply double-click on the <code>tuto.explorer/experiment.xenium</code> file. For more advanced usage of the Xenium Explorer, refer to this tutorial.</p> In\u00a0[15]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[16]: Copied! <pre>sdata.pl.render_images(\"image\").pl.render_shapes(\n    \"cellpose_boundaries\", outline_alpha=1, fill_alpha=0, outline_color=\"#fff\"\n).pl.show(\"global\")\n</pre> sdata.pl.render_images(\"image\").pl.render_shapes(     \"cellpose_boundaries\", outline_alpha=1, fill_alpha=0, outline_color=\"#fff\" ).pl.show(\"global\") <pre>INFO     Rasterizing image for faster rendering.                                                                   \n</pre> <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.9530949634755863].\n</pre> In\u00a0[\u00a0]: Copied! <pre>from napari_spatialdata import Interactive\n\nInteractive(sdata)\n</pre> from napari_spatialdata import Interactive  Interactive(sdata) In\u00a0[20]: Copied! <pre>sopa.io.write_report(\"report.html\", sdata)\n</pre> sopa.io.write_report(\"report.html\", sdata) <pre>[INFO] (sopa.io.report.generate) Writing general_section\n[INFO] (sopa.io.report.generate) Writing cell_section\n[INFO] (sopa.io.report.generate) Writing channel_section\n[INFO] (sopa.io.report.generate) Writing transcripts_section\n[INFO] (sopa.io.report.generate) Writing representation_section\n[INFO] (sopa.io.report.generate) Computing UMAP on 268 cells\n[INFO] (sopa.io.report.generate) Writing report to report.html\n</pre> In\u00a0[\u00a0]: Copied! <pre>sdata.write(\"tuto.zarr\")\n</pre> sdata.write(\"tuto.zarr\") <p>This way, you'll be able to open it later for further analysis, using <code>spatialdata.read_zarr(\"tuto.zarr\")</code>.</p> <p>Now, here is a list of ressources you may consider to go further:</p> <ul> <li>This tutorial on spatial statistic and geometric analysis.</li> <li>Use Squidpy which operates on both the <code>SpatialData</code> object or the <code>AnnData</code> object, or use other tools of the <code>scverse</code> ecosystem such as <code>Scanpy</code>.</li> <li>You can also try the CLI or the Snakemake pipeline of Sopa.</li> </ul>"},{"location":"tutorials/api_usage/#api-usage","title":"API usage\u00b6","text":""},{"location":"tutorials/api_usage/#context","title":"Context\u00b6","text":"<p>Sopa is built on top of the <code>spatialdata</code> library, the core scverse data structure, which can be seen as an extension of <code>AnnData</code> for spatial omics.</p> <p>It means that Sopa will manipulate <code>SpatialData</code> objects, that we usually denote by <code>sdata</code>.</p>"},{"location":"tutorials/api_usage/#create-a-spatialdata-object","title":"Create a SpatialData object\u00b6","text":"<p>The first step is to create a <code>SpatialData</code> object from your raw data. To do so, you need to use the function from <code>sopa.io</code> that is specific to your technology. If you don't know which raw files you need, refer to this FAQ section.</p> <p>For instance, for MERSCOPE data: <code>sdata = sopa.io.merscope(\"/path/to/region_0\")</code>.</p> <p>For the sake of this tutorial, we use a synthetic dataset:</p>"},{"location":"tutorials/api_usage/#saving-your-data-optional","title":"Saving your data (optional)\u00b6","text":"<p>Now that you have a <code>SpatialData</code> object, you can write it on-disk as below.</p> <p>It creates a <code>.zarr</code> directory that can later be open back via <code>spatialdata.read_zarr</code>.</p> <p>This step is highly recommended (although optionnal) as it can considerably speed-up the next steps.</p>"},{"location":"tutorials/api_usage/#tissue-segmentation-optional","title":"Tissue segmentation (optional)\u00b6","text":"<p>If desired, the tissue can be segmented (i.e., defining the contour of the tissue). This can be useful mostly for sparse tissues, as we will not run segmentation on patches that are outside of the tissue.</p> <p>This tissue segmentation is either using an H&amp;E image, or a staining image (e.g., with DAPI). For more details, refer to the documentation of <code>sopa.segmentation.tissue</code>.</p> <p>Note that, here, we have two images, but Sopa decides on which image the tissue segmentation is run. See the FAQ to understand how Sopa handles this.</p>"},{"location":"tutorials/api_usage/#alternative-using-napari","title":"Alternative using napari\u00b6","text":""},{"location":"tutorials/api_usage/#cell-segmentation","title":"Cell segmentation\u00b6","text":"<p>For cell segmentation, multiple choices are available: <code>cellpose</code>, <code>baysor</code>, <code>comseg</code>, or even a combination of them (e.g., <code>baysor</code> with <code>cellpose</code> as a prior).</p>"},{"location":"tutorials/api_usage/#cellpose","title":"Cellpose\u00b6","text":"<p>First, we generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p>"},{"location":"tutorials/api_usage/#baysor","title":"Baysor\u00b6","text":""},{"location":"tutorials/api_usage/#proseg","title":"Proseg\u00b6","text":"<p>Proseg also uses the transcript information to improve the segmentation. Its usage is very similar to Baysor, except that we need the <code>prior_shapes_key</code> argument, and must set <code>patch_width=None</code> to run on only one patch.</p> <p>Before to use <code>proseg</code>, make sure you have installed it as detailed in our getting started section.</p> <p>NB: many technologies already assigned each transcript to a prior, in that case you can use <code>prior_shapes_key=\"auto\"</code>. Else, you can run <code>Cellpose</code> as detailed above and use <code>prior_shapes_key=\"cellpose_boundaries\"</code>. More details in the sopa.make_transcript_patches API.</p>"},{"location":"tutorials/api_usage/#aggregation","title":"Aggregation\u00b6","text":"<p>The purpose of <code>sopa.aggregate</code> is to create an <code>AnnData</code> object of features per cell. Depending on your technology, it will count the transcript/bins inside each cell, and/or average each channel intensity inside each cell boundary.</p> <p>More specifically:</p> <ul> <li>For bins technologies like Visium HD data: for each cell, it will sum the transcript counts of all bins that are touching this cell.</li> <li>For transcript-based technologies like MERSCOPE/Xenium, it will count the transcripts inside each cells, and optionally average the channel intensities</li> <li>For multiplex imaging data, it will average the intensity of each channel inside each cell</li> </ul> <p>You don't need to specify any argument, whatever the technology you use. See here to understand how Sopa knows which elements to use for aggregation.</p>"},{"location":"tutorials/api_usage/#annotation-optional","title":"Annotation (optional)\u00b6","text":"<p>Annotation within Sopa is totally optionnal. These annotations tools were optimized for annotation of large data, but feel free to perform your own.</p>"},{"location":"tutorials/api_usage/#transcript-based-tangram","title":"Transcript-based (Tangram)\u00b6","text":"<p>Tangram is a transcript-based annotation that uses an annotated single-cell reference. Let's suppose your reference <code>AnnData</code> object is stored in a file called <code>adata_reference.h5ad</code> (preferably, keep raw counts), and the cell type is in <code>adata.obs[\"cell_type\"]</code>. Then, you can annotate your spatial data as follows:</p>"},{"location":"tutorials/api_usage/#staining-based","title":"Staining-based\u00b6","text":"<p>For now, our fluorescence-based annotation is very simple. We provide a dictionary where a channel is associated with a population. Then, each cell is associated with the cell type whose corresponding channel is the brightest (according to a certain Z-score). In this tutorial example, we can annotate Tumoral cells, T cells, and B cells:</p>"},{"location":"tutorials/api_usage/#visualization","title":"Visualization\u00b6","text":"<p>Many visualization tools can be used. Here, we show three of them, with different capabilities.</p>"},{"location":"tutorials/api_usage/#with-the-xenium-explorer","title":"With the Xenium Explorer\u00b6","text":"<p>The Xenium Explorer is a software developed by 10X Genomics for visualizing spatial data, and it can be downloaded freely here. This is the most user-friendly visualizer of the three, but it may not show all the spatial element from your <code>SpatialData</code> object (it only shows images, transcripts, and cell boundaries).</p> <p>Sopa allows the conversion of your SpatialData object to the Xenium Explorer.</p> <p>The command below creates some files under a new <code>tuto.explorer</code> directory:</p>"},{"location":"tutorials/api_usage/#with-spatialdata-plot","title":"With spatialdata-plot\u00b6","text":"<p><code>spatialdata-plot</code> library is a static plotting library for <code>SpatialData</code> objects. This solution is very convenient when working in Jupyter Notebooks.</p>"},{"location":"tutorials/api_usage/#with-napari-spatialdata","title":"With napari-spatialdata\u00b6","text":"<p><code>napari-spatialdata</code> is a plugin for Napari developed to visualize your SpatialData objects. This visualizer is very flexible, as you can display any spatial element, and you can directly save annotations from Napari in your SpatialData object.</p> <p>You can install it via <code>pip install 'napari-spatialdata[all]'</code></p>"},{"location":"tutorials/api_usage/#pipeline-report","title":"Pipeline report\u00b6","text":"<p>You can optionally create an HTML report of the pipeline run (in the example below, we save it under <code>report.html</code>). It contains some quality controls for your data.</p>"},{"location":"tutorials/api_usage/#further-analyses","title":"Further analyses\u00b6","text":"<p>If not done yet, you can save your <code>SpatialData</code> object, as below. It will create a <code>.zarr</code> directory.</p> <p>If you already saved your <code>SpatialData</code> object, you don't need to save it again, because all elements are automatically saved by default (see here to change this setting).</p>"},{"location":"tutorials/cli_usage/","title":"Command line interface","text":"<p>When installing <code>sopa</code> as written in our getting-started guidelines, a new command named <code>sopa</code> becomes available.</p> <p>Warning</p> <p>The Snakemake pipeline is recommended to get started with Sopa. Using the CLI is advised if you want more flexibility, but you'll need to parallelize the segmentation yourself, as detailed below.</p>"},{"location":"tutorials/cli_usage/#cli-helper","title":"CLI helper","text":"<p>Run <code>sopa --help</code> to get details about all the command line purposes. You can also use this helper on any subcommand, for instance, <code>sopa convert --help</code>.</p> <pre><code>// Run the Sopa CLI helper\n$ sopa --help\n Usage: sopa [OPTIONS] COMMAND [ARGS]...\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 aggregate     Aggregate transcripts/channels inside cells      \u2502\n\u2502 annotate      Perform cell-type annotation                     \u2502\n\u2502 crop          Crop an image based on a user-defined polygon    \u2502\n\u2502 explorer      Conversion to the Xenium Explorer's inputs       \u2502\n\u2502 patchify      Create patches with overlaps                     \u2502\n\u2502 read          Read any technology + write a SpatialData object \u2502\n\u2502 report        Create a web-report with figures/QCs             \u2502\n\u2502 resolve       Resolve the segmentation conflicts over patches  \u2502\n\u2502 segmentation  Perform cell segmentation on patches             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n// Example: run cellpose segmentation\n$ sopa segmentation cellpose sdata.zarr\n... [Logs] ...\n</code></pre>"},{"location":"tutorials/cli_usage/#save-the-spatialdata-object","title":"Save the <code>SpatialData</code> object","text":"<p>For this tutorial, we use a generated dataset. You can expect a total runtime of a few minutes.</p> <p>The command below will generate and save it on disk (you can change the path <code>tuto.zarr</code> to save it somewhere else). If you want to load your own data: choose the right panel below. For more information, refer to this FAQ describing which data input you need, or run <code>sopa convert --help</code>.</p> TutorialXeniumMERSCOPECosMxPhenoCyclerMACSimaOther <pre><code># it will generate a 'tuto.zarr' directory\nsopa convert . --sdata-path tuto.zarr --technology toy_dataset\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa convert /path/to/sample/directory --technology xenium\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa convert /path/to/sample/directory --technology merscope\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa convert /path/to/sample/directory --technology cosmx\n</code></pre> <pre><code># it will generate a '/path/to/sample.zarr' directory\nsopa convert /path/to/sample.qptiff --technology phenocycler\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa convert /path/to/sample/directory --technology macsima\n</code></pre> <p>There are also several other readers, such as <code>hyperion</code>, or <code>molecular_cartography</code>. You can also try generic readers, like <code>ome_tif</code>, or even <code>bioio</code> which supports many inputs formats. Note that, to use <code>bioio</code>, you'll need to <code>pip install bioio</code> and potentially other format-specific dependencies as described in their documentation.</p> <p>Replace <code>&lt;TECHNOLOGY&gt;</code> by the right name on the following command line: <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa convert /path/to/sample/directory --technology &lt;TECHNOLOGY&gt;\n</code></pre></p> <p>Info</p> <p>It has created a <code>.zarr</code> directory which stores a <code>SpatialData</code> object corresponding to your data sample. You can choose the location of the <code>.zarr</code> directory using the <code>--sdata-path</code> command line argument.</p>"},{"location":"tutorials/cli_usage/#run-segmentation","title":"Run segmentation","text":""},{"location":"tutorials/cli_usage/#option-1-cellpose","title":"Option 1: Cellpose","text":"<p>First, generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Now, we can run Cellpose on each individual patch. You can either run it directly on all patches (first option below), or on each patch individually (second option - ideal if you want to parallelize it yourself).</p> Run all patches at onceRun on each patch <p>The easiest way to run Cellpose is to use the command below, which directly run Cellpose on all patches and resolve the segmentation. You can add an additional channel, for instance, you can use <code>--channels DAPI --channels PolyT</code>.</p> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000\n</code></pre> <p>By default, this will run cellpose sequentially. To make it run it parallel, you can export the following env variable: <code>export SOPA_PARALLELIZATION_BACKEND=dask</code>.</p> <p>Execute the following command line on all <code>patch-index</code> (i.e., <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>) to run Cellpose using DAPI only (you can add an additional channel, for instance, <code>--channels DAPI --channels PolyT</code>):</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. This will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in our Snakefile. If you prefer using the already existing pipeline instead of the CLI, you can read our Snakemake pipeline tutorial.</p> <p>To automatically get the number of patches, you can either open the <code>tuto.zarr/.sopa_cache/patches_file_image</code> file, or compute <code>len(sdata['image_patches'])</code> in Python.</p> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n</code></pre> <p>At this stage, you executed 4 times Cellpose (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches: <pre><code>sopa resolve cellpose tuto.zarr\n</code></pre></p> <p>Note</p> <p>In the above commands, the <code>--diameter</code> and <code>--min-area</code> parameters are specific to the data type we work on. For your own data, consider using the default parameters from one of our config files. Here, <code>min-area</code> is in pixels^2.</p>"},{"location":"tutorials/cli_usage/#option-2-baysor","title":"Option 2: Baysor","text":"<p>Baysor needs a config to be executed. You can find official config examples here.</p> <p>Note</p> <p>You can also reuse the Baysor parameter we have defined for each machine, as in our Snakemake config files. Note that, our Snakemake config is a <code>.yaml</code> file, but the Baysor config should still be a <code>.toml</code> file.</p> <p>For this tutorial, we will use the config below. Save this in a <code>config.toml</code> file. <pre><code>[data]\nforce_2d = true\nmin_molecules_per_cell = 10\nx = \"x\"\ny = \"y\"\nz = \"z\"\ngene = \"genes\"\nmin_molecules_per_gene = 0\nmin_molecules_per_segment = 3\nconfidence_nn_id = 6\n\n[segmentation]\nscale = 6         # typical cell radius in microns (IMPORTANT)\nscale_std = \"25%\" # cell radius standard deviation\nprior_segmentation_confidence = 0\nestimate_scale_from_centers = false\nn_clusters = 4\niters = 500\nn_cells_init = 0\nnuclei_genes = \"\"\ncyto_genes = \"\"\n</code></pre></p> <p>Then, we generate the bounding boxes of the patches on which Baysor will be run. Here, the patches have a width and height of 200 microns. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify transcripts tuto.zarr --patch-width-microns 200 --prior-shapes-key cellpose_boundaries\n</code></pre> <p>As for cellpose, you can either run Baysor directly on all patches, or on each patch individually. You can provide the config argument as an inline dictionnary, or as a path to a <code>.toml</code> file, as below.</p> Run all patches at onceRun on each patch <p>The easiest way to run Baysor is to use the command below, which directly run Baysor on all patches and resolve the segmentation.</p> <pre><code>sopa segmentation baysor tuto.zarr --config '\"config.toml\"'\n</code></pre> <p>By default, this will run baysor sequentially. To make it run it parallel, you can export the following env variable: <code>export SOPA_PARALLELIZATION_BACKEND=dask</code>.</p> <p>Now, we can run Baysor on each individual patch. Execute the following command lines to run Baysor on each patch (i.e., <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>).</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. This will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in the Sopa Snakemake pipeline.</p> <p>To automatically get the number of patches, you can open the <code>tuto.zarr/.sopa_cache/patches_file_transcripts</code> file. This lists the names of the directories inside <code>tuto.zarr/.sopa_cache/baysor</code> related to each patch. If you selected an ROI, the excluded patches are effectively not in the <code>patches_file_transcripts</code> file.</p> <pre><code>sopa segmentation baysor tuto.zarr --config '\"config.toml\"' --patch-index 0\n\nsopa segmentation baysor tuto.zarr --config '\"config.toml\"' --patch-index 1\n\nsopa segmentation baysor tuto.zarr --config '\"config.toml\"' --patch-index 2\n\nsopa segmentation baysor tuto.zarr --config '\"config.toml\"' --patch-index 3\n</code></pre> <p>At this stage, you executed 4 times Baysor (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches: <pre><code>sopa resolve baysor tuto.zarr --gene-column genes\n</code></pre></p>"},{"location":"tutorials/cli_usage/#option-3-custom-staining-based","title":"Option 3: Custom staining-based","text":"<p>As for Cellpose, we generate the bounding boxes of the patches on which staining-based segmentation will be run.</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>With the <code>sopa segmentation generic-staining</code> command, you can use a custom segmentation method, with the signature described here (or any function named <code>*_patch</code> from this file).</p> <p>For instance, we can use <code>stardist_patch</code> directly from the CLI as below.</p> <pre><code>sopa segmentation generic-staining tuto.zarr --method-name stardist_patch\n</code></pre> <p>Warning</p> <p>The toy dataset is not H&amp;E based, so stardist will fail on this example because of the number of channels. To create the right number of channels on the toy dataset, you can use the following command: <pre><code>sopa convert . --sdata-path tuto.zarr --technology toy_dataset --kwargs '{\"c_coords\": [\"r\", \"g\", \"b\"]}'\n</code></pre></p>"},{"location":"tutorials/cli_usage/#aggregation","title":"Aggregation","text":"<p>This mandatory step turns the data into an <code>AnnData</code> object. We can count the transcript inside each cell, and/or average each channel intensity inside each cell boundary.</p> Count transcripts + average intensitiesCount transcriptsAverage intensities <pre><code>sopa aggregate tuto.zarr --aggregate-genes --aggregate-channels --min-transcripts 10\n</code></pre> <pre><code>sopa aggregate tuto.zarr --aggregate-genes --min-transcripts 10\n</code></pre> <pre><code>sopa aggregate tuto.zarr --aggregate-channels\n</code></pre>"},{"location":"tutorials/cli_usage/#annotation","title":"Annotation","text":"<p>If desired, cell-type annotation can be run. Currently, we support Tangram for transcript-based annotation and a simple scoring approach for channel-based annotation (called channel z-score).</p> Channel Z-score annotationTangram annotation <p>For now, our fluorescence-based annotation is very simple. We provide a dictionary where a channel is associated with a population. Then, each cell is associated with the cell type whose corresponding channel is the brightest (according to a certain Z-score). In this tutorial example, we can annotate Tumoral cells, T cells, and B cells: <pre><code>sopa annotate fluorescence tuto.zarr --marker-cell-dict '{\"CK\": \"Tumoral cell\", \"CD3\": \"T cell\", \"CD20\": \"B cell\"}'\n</code></pre></p> <p>More complex annotation</p> <p>If you have a large number of channels, it may be preferable to run clustering on your data, for instance, using Leiden clustering. Then, you can annotate each cluster manually by plotting a heatmap of all channels expressions per cluster.</p> <p>Tangram is a transcript-based annotation that uses an annotated single-cell reference. Let's suppose your reference <code>AnnData</code> object is stored in a file called <code>adata_reference.h5ad</code> (preferably, keep raw counts), and the cell type is in <code>adata.obs[\"cell_type\"]</code>. Then, you can annotate your spatial data as follows: <pre><code>sopa annotate tangram tuto.zarr --sc-reference-path adata_reference.h5ad --cell-type-key cell_type\n</code></pre></p>"},{"location":"tutorials/cli_usage/#pipeline-report","title":"Pipeline report","text":"<p>You can optionally create an HTML report of the pipeline run (in the example below, we save it under <code>report.html</code>). It contains some quality controls for your data.</p> <pre><code>sopa report tuto.zarr report.html\n</code></pre>"},{"location":"tutorials/cli_usage/#visualization-xenium-explorer","title":"Visualization (Xenium Explorer)","text":"<p>The Xenium Explorer is a software developed by 10X Genomics for visualizing spatial data, and it can be downloaded freely here. Sopa allows the conversion to the Xenium Explorer. It will create some files under a new <code>tuto.explorer</code> directory:</p> <pre><code>sopa explorer write tuto.zarr\n</code></pre> <p>If you have downloaded the Xenium Explorer, you can now open the results in the explorer: <code>open tuto.explorer/experiment.xenium</code> (if using a Unix operating system), or double-click on the latter file.</p> <p>License</p> <p>Xenium Explorer is a registered trademark of 10x Genomics. The Xenium Explorer is licensed for usage on Xenium data (more details here).</p> <p>Time efficiency</p> <p>Creating the image needed by the Xenium Explorer can be time-consuming. Therefore, we recommend performing one run for the image generation (below) and another to save the transcripts/boundaries/observations. <pre><code># this can be done directly after saving the raw data in a .zarr directory\nsopa explorer write tuto.zarr --mode \"+i\" --no-save-h5ad\n</code></pre></p> <p>After running everything with Sopa, you can finally save all the other Xenium Explorer input (e.g. boundaries and cell categories): <pre><code># this should be done after aggregation and an eventual annotation\nsopa explorer write tuto.zarr --mode \"-i\"\n</code></pre> For more details and customization, run the command line helper with <code>sopa explorer write --help</code>.</p>"},{"location":"tutorials/cli_usage/#further-analyses","title":"Further analyses","text":"<ul> <li>If you are familiar with the <code>spatialdata</code> library, you can directly use the <code>tuto.zarr</code> directory, corresponding to a <code>SpatialData</code> object: <pre><code>import spatialdata\n\nsdata = spatialdata.read_zarr(\"tuto.zarr\")\n</code></pre></li> <li>You can use Squidpy which operates on both the <code>SpatialData</code> object or the <code>AnnData</code> object, or use other tools of the <code>scverse</code> ecosystem such as <code>Scanpy</code>.</li> <li>You can also use the file <code>tuto.explorer/adata.h5ad</code> if you prefer the <code>AnnData</code> object instead of the full <code>SpatialData</code> object.</li> </ul>"},{"location":"tutorials/compare_segmentations/","title":"Comparing segmentations","text":"In\u00a0[1]: Copied! <pre>import spatialdata\n\nimport sopa\n</pre> import spatialdata  import sopa <p>As usual, we will show this example on a toy dataset.</p> In\u00a0[2]: Copied! <pre>sdata_full = sopa.io.toy_dataset()\n</pre> sdata_full = sopa.io.toy_dataset() <pre>[INFO] (sopa.utils.data) Image of size ((4, 2048, 2048)) with 400 cells and 100 transcripts per cell\n</pre> In\u00a0[4]: Copied! <pre>sdata_full\n</pre> sdata_full Out[4]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 1024, 1024), (3, 512, 512), (3, 256, 256)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u251c\u2500\u2500 'misc': DataFrame with shape: (&lt;Delayed&gt;, 2) (2D points)\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u2514\u2500\u2500 Shapes\n      \u2514\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), misc (Points), transcripts (Points), cells (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Here, we subset our <code>sdata_full</code> object based on a bounding from of width <code>1000</code> pixels. You can look at the above coordinates to choose an appropriate bounding box.</p> <p>Then, we save this crop as a new <code>.zarr</code> directory.</p> In\u00a0[5]: Copied! <pre>sdata = sdata_full.query.bounding_box(\n    axes=[\"y\", \"x\"], min_coordinate=[0, 0], max_coordinate=[1000, 1000], target_coordinate_system=\"global\"\n)\n\nsdata.write(\"subset.zarr\")\nsdata = spatialdata.read_zarr(\"subset.zarr\")  # read the data from the zarr directory\n</pre> sdata = sdata_full.query.bounding_box(     axes=[\"y\", \"x\"], min_coordinate=[0, 0], max_coordinate=[1000, 1000], target_coordinate_system=\"global\" )  sdata.write(\"subset.zarr\") sdata = spatialdata.read_zarr(\"subset.zarr\")  # read the data from the zarr directory <pre>INFO     The Zarr backing store has been changed from None the new file path: subset.zarr                          \n</pre> In\u00a0[6]: Copied! <pre>sopa.make_image_patches(sdata)\nsopa.make_transcript_patches(sdata)\n</pre> sopa.make_image_patches(sdata) sopa.make_transcript_patches(sdata) <pre>[INFO] (sopa.patches._patches) 1 patches were added to sdata['image_patches']\n</pre> <pre>[########################################] | 100% Completed | 106.04 ms\n</pre> <pre>[INFO] (sopa.patches._transcripts) 1 patche(s) were added to sdata['transcripts_patches']\n</pre> In\u00a0[\u00a0]: Copied! <pre>sopa.segmentation.cellpose(sdata, \"DAPI\", diameter=35, key_added=\"cellpose_DAPI_35\")\n\nsopa.segmentation.cellpose(sdata, [\"DAPI\", \"CK\"], diameter=15, key_added=\"cellpose_DAPI_CK_15\")\n\nsopa.segmentation.baysor(sdata, scale=2, key_added=\"baysor_scale_2\")\n</pre> sopa.segmentation.cellpose(sdata, \"DAPI\", diameter=35, key_added=\"cellpose_DAPI_35\")  sopa.segmentation.cellpose(sdata, [\"DAPI\", \"CK\"], diameter=15, key_added=\"cellpose_DAPI_CK_15\")  sopa.segmentation.baysor(sdata, scale=2, key_added=\"baysor_scale_2\") <p>Now, inside the shapes, with all our three segmentations: <code>'cellpose_DAPI_35'</code>, <code>'cellpose_DAPI_CK_15'</code>, and <code>'baysor_scale_2'</code>.</p> In\u00a0[9]: Copied! <pre>list(sdata.shapes.keys())\n</pre> list(sdata.shapes.keys()) Out[9]: <pre>['cells',\n 'image_patches',\n 'transcripts_patches',\n 'cellpose_DAPI_35',\n 'cellpose_DAPI_CK_15',\n 'baysor_scale_2']</pre> <p>Then, we can aggregate the transcripts inside the cells. Since we have multiple shapes layers, we need to precise <code>shapes_key</code>.</p> <p>Also, we can set a specific name for the table that will be created (via <code>key_added</code>), or keep <code>key_added=None</code> which will use the name <code>\"{shapes_key}_table\"</code> by default.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.aggregate(sdata, shapes_key=\"cellpose_DAPI_35\", key_added=None)\nsopa.aggregate(sdata, shapes_key=\"cellpose_DAPI_CK_15\", key_added=None)\nsopa.aggregate(sdata, shapes_key=\"baysor_scale_2\", key_added=None)\n</pre> sopa.aggregate(sdata, shapes_key=\"cellpose_DAPI_35\", key_added=None) sopa.aggregate(sdata, shapes_key=\"cellpose_DAPI_CK_15\", key_added=None) sopa.aggregate(sdata, shapes_key=\"baysor_scale_2\", key_added=None) <p>Now, we have one table for each shape layer:</p> In\u00a0[11]: Copied! <pre>list(sdata.tables.keys())\n</pre> list(sdata.tables.keys()) Out[11]: <pre>['table',\n 'cellpose_DAPI_35_table',\n 'cellpose_DAPI_CK_15_table',\n 'baysor_scale_2_table']</pre> In\u00a0[12]: Copied! <pre># the different table names that were created\ntable_names = [\"cellpose_DAPI_35_table\", \"cellpose_DAPI_CK_15_table\", \"baysor_scale_2_table\"]\n</pre> # the different table names that were created table_names = [\"cellpose_DAPI_35_table\", \"cellpose_DAPI_CK_15_table\", \"baysor_scale_2_table\"] In\u00a0[13]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[14]: Copied! <pre># Cellpose on DAPI with diameter 35\nsdata.pl.render_images(\"image\").pl.render_shapes(\n    \"cellpose_DAPI_35\", fill_alpha=0, outline_color=\"#fff\", outline_alpha=1\n).pl.show(\"global\")\n\n# Cellpose on DAPI and CK with diameter 15\nsdata.pl.render_images(\"image\").pl.render_shapes(\n    \"cellpose_DAPI_CK_15\", fill_alpha=0, outline_color=\"#fff\", outline_alpha=1\n).pl.show(\"global\")\n\n# Baysor with scale 2\nsdata.pl.render_images(\"image\").pl.render_shapes(\n    \"baysor_scale_2\", fill_alpha=0, outline_color=\"#fff\", outline_alpha=1\n).pl.show(\"global\")\n</pre> # Cellpose on DAPI with diameter 35 sdata.pl.render_images(\"image\").pl.render_shapes(     \"cellpose_DAPI_35\", fill_alpha=0, outline_color=\"#fff\", outline_alpha=1 ).pl.show(\"global\")  # Cellpose on DAPI and CK with diameter 15 sdata.pl.render_images(\"image\").pl.render_shapes(     \"cellpose_DAPI_CK_15\", fill_alpha=0, outline_color=\"#fff\", outline_alpha=1 ).pl.show(\"global\")  # Baysor with scale 2 sdata.pl.render_images(\"image\").pl.render_shapes(     \"baysor_scale_2\", fill_alpha=0, outline_color=\"#fff\", outline_alpha=1 ).pl.show(\"global\") <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.9530949634755863].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.9530949634755863].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.9530949634755863].\n</pre> In\u00a0[15]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n</pre> import matplotlib.pyplot as plt import seaborn as sns In\u00a0[17]: Copied! <pre>for name in table_names:\n    adata = sdata.tables[name]\n    n_cells = adata.n_obs\n    total_count = adata.X.sum()\n    transcript_counts = adata.X.sum(axis=1).A1\n    mean_count_per_cell = transcript_counts.mean()\n\n    print(f\"Table: {name}, {n_cells=}, {total_count=}, {mean_count_per_cell=:.2f}\")\n    sns.displot(transcript_counts, kde=True)\n    plt.title(\"Distribution of transcript counts per cell\")\n    plt.show()\n</pre> for name in table_names:     adata = sdata.tables[name]     n_cells = adata.n_obs     total_count = adata.X.sum()     transcript_counts = adata.X.sum(axis=1).A1     mean_count_per_cell = transcript_counts.mean()      print(f\"Table: {name}, {n_cells=}, {total_count=}, {mean_count_per_cell=:.2f}\")     sns.displot(transcript_counts, kde=True)     plt.title(\"Distribution of transcript counts per cell\")     plt.show() <pre>Table: cellpose_DAPI_35_table, n_cells=95, total_count=9460, mean_count_per_cell=99.58\n</pre> <pre>Table: cellpose_DAPI_CK_15_table, n_cells=163, total_count=8240, mean_count_per_cell=50.55\n</pre> <pre>Table: baysor_scale_2_table, n_cells=96, total_count=9565, mean_count_per_cell=99.64\n</pre> In\u00a0[18]: Copied! <pre>import scanpy as sc\n</pre> import scanpy as sc In\u00a0[19]: Copied! <pre>for name in table_names:\n    adata = sdata.tables[name]\n    sc.pp.normalize_total(adata)\n    sc.pp.log1p(adata)\n    sc.pp.neighbors(adata)\n    sc.tl.umap(adata)\n    sc.tl.leiden(adata)\n\n    sc.pl.umap(adata, color=\"leiden\")\n    plt.show()\n</pre> for name in table_names:     adata = sdata.tables[name]     sc.pp.normalize_total(adata)     sc.pp.log1p(adata)     sc.pp.neighbors(adata)     sc.tl.umap(adata)     sc.tl.leiden(adata)      sc.pl.umap(adata, color=\"leiden\")     plt.show() <pre>/var/folders/rl/nsddz37s55zbfg5h7b060rlc0000gn/T/ipykernel_28535/1797552473.py:7: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n  sc.tl.leiden(adata)\n</pre> <pre>/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:234: UserWarning: Some cells have zero counts\n  warn(UserWarning(\"Some cells have zero counts\"))\n</pre>"},{"location":"tutorials/compare_segmentations/#comparing-segmentations","title":"Comparing segmentations\u00b6","text":"<p>This tutorial aims to show how testing multiple segmentation methods (e.g. Cellpose/Proseg/Baysor/Comseg) or different set of segmentation parameters to compare them and find the best segmentation.</p> <p>We will run three segmentations, and compare them: Cellpose with two sets of parameters, and also Baysor.</p>"},{"location":"tutorials/compare_segmentations/#cropping-your-data","title":"Cropping your data\u00b6","text":"<p>This step is optional, although recommended. Indeed, cropping the data allows to quickly run multiple segmentation methods with multiple parameters, and compare them. Afterwards, you can keep the best segmentation method/parameters, and run it on the full dataset.</p>"},{"location":"tutorials/compare_segmentations/#creating-the-patches","title":"Creating the patches\u00b6","text":"<p>As usual, we create the patches for the segmentation.</p>"},{"location":"tutorials/compare_segmentations/#running-multiple-segmentations","title":"Running multiple segmentations\u00b6","text":"<p>We run three segmentations:</p> <ul> <li>Cellpose on DAPI only, with <code>diameter=35</code></li> <li>Cellpose on DAPI and CK, with <code>diameter=15</code></li> <li>Baysor, with <code>scale=2</code> microns (expected cell radius).</li> </ul> <p>Note that we use <code>key_added</code> to precise the name that we want to give to each segmentation.</p>"},{"location":"tutorials/compare_segmentations/#comparison","title":"Comparison\u00b6","text":"<p>Now, we can compare the different shapes / tables to see which segmentation method or which parameters were the best. We show some simple analysis below that can help us decide between the three.</p> <p>Feel free to perform more sophisticated quality checks.</p>"},{"location":"tutorials/compare_segmentations/#visual-comparison","title":"Visual comparison\u00b6","text":"<p>We can plot the images / shapes / transcripts to visually find the best segmentation. Here, we can definitely see that <code>\"cellpose_DAPI_CK_15\"</code> is not good, as the cells are very small. It appears that <code>diameter=15</code> was not a good Cellpose parameter for this image.</p>"},{"location":"tutorials/compare_segmentations/#tables-comparison","title":"Tables comparison\u00b6","text":"<p>We can also compute some simple quality controls, such as the mean transcript count per cell, or the distribution of transcript count. Again, we see that cellpose with <code>diameter=15</code> was worse than the two other segmentations.</p>"},{"location":"tutorials/compare_segmentations/#umap-comparisons","title":"UMAP comparisons\u00b6","text":"<p>We can also compute a UMAP on all tables, and look which table gives the best separation. Here, it seems that Baysor is slightly cleaner.</p>"},{"location":"tutorials/compare_segmentations/#next-steps","title":"Next steps\u00b6","text":"<p>After the above comparison, you should have found the right method / parameters for your dataset.</p> <p>You can now use these parameters to run Sopa on the full slide or cohort. For that, refer to the other tutorials, for instance the API or Snakemake tutorials.</p>"},{"location":"tutorials/comseg/","title":"ComSeg usage","text":"In\u00a0[1]: Copied! <pre>import sopa\n</pre> import sopa In\u00a0[2]: Copied! <pre>### Load the data\nsdata = sopa.io.toy_dataset()  # here, we use the toy dataset\n\nsopa.make_image_patches(sdata, patch_width=1200, patch_overlap=50)\n\nsopa.segmentation.cellpose(sdata, [\"DAPI\"], diameter=35)\n</pre> ### Load the data sdata = sopa.io.toy_dataset()  # here, we use the toy dataset  sopa.make_image_patches(sdata, patch_width=1200, patch_overlap=50)  sopa.segmentation.cellpose(sdata, [\"DAPI\"], diameter=35) <pre>[INFO] (sopa.utils.data) Image of size ((4, 2048, 2048)) with 400 cells and 100 transcripts per cell\n[INFO] (sopa.patches._patches) 4 patches were added to sdata['image_patches']\n[WARNING] (sopa._settings) Running without parallelization backend can be slow. Consider using a backend, e.g. via `sopa.settings.parallelization_backend = 'dask'`, or `export SOPA_PARALLELIZATION_BACKEND=dask`.\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:38&lt;00:00,  9.65s/it]\n[INFO] (sopa.segmentation._stainings) Found 411 total cells\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 118/118 [00:00&lt;00:00, 7700.76it/s]\n[INFO] (sopa.segmentation._stainings) Added 372 cell boundaries in sdata['cellpose_boundaries']\n</pre> In\u00a0[3]: Copied! <pre>sopa.make_transcript_patches(\n    sdata,\n    prior_shapes_key=\"cellpose_boundaries\",\n    write_cells_centroids=True,\n    patch_width=200,\n)\n</pre> sopa.make_transcript_patches(     sdata,     prior_shapes_key=\"cellpose_boundaries\",     write_cells_centroids=True,     patch_width=200, ) <pre>[########################################] | 100% Completed | 455.53 ms\n</pre> <pre>[INFO] (sopa.patches._transcripts) 4 patche(s) were added to sdata['transcripts_patches']\n</pre> In\u00a0[4]: Copied! <pre># the config dictionary is optional. If not provided, it will be inferred\nconfig = {\n    \"dict_scale\": {\"x\": 1, \"y\": 1, \"z\": 1},  # spot coordinates already in \u00b5m\n    \"mean_cell_diameter\": 15,\n    \"max_cell_radius\": 25,\n    \"norm_vector\": False,\n    \"alpha\": 0.5,  # alpha value to compute the polygon https://pypi.org/project/alphashape/\n    \"allow_disconnected_polygon\": False,\n    \"min_rna_per_cell\": 5,  # minimal number of RNAs for a cell to be taken into account\n    \"gene_column\": \"genes\",\n}\n\nsopa.segmentation.comseg(sdata, config)\n</pre> # the config dictionary is optional. If not provided, it will be inferred config = {     \"dict_scale\": {\"x\": 1, \"y\": 1, \"z\": 1},  # spot coordinates already in \u00b5m     \"mean_cell_diameter\": 15,     \"max_cell_radius\": 25,     \"norm_vector\": False,     \"alpha\": 0.5,  # alpha value to compute the polygon https://pypi.org/project/alphashape/     \"allow_disconnected_polygon\": False,     \"min_rna_per_cell\": 5,  # minimal number of RNAs for a cell to be taken into account     \"gene_column\": \"genes\", }  sopa.segmentation.comseg(sdata, config) <pre>[WARNING] (sopa._settings) Running without parallelization backend can be slow. Consider using a backend, e.g. via `sopa.settings.parallelization_backend = 'dask'`, or `export SOPA_PARALLELIZATION_BACKEND=dask`.\n  0%|          | 0/4 [00:00&lt;?, ?it/s]OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/comseg/clustering.py:154: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n  sc.tl.leiden(adata, resolution=resolution)\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:42&lt;00:00, 10.53s/it]\nReading transcript-segmentation outputs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 30.89it/s]\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 524/524 [00:00&lt;00:00, 6987.80it/s]\n[INFO] (sopa.segmentation._transcripts) Aggregating transcripts on merged cells\n[INFO] (sopa.aggregation.transcripts) Aggregating transcripts over 160 cells\n/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/anndata/_core/storage.py:48: FutureWarning: AnnData previously had undefined behavior around matrices of type &lt;class 'scipy.sparse._coo.coo_matrix'&gt;.In 0.12, passing in this type will throw an error. Please convert to a supported type.Continue using for this minor version at your own risk.\n  warnings.warn(msg, FutureWarning)\n</pre> <pre>[########################################] | 100% Completed | 368.71 ms\n</pre> <pre>[INFO] (sopa.segmentation._transcripts) Added sdata.tables['table'], and 372 cell boundaries to sdata['comseg_boundaries']\n</pre> In\u00a0[5]: Copied! <pre>sopa.aggregate(sdata)\n</pre> sopa.aggregate(sdata) <pre>[INFO] (sopa.aggregation.aggregation) Using existing table for aggregation\n[WARNING] (sopa.aggregation.aggregation) sdata.table is already existing. Transcripts are not count again.\n[INFO] (sopa.aggregation.channels) Aggregating channels intensity over 372 cells with mode='average'\n</pre> <pre>[########################################] | 100% Completed | 103.84 ms\n</pre> <pre>[INFO] (sopa.aggregation.aggregation) Filtering 0 cells\n/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:96: UserWarning: Key `comseg_boundaries` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/dev/sopa/sopa/aggregation/aggregation.py:195: ImplicitModificationWarning: Setting element `.obsm['intensities']` of view, initializing view as actual.\n  self.table.obsm[SopaKeys.INTENSITIES_OBSM] = pd.DataFrame(\n/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:96: UserWarning: Key `comseg_boundaries` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:116: UserWarning: Key `table` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n</pre> In\u00a0[6]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[7]: Copied! <pre>sdata.pl.render_images(\"image\").pl.render_shapes(\n    \"comseg_boundaries\", outline_alpha=1, fill_alpha=0, outline_color=\"w\"\n).pl.show(\"global\")\n</pre> sdata.pl.render_images(\"image\").pl.render_shapes(     \"comseg_boundaries\", outline_alpha=1, fill_alpha=0, outline_color=\"w\" ).pl.show(\"global\") <pre>INFO     Rasterizing image for faster rendering.                                                                   \n</pre> <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.9530949634755863].\n</pre> <p>You can also use the Xenium Explorer:</p> In\u00a0[8]: Copied! <pre>sopa.io.write(\"tuto.explorer\", sdata)\n</pre> sopa.io.write(\"tuto.explorer\", sdata) <pre>[INFO] (sopa.io.explorer.table) Writing table with 5 columns\n[INFO] (sopa.io.explorer.table) Writing 2 cell categories: region, slide\n[INFO] (sopa.io.explorer.shapes) Writing 372 cell polygons\n[INFO] (sopa.io.explorer.points) Writing 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 0: 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 1: 10000 transcripts\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (4, 2048, 2048)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 2048, 2048)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 1024, 1024)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 512, 512)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 256, 256)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 128, 128)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 64, 64)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre>"},{"location":"tutorials/comseg/#comseg-usage","title":"ComSeg usage\u00b6","text":"<p>ComSeg is a transcript-based segmentation method that creates a KNN graph of RNA molecules, weighted by the co-expression of RNA species. Initially, this KNN graph is partitioned into communities of RNAs likely to belong to the same cell. ComSeg then merges these RNA communities to compute the final cell segmentation. The method uses nucleus segmentation as prior to initialize the partitioning of the KNN graph of RNA molecules. ComSeg only segments cells with their nuclei segmented and does not take into account cells without missing nucleus.</p> <p>If nucleus segmentation is not available, ComSeg can operate using other staining segmentation or solely nucleus centroids obtained from other sources. For more details, please refer to the ComSeg documentation.</p>"},{"location":"tutorials/comseg/#requirements","title":"Requirements\u00b6","text":"<p>To use ComSeg, run <code>pip install comseg</code> in the same environment as <code>sopa</code>. For more installation options, refer to their installation guide.</p> <p>Then, choose one the the three use cases (i.e., Snakemake or CLI or API) below.</p>"},{"location":"tutorials/comseg/#snakemake-usage","title":"Snakemake usage\u00b6","text":"<p>You can run ComSeg with snakemake in a similar way than the other methods. You can run the toy dataset as follow:</p> <pre>snakemake --config sdata_path=tuto.zarr --configfile=config/toy/comseg.yaml --cores 1 --use-conda\n</pre> <p>See here for MERSCOPE/Xenium/CosMx config files.</p>"},{"location":"tutorials/comseg/#api-usage","title":"API usage\u00b6","text":"<p>In this tutorial, we first compute the nucleus segmentation prior using Cellpose on the DAPI staining</p>"},{"location":"tutorials/comseg/#1-running-cellpose-as-a-prior","title":"1. Running Cellpose as a prior\u00b6","text":"<p>First, we generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p>"},{"location":"tutorials/comseg/#2-generating-patches-for-comseg","title":"2. Generating Patches for ComSeg\u00b6","text":"<p>Once the nuclei are segmented, we generate the bounding boxes of the patches on which ComSeg will be run. ComSeg also requires the nuclei centroids from the Cellpose segmentation. Therefore, we specify the <code>prior_shapes_key</code> argument, and choose <code>write_cells_centroids=True</code>:</p>"},{"location":"tutorials/comseg/#3-running-comseg-on-each-patch","title":"3. Running ComSeg on each patch\u00b6","text":"<p>Parameters for ComSeg can be gathered into a single configuration dictionary. Below is a simple configuration example for using ComSeg. For a more comprehensive description of the configuration dictionary, please refer to the documentation</p> <p>Of note, ComSeg segments cells as a point cloud of RNA. To generate cell shapes from the segmented RNA point clouds, ComSeg leverages alpha shapes. An important parameter to set is <code>alpha</code>, which influences the shape of the generated cell polygons. More about <code>alpha</code> shapes can be found here</p>"},{"location":"tutorials/comseg/#4-aggregation","title":"4. Aggregation\u00b6","text":"<p>As for all other methods, we can run aggregation: transcripts inside each cell are counted and added in a <code>AnnData</code> object in <code>sdata.tables[\"table\"]</code></p>"},{"location":"tutorials/comseg/#5-check-the-segmentation","title":"5. Check the segmentation\u00b6","text":""},{"location":"tutorials/comseg/#cli-usage","title":"CLI usage\u00b6","text":"<p>First, follow the original CLI tutorial until you finished the \"Cellpose segmentation\" section, and then, continue below.</p>"},{"location":"tutorials/comseg/#1-save-a-comseg-config-file-as-a-configjson-file","title":"1. Save a ComSeg config file as a config.json file\u00b6","text":"<p>We display below a minimal example of a ComSeg <code>config.json</code> file</p> <pre>{\n  \"dict_scale\": {\n    \"x\": 1,\n    \"y\": 1,\n    \"z\": 1\n  },\n  \"mean_cell_diameter\": 15,\n  \"max_cell_radius\": 20,\n  \"allow_disconnected_polygon\": true,\n  \"alpha\": 0.5,\n  \"min_rna_per_cell\": 5,\n  \"gene_column\": \"genes\",\n  \"norm_vector\": false\n}\n</pre> <p>If you did not install the needed external R packages, set <code>\"norm_vector\": false</code>. More information on the parameters can be found in the ComSeg documentation.</p>"},{"location":"tutorials/comseg/#2-create-the-comseg-patches","title":"2. Create the ComSeg patches\u00b6","text":"<p>On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify transcripts tuto.zarr --patch-width-microns 200 --prior-shapes-key cellpose_boundaries --write-cells-centroids\n</code></pre> <p>The <code>prior-shapes-key</code> argument is the name of the nuclei boundaries shape in the sdata object that will be used for the prior and centroid. In this example, it is set to <code>cellpose_boundaries</code>, which assumes that the Cellpose segmentation has already been run.</p>"},{"location":"tutorials/comseg/#3-run-comseg","title":"3. Run ComSeg\u00b6","text":"<p><code>sopa segmentation comseg tuto.zarr --config '\"config.json\"'</code></p>"},{"location":"tutorials/comseg/#4-finish-with-the-standard-cli-commands","title":"4. Finish with the standard CLI commands\u00b6","text":"<p>You can finish as in the original CLI tutorial.</p> <p>E.g., you can run:</p> <p><code>sopa aggregate tuto.zarr --aggregate-genes --aggregate-channels --min-transcripts 10</code></p> <p><code>sopa annotate fluorescence tuto.zarr --marker-cell-dict '{\"CK\": \"Tumoral cell\", \"CD3\": \"T cell\", \"CD20\": \"B cell\"}'</code></p> <p><code>sopa explorer write tuto.zarr</code></p>"},{"location":"tutorials/custom_segmentation/","title":"Custom segmentation","text":"In\u00a0[1]: Copied! <pre>import sopa\n</pre> import sopa In\u00a0[2]: Copied! <pre>sdata = sopa.io.toy_dataset()\n</pre> sdata = sopa.io.toy_dataset() <pre>[INFO] (sopa.utils.data) Image of size ((4, 2048, 2048)) with 400 cells and 100 transcripts per cell\n</pre> In\u00a0[3]: Copied! <pre>import numpy as np\n\n\ndef segmentation_function(image: np.ndarray) -&gt; np.ndarray:\n    \"\"\"A dummy example of a custom segmentation method\n    that creates one cell (with a padding of 10 pixels).\n\n    Args:\n        image: An image of shape `(C, Y, X)`\n\n    Returns:\n        A mask of shape `(Y, X)` containing one cell\n    \"\"\"\n    mask = np.zeros(image.shape[1:], dtype=int)\n\n    # one cell, corresponding to value 1\n    mask[10:100, 10:100] = 1  # squared shaped\n\n    return mask\n</pre> import numpy as np   def segmentation_function(image: np.ndarray) -&gt; np.ndarray:     \"\"\"A dummy example of a custom segmentation method     that creates one cell (with a padding of 10 pixels).      Args:         image: An image of shape `(C, Y, X)`      Returns:         A mask of shape `(Y, X)` containing one cell     \"\"\"     mask = np.zeros(image.shape[1:], dtype=int)      # one cell, corresponding to value 1     mask[10:100, 10:100] = 1  # squared shaped      return mask In\u00a0[4]: Copied! <pre>sopa.make_image_patches(sdata, patch_width=1000)  # we create 9 patches for the demo\n</pre> sopa.make_image_patches(sdata, patch_width=1000)  # we create 9 patches for the demo <pre>[INFO] (sopa.patches._patches) 9 patches were added to sdata['image_patches']\n</pre> In\u00a0[5]: Copied! <pre>sopa.segmentation.custom_staining_based(sdata, segmentation_function, channels=[\"DAPI\"])\n</pre> sopa.segmentation.custom_staining_based(sdata, segmentation_function, channels=[\"DAPI\"]) <pre>[WARNING] (sopa._settings) Running without parallelization backend can be slow. Consider using a backend, e.g. via `sopa.settings.parallelization_backend = 'dask'`, or `export SOPA_PARALLELIZATION_BACKEND=dask`.\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 25.21it/s]\n[INFO] (sopa.segmentation._stainings) Found 9 total cells\nResolving conflicts: 0it [00:00, ?it/s]\n[INFO] (sopa.segmentation._stainings) Added 9 cell boundaries in sdata['custom_boundaries']\n</pre> <p>Now, we have shapes called <code>\"custom_boundaries\"</code> in our SpatialData object:</p> In\u00a0[6]: Copied! <pre>sdata\n</pre> sdata Out[6]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 1024, 1024), (3, 512, 512), (3, 256, 256)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u251c\u2500\u2500 'misc': DataFrame with shape: (&lt;Delayed&gt;, 2) (2D points)\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u2514\u2500\u2500 Shapes\n      \u251c\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\n      \u251c\u2500\u2500 'custom_boundaries': GeoDataFrame shape: (9, 1) (2D shapes)\n      \u2514\u2500\u2500 'image_patches': GeoDataFrame shape: (9, 3) (2D shapes)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), misc (Points), transcripts (Points), cells (Shapes), custom_boundaries (Shapes), image_patches (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>We can continue the normal API process, i.e. using the aggregation:</p> In\u00a0[7]: Copied! <pre>sopa.aggregate(sdata)\n</pre> sopa.aggregate(sdata) <pre>[INFO] (sopa.aggregation.transcripts) Aggregating transcripts over 9 cells\n</pre> <pre>[                                        ] | 0% Completed | 101.21 us</pre> <pre>/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/anndata/_core/storage.py:48: FutureWarning: AnnData previously had undefined behavior around matrices of type &lt;class 'scipy.sparse._coo.coo_matrix'&gt;.In 0.12, passing in this type will throw an error. Please convert to a supported type.Continue using for this minor version at your own risk.\n  warnings.warn(msg, FutureWarning)\n</pre> <pre>[########################################] | 100% Completed | 105.11 ms\n</pre> <pre>[INFO] (sopa.aggregation.channels) Aggregating channels intensity over 9 cells with mode='average'\n</pre> <pre>[########################################] | 100% Completed | 101.58 ms\n</pre> <pre>[INFO] (sopa.aggregation.aggregation) Filtering 0 cells\n/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:96: UserWarning: Key `custom_boundaries` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/dev/sopa/sopa/aggregation/aggregation.py:195: ImplicitModificationWarning: Setting element `.obsm['intensities']` of view, initializing view as actual.\n  self.table.obsm[SopaKeys.INTENSITIES_OBSM] = pd.DataFrame(\n/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:96: UserWarning: Key `custom_boundaries` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n</pre> <p>For the sake of this tutorial, we show the resulting \"dummy\" segmentation. As we created one square cell for ech patch, this results in 9 cells:</p> In\u00a0[8]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[10]: Copied! <pre>sdata.pl.render_images(\"image\").pl.render_shapes(\n    \"custom_boundaries\", fill_alpha=0, outline_alpha=1, outline_color=\"#fff\"\n).pl.show(\"global\")\n</pre> sdata.pl.render_images(\"image\").pl.render_shapes(     \"custom_boundaries\", fill_alpha=0, outline_alpha=1, outline_color=\"#fff\" ).pl.show(\"global\") <pre>INFO     Rasterizing image for faster rendering.                                                                   \n</pre> <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.9530949634755863].\n</pre>"},{"location":"tutorials/custom_segmentation/#custom-segmentation","title":"Custom segmentation\u00b6","text":"<p>The Sopa CLI and pipeline are based on Cellpose for staining-based segmentation. Yet, if desired, one can implement another staining-based segmentation algorithm.</p> <p>You can plug your segmentation model into Sopa to benefit from all the other functionalities. In particular, it will scale the segmentation since Sopa will run on small patches.</p>"},{"location":"tutorials/custom_segmentation/#define-your-segmentation-function","title":"Define your segmentation function\u00b6","text":"<p>You need a Python function as described below:</p> <ul> <li><p>The function input is an image of shape <code>(C, Y, X)</code> (<code>C</code> is the number of desired channels; it can be one if you want DAPI only)</p> </li> <li><p>The function output is a mask of shape <code>(Y, X)</code>. This mask should contain positive values representing the segmented cells, and contain <code>0</code> outside of the cells. For instance, if 4 cells are segmented, the mask should contain the values 1, 2, 3, and eventually 0 (where there is no cell).</p> </li> </ul> <p>Here is a dummy example of how it could look like:</p>"},{"location":"tutorials/custom_segmentation/#use-it-via-the-api","title":"Use it via the API\u00b6","text":"<p>The easiest way to use it is via the API. The process is very similar to Cellpose:</p>"},{"location":"tutorials/he/","title":"H&amp;E usage","text":"In\u00a0[1]: Copied! <pre>import spatialdata\nimport spatialdata_plot\n\nimport sopa\n</pre> import spatialdata import spatialdata_plot  import sopa In\u00a0[\u00a0]: Copied! <pre>sdata = sopa.io.wsi(\"/path/to/slide\")\n</pre> sdata = sopa.io.wsi(\"/path/to/slide\") In\u00a0[\u00a0]: Copied! <pre># here, we will directly open the processed Xenium directory\nsdata = sopa.io.xenium(\"data/xenium/Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs\", cells_boundaries=True)\n</pre> # here, we will directly open the processed Xenium directory sdata = sopa.io.xenium(\"data/xenium/Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs\", cells_boundaries=True) <p>Here, we see that the H&amp;E image is called <code>\"he_image\"</code>:</p> In\u00a0[4]: Copied! <pre>sdata\n</pre> sdata Out[4]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 71883, 20562), (3, 35941, 10281), (3, 17970, 5140), (3, 8985, 2570), (3, 4492, 1285)\n\u2502     \u251c\u2500\u2500 'morphology_focus': DataTree[cyx] (1, 13752, 48274), (1, 6876, 24137), (1, 3438, 12068), (1, 1719, 6034), (1, 859, 3017)\n\u2502     \u2514\u2500\u2500 'morphology_mip': DataTree[cyx] (1, 13752, 48274), (1, 6876, 24137), (1, 3438, 12068), (1, 1719, 6034), (1, 859, 3017)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 10) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u2514\u2500\u2500 'cell_boundaries': GeoDataFrame shape: (190965, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (190965, 474)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), morphology_focus (Images), morphology_mip (Images), transcripts (Points), cell_boundaries (Shapes)</pre> In\u00a0[\u00a0]: Copied! <pre>sdata.write(\"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs.zarr\")\nsdata = spatialdata.read_zarr(\"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs.zarr\")\n\n# (optional) the new spatial elements will not be saved on disk automatically\nsopa.settings.auto_save_on_disk = False\n</pre> sdata.write(\"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs.zarr\") sdata = spatialdata.read_zarr(\"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs.zarr\")  # (optional) the new spatial elements will not be saved on disk automatically sopa.settings.auto_save_on_disk = False <p>Optionally, we can run tissue segmentation. This will create new polygons saved inside <code>sdata['region_of_interest']</code>.</p> <p>NB: by default, Sopa knows it should use <code>\"he_image\"</code> for tissue segmentation. Depending on your data, you might need to provide the <code>image_key</code> argument.</p> <p>For more details, refer to the documentation of <code>sopa.segmentation.tissue</code>.</p> In\u00a0[4]: Copied! <pre>sopa.segmentation.tissue(sdata, expand_radius_ratio=0.01)\n</pre> sopa.segmentation.tissue(sdata, expand_radius_ratio=0.01) <pre>[INFO] (sopa.segmentation._tissue) Using image_key='he_image' and mode='saturation' as default\n</pre> <p>The tissue segmentation can be shown as below:</p> In\u00a0[6]: Copied! <pre>sdata.pl.render_images(\"he_image\", scale=\"scale3\").pl.render_shapes(\n    \"region_of_interest\", outline_alpha=1, fill_alpha=0\n).pl.show(\"global\")\n</pre> sdata.pl.render_images(\"he_image\", scale=\"scale3\").pl.render_shapes(     \"region_of_interest\", outline_alpha=1, fill_alpha=0 ).pl.show(\"global\") <pre>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.123893805..1.0].\n</pre> In\u00a0[\u00a0]: Copied! <pre># here we use the 'histo_ssl' model, but many other models are available\nsopa.patches.compute_embeddings(sdata, \"histo_ssl\", image_key=\"he_image\", level=1, patch_width=224)\n</pre> # here we use the 'histo_ssl' model, but many other models are available sopa.patches.compute_embeddings(sdata, \"histo_ssl\", image_key=\"he_image\", level=1, patch_width=224) <pre>[INFO] (sopa.patches.infer) Processing 5312 patches extracted from level 1\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 166/166 [01:31&lt;00:00,  1.81it/s]\n[INFO] (sopa.patches._patches) Added 5312 patche(s) to sdata['embeddings_patches']\n/Users/quentinblampey/miniforge3/envs/spatial-dev/lib/python3.10/site-packages/spatialdata/models/models.py:1053: UserWarning: Converting `region_key: region` to categorical dtype.\n  return convert_region_column_to_categorical(adata)\n</pre> <p>Now, we have a key <code>'histo_ssl_embeddings'</code> containing the embeddings (as an <code>AnnData</code> object), and <code>'embeddings_patches'</code> containing the geometries of the patches.</p> In\u00a0[15]: Copied! <pre>sdata\n</pre> sdata Out[15]: <pre>SpatialData object, with associated Zarr store: /Users/quentinblampey/dev/sopa/docs/tutorials/Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs.zarr\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 71883, 20562), (3, 35941, 10281), (3, 17970, 5140), (3, 8985, 2570), (3, 4492, 1285)\n\u2502     \u251c\u2500\u2500 'morphology_focus': DataTree[cyx] (1, 13752, 48274), (1, 6876, 24137), (1, 3438, 12068), (1, 1719, 6034), (1, 859, 3017)\n\u2502     \u2514\u2500\u2500 'morphology_mip': DataTree[cyx] (1, 13752, 48274), (1, 6876, 24137), (1, 3438, 12068), (1, 1719, 6034), (1, 859, 3017)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 10) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'cell_boundaries': GeoDataFrame shape: (190965, 1) (2D shapes)\n\u2502     \u251c\u2500\u2500 'embeddings_patches': GeoDataFrame shape: (5312, 3) (2D shapes)\n\u2502     \u2514\u2500\u2500 'region_of_interest': GeoDataFrame shape: (2, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u251c\u2500\u2500 'histo_ssl_embeddings': AnnData (5312, 512)\n      \u2514\u2500\u2500 'table': AnnData (190965, 474)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), morphology_focus (Images), morphology_mip (Images), transcripts (Points), cell_boundaries (Shapes), embeddings_patches (Shapes), region_of_interest (Shapes)\nwith the following elements not in the Zarr store:\n    \u25b8 embeddings_patches (Shapes)\n    \u25b8 region_of_interest (Shapes)\n    \u25b8 histo_ssl_embeddings (Tables)</pre> <p>Then, clustering can be run on the patches embeddings. This will add a <code>\"cluster\"</code> column to <code>sdata[\"histo_ssl_embeddings\"].obs</code>.</p> <p>See the documentation of <code>sopa.patches.cluster_embeddings</code> for more details.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.patches.cluster_embeddings(sdata, \"histo_ssl_embeddings\")\n</pre> sopa.patches.cluster_embeddings(sdata, \"histo_ssl_embeddings\") In\u00a0[19]: Copied! <pre>sdata[\"histo_ssl_embeddings\"].obs\n</pre> sdata[\"histo_ssl_embeddings\"].obs Out[19]: region instance cluster 0 embeddings_patches 0 0 1 embeddings_patches 1 1 2 embeddings_patches 2 3 3 embeddings_patches 3 3 4 embeddings_patches 4 3 ... ... ... ... 5307 embeddings_patches 5307 7 5308 embeddings_patches 5308 1 5309 embeddings_patches 5309 0 5310 embeddings_patches 5310 6 5311 embeddings_patches 5311 0 <p>5312 rows \u00d7 3 columns</p> <p>The patches clusters can be shown with <code>spatialdata_plot</code>:</p> In\u00a0[20]: Copied! <pre>sdata.pl.render_shapes(\"region_of_interest\", outline_alpha=1, fill_alpha=0).pl.render_shapes(\n    \"embeddings_patches\", color=\"cluster\"\n).pl.show(\"global\")\n</pre> sdata.pl.render_shapes(\"region_of_interest\", outline_alpha=1, fill_alpha=0).pl.render_shapes(     \"embeddings_patches\", color=\"cluster\" ).pl.show(\"global\") <pre>/Users/quentinblampey/miniforge3/envs/spatial-dev/lib/python3.10/site-packages/spatialdata_plot/pl/utils.py:777: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n  color_vector = color_source_vector.map(color_mapping)\n</pre> In\u00a0[\u00a0]: Copied! <pre># before the join, we save the cluster inside the patches to retreive them easily later on\nsdata[\"embeddings_patches\"][\"cluster\"] = sdata[\"histo_ssl_embeddings\"].obs[\"cluster\"].values\n\nres_gdf = sopa.spatial.sjoin(sdata, \"cell_boundaries\", \"embeddings_patches\", target_coordinate_system=\"global\")\n</pre> # before the join, we save the cluster inside the patches to retreive them easily later on sdata[\"embeddings_patches\"][\"cluster\"] = sdata[\"histo_ssl_embeddings\"].obs[\"cluster\"].values  res_gdf = sopa.spatial.sjoin(sdata, \"cell_boundaries\", \"embeddings_patches\", target_coordinate_system=\"global\") <p>The resulting <code>GeoDataFrame</code> may have more columns than cells, because one cell may be inside multiple patches. We will keep only the first patch, and then save the resulting <code>\"cluster\"</code> column into the <code>sdata.tables[\"table\"]</code>.</p> In\u00a0[48]: Copied! <pre>sdata.tables[\"table\"].obs[\"cluster\"] = res_gdf[~res_gdf.index.duplicated()][\"cluster\"].values\n</pre> sdata.tables[\"table\"].obs[\"cluster\"] = res_gdf[~res_gdf.index.duplicated()][\"cluster\"].values <p>Here, for simplicity, we use <code>scanpy</code> to plot the cells (as dots). But we could also use <code>spatialdata_plot</code>.</p> <p>We can see the cells segmented by the Xenium, colored by the H&amp;E patch in which they belong.</p> In\u00a0[50]: Copied! <pre>import scanpy as sc\n</pre> import scanpy as sc In\u00a0[51]: Copied! <pre>sc.pl.spatial(sdata[\"table\"], color=\"cluster\", spot_size=10)\n</pre> sc.pl.spatial(sdata[\"table\"], color=\"cluster\", spot_size=10)"},{"location":"tutorials/he/#he-usage","title":"H&amp;E usage\u00b6","text":"<p>The purpose of this notebook is to showcase how to perform basic analyses of H&amp;E data and eventually combine it other modalities (transcriptomics or multiplex imaging).</p> <p>You will need the <code>wsi</code> extra of sopa for this tutorial, i.e. <code>pip install sopa[wsi]</code></p>"},{"location":"tutorials/he/#reading-your-data","title":"Reading your data\u00b6","text":"<p>You have multiple options to read your H&amp;E image.</p>"},{"location":"tutorials/he/#he-only","title":"H&amp;E only\u00b6","text":"<p>You can open a H&amp;E slide by using the <code>sopa.io.wsi</code> reader. It supports multiple backends, such as <code>openslide</code>, <code>slideio</code>, or <code>tiffslide</code> (default).</p>"},{"location":"tutorials/he/#he-and-spatial-omics","title":"H&amp;E and spatial omics\u00b6","text":"<p>If you have both spatial omics and H&amp;E data, we recommend running Sopa as usual on the spatial modality, and then adding your H&amp;E information. You can align the H&amp;E image as in this tutorial to add it to your spatial omics slide.</p> <p>If you have Xenium data, you may have your H&amp;E slide already aligned and in <code>.ome.tif</code> format. In that case, the <code>sopa.io.xenium</code> function already imported the H&amp;E slide.</p>"},{"location":"tutorials/he/#example","title":"Example\u00b6","text":"<p>For this tutorial, we use this Xenium pancreatic cancer dataset, with the H&amp;E slide already aligned to the spatial transcriptomics.</p> <p>To keep it simple, we will assume the Sopa pipeline has already been run, and for the sake of this tutorial we will directly use the Xenium default segmentation (<code>cells_boundaries=True</code>) as if it was a Sopa output.</p>"},{"location":"tutorials/he/#optional-save-your-spatialdata-object","title":"Optional: Save your SpatialData object\u00b6","text":"<p>You can write the data on-disk (<code>.zarr</code> directory). This will be more efficient if you used <code>tiffslide</code> as a backend or the <code>ome.tif</code> reader.</p> <p>You can also decide to skip this step and work only in-memory. This can still be efficient if you used the <code>openslide</code> or <code>slideio</code> backend in <code>sopa.io.wsi</code> (interesting when running on H&amp;E slides without spatial transcriptomics/proteomics).</p>"},{"location":"tutorials/he/#tissue-segmentation","title":"Tissue segmentation\u00b6","text":""},{"location":"tutorials/he/#cell-segmentation","title":"Cell segmentation\u00b6","text":"<p>If you have Xenium data, as is this tutorial, we recommend to segment the data on the transcriptomics information rather than the H&amp;E image. Refer to the main API tutorial to use for instance Baysor or Proseg, or use the default cell segmentation provided by 10X Genomics by default.</p> <p>Yet, if you have only a H&amp;E/WSI slide without spatial omics, you can use <code>sopa.segmentation.stardist</code> for nucleus segmentation based on the H&amp;E image.</p>"},{"location":"tutorials/he/#patches-embeddings-and-clusters","title":"Patches embeddings and clusters\u00b6","text":"<p>It is common to embed H&amp;E patches using a computer vision model. Here, we use a computer vision model to embed patches. On the following example, we compute embeddings for patches of width <code>224</code> pixels at the level 1 (i.e., the first sub-resolution image).</p> <p>You can adjust the level to get different resolutions. For instance, <code>level=0, patch_width=100</code> would produce a resolution of about one cell per patch.</p> <p>See the documentation of <code>sopa.patches.compute_embeddings</code> to see all supported models and more details. For faster inference, you can pass <code>device=\"cuda\"</code>.</p>"},{"location":"tutorials/he/#spatial-join","title":"Spatial join\u00b6","text":"<p>You may be interested in joining the H&amp;E patches and the cells. This way, you could know inside witch patch-cluster belongs each cell. This can be done with <code>sopa.spatial.sjoin</code>.</p>"},{"location":"tutorials/multi_step_segmentation/","title":"Multi-step segmentation","text":"<p>Multi-step segmentation consists of running multiple times Cellpose over the whole slides with different parameters. For instance, we can first run a nucleus segmentation using DAPI, then another round using DAPI and a membrane staining, and finally, DAPI and cell boundary staining. This can make the segmentation more robust. Note that the results of the multiple steps are combined into one final segmentation.</p>"},{"location":"tutorials/multi_step_segmentation/#using-the-api","title":"Using the API","text":"<p>To run multi-step segmentation via the API, you can run multiple segmentation methods, and then combine them with sopa.segmentation.combine.</p> <p>On the example below, we run Cellpose twice, once for nuclei and once for tumor cells. We then combine the two segmentations into a single one.</p> <pre><code>import sopa\n\nsdata = sopa.io.toy_dataset(length=1000)\nsopa.make_image_patches(sdata)\n\nsopa.segmentation.cellpose(sdata, \"DAPI\", diameter=35, key_added=\"nuclei\")\nsopa.segmentation.cellpose(sdata, [\"CK\", \"DAPI\"], diameter=35, key_added=\"tumor_cells\")\n\nsopa.segmentation.combine(sdata, [\"nuclei\", \"tumor_cells\"], key_added=\"combined_cells\")\n</code></pre> <p>Then, you can continue as usual, i.e. with <code>sopa.aggregate</code> and so on.</p>"},{"location":"tutorials/multi_step_segmentation/#using-the-cli","title":"Using the CLI","text":"<p>Warning</p> <p>Here, we only detail the multi-step segmentation. For the rest of the CLI usage, refer to our CLI usage tutorial, and only replace the \"Run segmentation\" section with the instructions below.</p> <p>First, generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels, and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Now, we can run Cellpose on each of the four patches and for each \"segmentation step\" we want. In this toy example, we run 3 steps with (i) CK + DAPI, (ii) CD3 + DAPI, and (iii) CD20 + DAPI.</p> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels CK --channels DAPI \\\n    --cache-dir-name cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels CD3 --channels DAPI \\\n    --cache-dir-name cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels CD20 --channels DAPI \\\n    --cache-dir-name cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000\n</code></pre> <p>Note</p> <p>In the above commands, the <code>--diameter</code> and <code>--min-area</code> parameters are specific to the data type we work on. For your own data, consider using the default parameters from one of our config files. Here, <code>min-area</code> is in pixels^2.</p> <p>At this stage, you executed 12 times Cellpose (3 steps on each of the 4 patches). Now, we need to resolve the conflict, i.e., merge the three segmentations into one. Note that we gave the paths to the temporary boundaries we made above. <pre><code>sopa resolve cellpose tuto.zarr \\\n    --cache-dir-name cellpose_CK \\\n    --cache-dir-name cellpose_CD3 \\\n    --cache-dir-name cellpose_CD20\n</code></pre></p> <p>Congrats, you have now merged the results of a three-step segmentation! You can now refer to our normal CLI usage tutorial for all the other tasks.</p>"},{"location":"tutorials/snakemake/","title":"Snakemake pipeline","text":"<p>Sopa comes with an existing Snakemake workflow to get started quickly. This will not involve any coding but requires some setup specific to <code>snakemake</code>.</p> <p>Info</p> <p>If you're more familiar with Nextflow, you can try nf-core/sopa instead.</p>"},{"location":"tutorials/snakemake/#setup","title":"Setup","text":""},{"location":"tutorials/snakemake/#installation","title":"Installation","text":"<p>Follow our installation instructions until the end of the \"Snakemake setup\" section.</p> <p>At the end, you should have one <code>sopa</code> environment, one one environment with <code>snakemake&gt;=8.0.0</code> (it can be the same environment, if desired), and you should also have cloned the <code>sopa</code> repository.</p>"},{"location":"tutorials/snakemake/#choose-a-config-file","title":"Choose a config file","text":"<p>Our pipeline config is a YAML file that describes all the steps desired for the pipeline. It is flexible; for instance, if you remove the <code>baysor</code> section from the config, then it will not run baysor.</p> <p>You can choose a config among the existing ones here or create your own.</p> <p>Keep in mind the path of your config (relative to the <code>workflow</code> directory) because you'll need it later. For instance, <code>config/merscope/base.yaml</code> is a valid relative path. You can also use an absolute path if you prefer.</p>"},{"location":"tutorials/snakemake/#run-the-pipeline","title":"Run the pipeline","text":""},{"location":"tutorials/snakemake/#locate-your-raw-data","title":"Locate your raw data","text":"<p>First, you need to locate the path to one sample's raw experiment file(s). This is usually a directory containing one or many image(s) and, eventually, a transcript file. If you don't know what data you need, see our FAQ.</p> <p>Again, remind this path, as we will use it later.</p>"},{"location":"tutorials/snakemake/#activate-snakemake","title":"Activate snakemake","text":"<p>Then, activate an environment that has the snakemake command: <pre><code>conda activate snakemake    # or any environment that has `snakemake`\n</code></pre></p> <p>And move in the <code>workflow</code> directory of the <code>sopa</code> repository: <pre><code>cd workflow   # move to the workflow directory inside the sopa repository\n</code></pre></p>"},{"location":"tutorials/snakemake/#run-snakemake","title":"Run Snakemake","text":"<p>You can either execute the pipeline locally or on a high-performance-cluster (choose the right option below).</p> Local execution (e.g., personal laptop)Slurm clusterLSF clusterOther high-performance-cluster <p>You can execute the pipeline locally as below (in this example, we use only one core). Make sure to replace <code>data_path</code> with the path to your raw data directory, and <code>configfile</code> with the relative path to your config (as detailed above).</p> <pre><code>snakemake \\\n    --config data_path=/path/to/directory \\\n    --configfile=config/merscope/base.yaml \\\n    --workflow-profile profile/local \\\n    --cores 1\n</code></pre> <p>Faster pipeline</p> <p>Even though Sopa can be run locally, we recommend to use it on high-performance-clusters to benefit from all the pipeline capabilities (see the second tab just above).</p> <p>To fully benefit from Slurm, you'll need a Snakemake cluster profile. Sopa offers a default Slurm profile for you. Make sure you have <code>snakemake&gt;=8.0.0</code>, and also install the Slurm plugin with <code>pip install snakemake-executor-plugin-slurm</code>.</p> <p>Then, you can use the Slurm profile as shown below. Make sure to replace <code>data_path</code> with the path to your raw data directory, and <code>configfile</code> with the relative path to your config (as detailed above).</p> <pre><code>snakemake \\\n    --config data_path=/path/to/directory \\\n    --configfile=config/merscope/base.yaml \\\n    --workflow-profile profile/slurm  # or any profile you want\n</code></pre> <p>Specify the slurm partition names</p> <p>You may need to update the <code>slurm_partition</code> parameters inside the <code>workflow/profile/slurm/config.yaml</code> file according to the partition names of your cluster (else, it will always use the same partition). You can also change <code>mem_mb</code>, depending on the RAM capabilities of your cluster.</p> <p>Warning</p> <p>The LSF profile is experimental. Don't hesitate to open an issue or a PR.</p> <p>To fully benefit from LSF, you'll need a Snakemake cluster profile. Sopa offers a default LSF profile for you, but it is still experimental. Make sure you have <code>snakemake&gt;=8.0.0</code>, and also install the LSF plugin with <code>pip install snakemake-executor-plugin-lsf</code>.</p> <p>Then, you can use the LSF profile as shown below. Make sure to replace <code>data_path</code> with the path to your raw data directory, and <code>configfile</code> with the relative path to your config (as detailed above).</p> <pre><code>snakemake \\\n    --config data_path=/path/to/directory \\\n    --configfile=config/merscope/base.yaml \\\n    --workflow-profile profile/lsf  # or any profile you want\n</code></pre> <p>If you have high-performance-cluster that is not a Slurm/LSF HPC, then we recommend reading more about the Snakemake profiles, and, especially, the different executor plugins.</p> <p>Once you installed an executor plugin, you can use it with the command below. Make sure to replace <code>data_path</code> with the path to your raw data directory, and <code>configfile</code> with the relative path to your config (as detailed above).</p> <pre><code>snakemake \\\n    --config data_path=/path/to/directory \\\n    --configfile=config/merscope/base.yaml\n    --executor my_executor  # your new executor\n</code></pre> <p>Or you can also create a new profile for your HPC: for instance, you can create <code>workflow/profile/my_profile/config.yaml</code>, which you can use it witht the following command:</p> <pre><code>snakemake \\\n    --config data_path=/path/to/directory \\\n    --configfile=config/merscope/base.yaml\n    --workflow-profile profile/my_profile  # your new profile\n</code></pre> <p>RAM per rule</p> <p>Some Snakemake rules may use more RAM, for instance <code>explorer</code>, or <code>to_spatialdata</code>. Consider adjusting the RAM and the walltime depending on the Snakemake rules.</p> <p>For more customization, see the snakemake CLI documentation.</p>"},{"location":"tutorials/snakemake/#toy-example","title":"Toy example","text":"<p>In the example below, we run the pipeline on a generated toy dataset. Running it locally can help test a new pipeline or config.</p> <p>Make sure you have installed everything as detailed in this tutorial, and then run the following command lines:</p> Cellpose usageProseg usageBaysor usage <p>Make sure you have installed sopa with the <code>cellpose</code> extra (for instance, this can be done via the following command: <code>pip install 'sopa[cellpose]'</code>). <pre><code>conda activate snakemake    # or any environment that has `snakemake`\ncd workflow   # move to the workflow directory inside the sopa repository\n\n# you can replace tuto.zarr by another path where the data will be saved\nsnakemake \\\n    --config sdata_path=tuto.zarr \\\n    --configfile=config/toy/cellpose.yaml \\\n    --workflow-profile profile/local \\\n    --cores 1\n</code></pre></p> <p>Make sure you have installed the <code>proseg</code> command (refer to our getting started). <pre><code>conda activate snakemake    # or any environment that has `snakemake`\ncd workflow   # move to the workflow directory inside the sopa repository\n\n# you can replace tuto.zarr by another path where the data will be saved\nsnakemake \\\n    --config sdata_path=tuto.zarr \\\n    --configfile=config/toy/proseg.yaml \\\n    --workflow-profile profile/local \\\n    --cores 1\n</code></pre></p> <p>Make sure you have installed sopa with the <code>baysor</code> extra, and that you have installed the <code>baysor</code> command (refer to our getting started). <pre><code>conda activate snakemake    # or any environment that has `snakemake`\ncd workflow   # move to the workflow directory inside the sopa repository\n\n# you can replace tuto.zarr by another path where the data will be saved\nsnakemake \\\n    --config sdata_path=tuto.zarr \\\n    --configfile=config/toy/baysor.yaml \\\n    --workflow-profile profile/local \\\n    --cores 1\n</code></pre></p> <p>Notes</p> <p>On the above example, it executes snakemake sequentially (one core), which is enough for debugging purposes. You can remove the argument, or set a higher number of cores.</p> <p>You can then check <code>tuto.explorer</code> for output files. Notably, if you have installed the Xenium Explorer, double-click on <code>experiment.xenium</code> to visualize the results.</p>"},{"location":"tutorials/snakemake/#pipeline-outputs","title":"Pipeline outputs","text":"<p>The pipeline outputs consists in two directories located next to your raw data directory. They have the same name as your raw directory, but with extension <code>.zarr</code> and <code>.explorer</code> respectively (see below for more details).</p> <p>Info</p> <p>You can also change the path to the <code>.zarr</code> output, by providing <code>sdata_path=/your/path.zarr</code> just after <code>--config</code> on the snakemake execution line. This will also move the <code>.explorer</code> directory, that will be saved at <code>/your/path.explorer</code></p>"},{"location":"tutorials/snakemake/#spatialdata-directory","title":"<code>SpatialData</code> directory","text":"<p>If you are familiar with the <code>spatialdata</code> library, you can use the <code>.zarr</code> directory, corresponding to a <code>SpatialData</code> object: <pre><code>import spatialdata\n\nsdata = spatialdata.read_zarr(\"/path/to/data.zarr\")\n</code></pre></p>"},{"location":"tutorials/snakemake/#explorer-directory","title":"Explorer directory","text":"<p>The <code>.explorer</code> directory contains the following files:</p> <ul> <li> <p><code>report.html</code> a short quality control of you data, as an HTML report</p> </li> <li> <p><code>adata.h5ad</code> the AnnData object with spatial locations of the cells (see <code>adata.obsm['spatial']</code>), and also cell-by-gene table and/or the cell-by-channel table.</p> </li> <li> <p><code>experiment.xenium</code> the Xenium Explorer file: double-click on it to open it on the Xenium Explorer (download the software here)</p> </li> <li> <p>The other files are data files related and required by the Xenium Explorer</p> </li> </ul>"},{"location":"tutorials/snakemake/#advanced-usage","title":"Advanced usage","text":""},{"location":"tutorials/snakemake/#create-your-own-config","title":"Create your own config","text":"<p>If the existing <code>config</code> files are not suited for your project, you can update an existing one or create a whole new one. For this, use this commented config to understand the purpose of each argument. Note that some sections are optional: in this case, remove the section or the argument, and Sopa will not run it.</p> <p>When running snakemake, you will then need to provide the relative or absolute path to your <code>.yaml</code> config, for instance <code>--configfile=/path/to/your/config.yaml</code>.</p>"},{"location":"tutorials/snakemake/#passing-kwargs-to-the-config","title":"Passing kwargs to the config","text":"<p>Internally, the Snakemake pipeline is calling Sopa's CLI. Not all argument are used in the default config files. You can pass additionnal kwargs to the config so that they are given to the CLI.</p> <p>For instance, if you want to pass kwargs to the MERSCOPE reader, you can update the config as below: <pre><code>read:\n  technology: merscope\n  kwargs:\n    z_layers: 2\n</code></pre></p>"},{"location":"tutorials/snakemake/#create-your-own-profile","title":"Create your own profile","text":"<p>As mentioned above, you can use a Snakemake profile to execute the pipeline. In Snakemake&gt;=8.0.0, there are multiple executor plugins that can help you.</p> <p>Save your new profile under <code>workflow/profile/my_profile/config.yaml</code>.</p> <p>Then, to use the new profile, pass <code>--workflow-profile profile/my_profile</code> to your <code>snakemake</code> command.</p>"},{"location":"tutorials/spatial/","title":"Spatial operations","text":"In\u00a0[\u00a0]: Copied! <pre>import anndata\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sopa\n\nheatmap_kwargs = {\"vmax\": 40, \"cmap\": sns.cm.rocket_r, \"cbar_kws\": {\"label\": \"Mean hop distance\"}}\n</pre> import anndata import matplotlib.pyplot as plt import seaborn as sns  import sopa  heatmap_kwargs = {\"vmax\": 40, \"cmap\": sns.cm.rocket_r, \"cbar_kws\": {\"label\": \"Mean hop distance\"}} <p>Notes about coordinate systems: the coordinates of your cells can be either in pixels or microns. This depends on the segmentation you used. For instance, cellpose will output coordinates in pixels, while baysor or comseg will output coordinates in microns.</p> In\u00a0[2]: Copied! <pre>adata = anndata.read_h5ad(\"adata_liver_merscope.h5ad\")\n</pre> adata = anndata.read_h5ad(\"adata_liver_merscope.h5ad\") <p>Then, compute the Delaunay graph on your data. Especially, use the <code>radius</code> argument to drop long edges. In this examples, edges longer than 50 microns are removed.</p> <p>The later function comes from Squidpy.</p> In\u00a0[3]: Copied! <pre>sopa.spatial.spatial_neighbors(adata, radius=[0, 50])\n</pre> sopa.spatial.spatial_neighbors(adata, radius=[0, 50]) <pre>[INFO] (sopa.spatial._build) Computing delaunay graph\n</pre> In\u00a0[4]: Copied! <pre>cell_type_to_cell_type = sopa.spatial.mean_distance(adata, \"cell_type\", \"cell_type\")\n</pre> cell_type_to_cell_type = sopa.spatial.mean_distance(adata, \"cell_type\", \"cell_type\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:08&lt;00:00,  3.36it/s]\n</pre> In\u00a0[5]: Copied! <pre>plt.figure(figsize=(7, 6))\nsns.heatmap(cell_type_to_cell_type, **heatmap_kwargs)\n</pre> plt.figure(figsize=(7, 6)) sns.heatmap(cell_type_to_cell_type, **heatmap_kwargs) Out[5]: <pre>&lt;Axes: xlabel='cell_type', ylabel='cell_type'&gt;</pre> <p>Similary, you can compute the mean hop-distance between all pairs of cell-types and niches:</p> In\u00a0[6]: Copied! <pre>cell_type_to_niche = sopa.spatial.mean_distance(adata, \"cell_type\", \"niches\")\n</pre> cell_type_to_niche = sopa.spatial.mean_distance(adata, \"cell_type\", \"niches\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.41it/s]\n</pre> In\u00a0[7]: Copied! <pre>plt.figure(figsize=(3, 6))\nsns.heatmap(cell_type_to_niche, **heatmap_kwargs)\n</pre> plt.figure(figsize=(3, 6)) sns.heatmap(cell_type_to_niche, **heatmap_kwargs) Out[7]: <pre>&lt;Axes: xlabel='niches', ylabel='cell_type'&gt;</pre> <p>Same between niches and niches:</p> In\u00a0[8]: Copied! <pre>niche_to_niche = sopa.spatial.mean_distance(adata, \"niches\")\n</pre> niche_to_niche = sopa.spatial.mean_distance(adata, \"niches\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.44it/s]\n</pre> In\u00a0[9]: Copied! <pre>plt.figure(figsize=(3, 3))\nsns.heatmap(niche_to_niche, **heatmap_kwargs)\n</pre> plt.figure(figsize=(3, 3)) sns.heatmap(niche_to_niche, **heatmap_kwargs) Out[9]: <pre>&lt;Axes: xlabel='niches', ylabel='niches'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>gdf = sopa.spatial.vectorize_niches(adata, \"niches\")\ngdf\n</pre> gdf = sopa.spatial.vectorize_niches(adata, \"niches\") gdf Out[\u00a0]: geometry niches length area roundness 0 POLYGON ((11256.961 7834.639, 11257.304 7835.6... Bile duct 371.136469 6941.104125 0.633244 3 POLYGON ((11122.354 8163.108, 11123.162 8163.7... Bile duct 393.638585 5539.287922 0.449230 6 POLYGON ((10936.163 381.622, 10936.478 381.898... Bile duct 1595.710237 24099.793633 0.118936 8 POLYGON ((11021.489 747.492, 11019.723 748.834... Bile duct 561.516074 5763.341860 0.229699 17 POLYGON ((11042.181 3981.166, 11043.124 3980.8... Bile duct 584.173216 6296.007422 0.231842 ... ... ... ... ... ... 2292 POLYGON ((2805.196 4508.688, 2805.687 4509.714... Vascular 589.849425 13760.673500 0.497012 2370 POLYGON ((459.355 560.935, 460.631 562.344, 46... Vascular 727.372986 7949.503667 0.188815 2378 POLYGON ((192.733 4605.956, 193.558 4606.628, ... Vascular 601.631439 8236.973094 0.285967 2388 POLYGON ((78.743 2939.361, 79.118 2940.362, 80... Vascular 390.753989 8232.263635 0.677520 2390 POLYGON ((10.051 4012.561, 10.497 4013.717, 18... Vascular 395.425837 9050.534716 0.727368 <p>118 rows \u00d7 5 columns</p> <p>Now, each occurence (or connected component) of each niche category is a Polygon. On this example, the Necrosis niche has 3 components, as shown below.</p> In\u00a0[\u00a0]: Copied! <pre>legend_kwds = {\n    \"bbox_to_anchor\": (1.04, 0.5),\n    \"loc\": \"center left\",\n    \"borderaxespad\": 0,\n    \"frameon\": False,\n    \"title\": \"Niches\",\n}\n\ngdf.plot(column=\"niches\", legend=True, legend_kwds=legend_kwds)\n</pre> legend_kwds = {     \"bbox_to_anchor\": (1.04, 0.5),     \"loc\": \"center left\",     \"borderaxespad\": 0,     \"frameon\": False,     \"title\": \"Niches\", }  gdf.plot(column=\"niches\", legend=True, legend_kwds=legend_kwds) Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> In\u00a0[12]: Copied! <pre>df_niches_geometries = sopa.spatial.niches_geometry_stats(adata, \"niches\")\ndf_niches_geometries\n</pre> df_niches_geometries = sopa.spatial.niches_geometry_stats(adata, \"niches\") df_niches_geometries <pre>[INFO] (sopa.spatial.morpho) Computing pairwise distances between 118 components\n</pre> Out[12]: n_components length area roundness min_distance_to_niche_Bile duct min_distance_to_niche_Lymphoid structure min_distance_to_niche_Necrosis min_distance_to_niche_Stroma min_distance_to_niche_Stromal border min_distance_to_niche_Tumour min_distance_to_niche_Tumour-myeloid min_distance_to_niche_Vascular niches Bile duct 53 871.163413 1.968860e+04 0.337805 0.000000 2380.538268 1449.461569 73.698113 606.466864 503.188672 1458.109531 554.878833 Lymphoid structure 2 1036.895946 6.074089e+04 0.655267 99.283752 0.000000 1293.705232 0.000000 484.004416 288.855609 778.042413 727.563948 Necrosis 3 14679.900601 1.859571e+06 0.144873 215.188214 2613.268586 0.000000 0.000000 530.994922 24.705659 0.000000 206.323638 Stroma 1 159551.459121 2.385822e+07 0.011777 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 Stromal border 10 32107.645354 1.562288e+06 0.023618 1282.747393 4533.620464 1263.667065 356.928689 0.000000 0.000000 624.666420 365.469128 Tumour 8 22964.491358 6.363175e+06 0.178266 258.930767 2124.252221 433.590282 2.529358 40.851952 0.000000 257.084459 121.688532 Tumour-myeloid 13 5625.146904 2.741475e+05 0.116237 531.479998 3349.152789 603.320975 0.000000 332.532881 79.196333 0.000000 694.707711 Vascular 28 808.856057 2.111648e+04 0.403680 1065.886005 3766.261346 1702.920627 401.167661 477.280906 283.654705 1370.371248 0.000000 In\u00a0[13]: Copied! <pre>fig, axes = plt.subplots(1, 4, figsize=(15, 6))\n\nfor i, name in enumerate([\"n_components\", \"length\", \"area\", \"roundness\"]):\n    vmax = df_niches_geometries[name].sort_values()[-2:].mean()\n    sns.heatmap(df_niches_geometries[[name]], cmap=\"viridis\", annot=True, fmt=\".2f\", vmax=vmax, ax=axes[i])\n\nplt.subplots_adjust(wspace=1.5)\n</pre> fig, axes = plt.subplots(1, 4, figsize=(15, 6))  for i, name in enumerate([\"n_components\", \"length\", \"area\", \"roundness\"]):     vmax = df_niches_geometries[name].sort_values()[-2:].mean()     sns.heatmap(df_niches_geometries[[name]], cmap=\"viridis\", annot=True, fmt=\".2f\", vmax=vmax, ax=axes[i])  plt.subplots_adjust(wspace=1.5) In\u00a0[\u00a0]: Copied! <pre>import networkx as nx\nfrom community import community_louvain\nfrom netgraph import Graph\n</pre> import networkx as nx from community import community_louvain from netgraph import Graph In\u00a0[15]: Copied! <pre>weights, node_color, node_size, node_shape = sopa.spatial.prepare_network(adata, \"cell_type\", \"niches\")\n</pre> weights, node_color, node_size, node_shape = sopa.spatial.prepare_network(adata, \"cell_type\", \"niches\") <pre>[INFO] (sopa.spatial.distance) Computing all distances for the 4 pairs of categories\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:07&lt;00:00,  3.61it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.69it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:07&lt;00:00,  3.52it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.48it/s]\n</pre> In\u00a0[16]: Copied! <pre>g = nx.from_pandas_adjacency(weights)\nnode_to_community = community_louvain.best_partition(g, resolution=1.35)\n</pre> g = nx.from_pandas_adjacency(weights) node_to_community = community_louvain.best_partition(g, resolution=1.35) In\u00a0[\u00a0]: Copied! <pre>Graph(\n    g,\n    node_size=node_size,\n    node_color=node_color,\n    node_shape=node_shape,\n    node_edge_width=0,\n    node_layout=\"community\",\n    node_layout_kwargs={\"node_to_community\": node_to_community},\n    node_labels=True,\n    node_label_fontdict={\"size\": 6, \"weight\": \"bold\"},\n    edge_alpha=1,\n    edge_width=0.5,\n    edge_layout_kwargs={\"k\": 2000},\n    edge_layout=\"bundled\",\n)\n</pre> Graph(     g,     node_size=node_size,     node_color=node_color,     node_shape=node_shape,     node_edge_width=0,     node_layout=\"community\",     node_layout_kwargs={\"node_to_community\": node_to_community},     node_labels=True,     node_label_fontdict={\"size\": 6, \"weight\": \"bold\"},     edge_alpha=1,     edge_width=0.5,     edge_layout_kwargs={\"k\": 2000},     edge_layout=\"bundled\", ) <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/netgraph/_edge_layout.py:978: RuntimeWarning: invalid value encountered in divide\n  displacement = compatibility * delta / distance_squared[..., None]\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/netgraph/_utils.py:360: RuntimeWarning: invalid value encountered in divide\n  v = v / np.linalg.norm(v, axis=-1)[:, None] # unit vector\n</pre> Out[\u00a0]: <pre>&lt;netgraph._main.Graph at 0x2b1668fd0&gt;</pre>"},{"location":"tutorials/spatial/#1-prepare-your-data","title":"1. Prepare your data\u00b6","text":"<p>You'll need the <code>AnnData</code> output of Sopa. If using the <code>SpatialData</code> object itself, simply extract the table.</p> <p>Make sure you have at least a cell-type annotation (i.e. a column in <code>adata.obs</code> corresponding to cell-types), and eventually a niche annotation (with algorithms such as Novae).</p>"},{"location":"tutorials/spatial/#optional-download-the-tutorial-data","title":"(Optional) Download the tutorial data\u00b6","text":"<p>The <code>.h5ad</code> file used in this tutorial is publicly available on Zenodo here.</p>"},{"location":"tutorials/spatial/#2-distances-between-cell-categories","title":"2. Distances between cell categories\u00b6","text":"<p>You can compute the mean hop-distance between all pairs of cell-types:</p> <p>Below, <code>'cell_type'</code> is the name of the column of <code>adata.obs</code> containing the cell-type annotation</p>"},{"location":"tutorials/spatial/#3-transform-niches-into-shapes","title":"3. Transform niches into shapes\u00b6","text":"<p>If desired, niches can be transformed into Shapely geometries. Each occurence of a specific niche will correspond to one Polygon. This makes efficient further operations on niches, such as the one in the next section.</p>"},{"location":"tutorials/spatial/#4-niches-geometries","title":"4. Niches geometries\u00b6","text":"<p>For each niche, we can compute geometric properties. Here, we computed some simple properties of each niche: their mean length (or perimeter), their mean area, and their mean roundness (score between 0 and 1, where high values means \"circle\"-like shape).</p> <p>NB: Since one niche can be divided into multiple connected components (or multiple occurences), we indeed need to average the above geometric properties over all connected components of one niche category</p>"},{"location":"tutorials/spatial/#5-cell-type-niche-network","title":"5. Cell-type / Niche network\u00b6","text":"<p>The distances between cell-types and/or niches can be summerized into one network, and plot with the Netgraph library. It provides a quick overview of the interactions happening in the micro-environment of one slide.</p> <p>To continue, you'll need to install Louvain and Netgraph:</p> <pre>!pip install python-louvain\n!pip install netgraph\n</pre>"},{"location":"tutorials/techno_specific/","title":"Technology-specific advice","text":"<p>Sopa is designed to run on all spatial technologies at single-cell resolution, but some choices or parameters may be more or less suited to certain technologies.</p> <p>Note</p> <p>All this advice is for the API usage, but it also applies to the CLI and the Snakemake pipeline (update the usage accordingly or look at our per-technology Snakemake configs).</p>"},{"location":"tutorials/techno_specific/#xenium-or-merscope","title":"Xenium or MERSCOPE","text":"<p>For Xenium or MERSCOPE data, we recommend using a transcript-based segmentation tool, e.g., Baysor or Proseg. With the Xenium 5k panel, Proseg is recommended due to its fast results and high quality.</p> <p>To use the prior 10X or Vizgen segmentation, you need to precise it in <code>sopa.make_transcript_patches</code> - with <code>sopa&gt;=2.0.4</code>, use <code>prior_shapes_key=\"auto\"</code> to automatically detect the prior and use it for Baysor/Proseg.</p> <pre><code>sopa.make_transcript_patches(sdata, prior_shapes_key=\"auto\") # for proseg, also add patch_width=None\n</code></pre> <p>If using Baysor, you can also use <code>area=20</code> to filter cells with an area below 20 um\u00b2.</p> <p>To filter low-quality cells, you can provide <code>min_transcripts=20</code> to the aggregation.</p>"},{"location":"tutorials/techno_specific/#cosmx","title":"CosMx","text":"<p>For CosMx data, the same advice as above is applicable, although you may experience some issues when reading the data with <code>sopa.io.cosmx</code> due to some frequent changes in the AtoMX exports. If so, please open an issue to improve this.</p>"},{"location":"tutorials/techno_specific/#visium-hd","title":"Visium HD","text":"<p>See here the full Visium HD specific tutorial.</p>"},{"location":"tutorials/techno_specific/#macsima-or-phenocycler","title":"MACSima or PhenoCycler","text":"<p>For spatial proteomics, Cellpose is needed. To avoid having artifacts outside of the tissue, we recommend running <code>sopa.segmentation.tissue</code> before running Cellpose. This way, Cellpose will run only inside the tissue.</p> <p>For MACSima, we recommend to use <code>diameter=35</code> pixels and <code>min_area=400</code> pixels\u00b2 to <code>sopa.segmentation.cellpose</code>. For PhenoCycler data, it will depend on the image resolution, so you'll need to choose a diameter (in pixels) that is biologically relevant.</p> <p>During aggregation, you can for instance use <code>expand_radius_ratio=0.1</code> to expand the cells, <code>min_intensity_ratio=0.1</code> to filter cells with a too low intensity.</p>"},{"location":"tutorials/techno_specific/#he-or-wsi","title":"H&amp;E or WSI","text":"<p>If you have only a H&amp;E/WSI slide without spatial omics, you can also use Sopa, although many operations are dedicated to spatial omics. For instance, <code>sopa.segmentation.tissue</code> for tissue segmentation, <code>sopa.segmentation.stardist</code> for cell segmentation, <code>sopa.patches.compute_embeddings</code> and <code>sopa.patches.cluster_embeddings</code> for patches embeddings/clusters.</p> <p>Though, if you have H&amp;E with spatial omics, e.g. Xenium + H&amp;E, in that case, we recommend segmenting the data on the spatial transcriptomics and aligning the H&amp;E to performed joined operations as in this tutorial.</p> <p>Sopa WSI extra</p> <p>There is a Sopa extra for WSI, you can install it via <code>pip install 'sopa[wsi]'</code></p>"},{"location":"tutorials/techno_specific/#other","title":"Other","text":"<p>For other technologies not listed here, please open a new GitHub issue.</p>"},{"location":"tutorials/visium_hd/","title":"Visium HD tutorial","text":"In\u00a0[\u00a0]: Copied! <pre>import spatialdata\n\nimport sopa\n</pre> import spatialdata  import sopa <p>You can read your Visium HD data with <code>sopa.io.visium_hd</code>.</p> <p>Important notes:</p> <ul> <li>This API tutorial assumes you already ran Space Ranger. If you didn't, you can consider running the full sopa pipeline for Visium HD via Nextflow (see <code>nf-core/sopa</code>)</li> <li>If Space Ranger produced files with no prefix (for instance, <code>feature_slice.h5</code>), then pass <code>dataset_id=\"\"</code> to the reader below.</li> <li>If your full resolution microscopy image is not stored in the <code>microscope_image</code>, you need to provide <code>fullres_image_file</code> as below. Else, it will be found automatically. This is not necessary if you have prior 10X Genomics segmentation (in which case you can diectly use proseg).</li> </ul> In\u00a0[\u00a0]: Copied! <pre>sdata = sopa.io.visium_hd(\n    \"data/visium_hd/Visium_HD_Mouse_Small_Intestine\",  # Space Ranger output directory\n    fullres_image_file=\"/path/to/microscopy/image.tiff\",  # not needed for this tuto\n    dataset_id=\"\",  # only if Space Ranger produced files with no prefix\n)\n\nsdata\n</pre> sdata = sopa.io.visium_hd(     \"data/visium_hd/Visium_HD_Mouse_Small_Intestine\",  # Space Ranger output directory     fullres_image_file=\"/path/to/microscopy/image.tiff\",  # not needed for this tuto     dataset_id=\"\",  # only if Space Ranger produced files with no prefix )  sdata <p>Then, we save it on-disk:</p> In\u00a0[2]: Copied! <pre>sdata.write(\"mouse_small_intestine.zarr\")  # save it\n\nsdata = spatialdata.read_zarr(\"mouse_small_intestine.zarr\")  # open-it back\n</pre> sdata.write(\"mouse_small_intestine.zarr\")  # save it  sdata = spatialdata.read_zarr(\"mouse_small_intestine.zarr\")  # open-it back <p>The first option is to run Stardist on the H&amp;E image. Note that, to do that, you'll need the full-resolution image. Else, if you have a prior 10X segmentation, you can directly go to the Proseg section.</p> <p>First, we create the patches for the cell segmentation.</p> In\u00a0[5]: Copied! <pre>sopa.make_image_patches(sdata)\n</pre> sopa.make_image_patches(sdata) <pre>[INFO] (sopa.patches._patches) Added 156 patche(s) to sdata['image_patches']\n</pre> <p>Now we can run stardist on the H&amp;E image.</p> In\u00a0[6]: Copied! <pre>sopa.segmentation.stardist(sdata, min_area=30)\n</pre> sopa.segmentation.stardist(sdata, min_area=30) <pre>[WARNING] (sopa._settings) Running without parallelization backend can be slow. Consider using a backend, e.g. via `sopa.settings.parallelization_backend = 'dask'`, or `export SOPA_PARALLELIZATION_BACKEND=dask`.\n  3%|\u258e         | 4/156 [00:34&lt;22:03,  8.71s/it]</pre> <pre>WARNING:tensorflow:5 out of the last 5 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x5638ebb50&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n</pre> <pre>  3%|\u258e         | 5/156 [00:36&lt;16:07,  6.40s/it]</pre> <pre>WARNING:tensorflow:6 out of the last 6 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x563ab4550&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 156/156 [16:27&lt;00:00,  6.33s/it]\n[INFO] (sopa.segmentation._stainings) Found 430536 total cells\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 63782/63782 [00:23&lt;00:00, 2714.30it/s]\n[INFO] (sopa.segmentation._stainings) Added 410196 cell boundaries in sdata['stardist_boundaries']\n</pre> <p>You can use <code>proseg</code> to use the bins information to improve the segmentation and aggregation. To do so, <code>proseg</code> needs a prior segmentation: you can either use <code>stardist</code> (see how to run it above), or directly use the 10X Genomics default segmentation available on the recent Visium HD versions.</p> <p>Using <code>prior_shapes_key=\"auto\"</code> will automatically detect which segmentation to use. If you ran <code>stardist</code>, it will use it as a prior, else it will fallback to the default 10X Genomics segmentation.</p> <p>NB: this feature is still experimental, and was added in <code>sopa==2.1.10</code>. Ensure you read your data with <code>sopa.io.visium_hd</code> using <code>sopa&gt;=2.1.10</code>.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.segmentation.proseg(sdata, prior_shapes_key=\"auto\")\n</pre> sopa.segmentation.proseg(sdata, prior_shapes_key=\"auto\") <p>Since <code>proseg</code> already aggregate the bins inside the cells, the next section (i.e., aggregation) is not mandatory.</p> <p>Now, we can run <code>sopa.aggregate</code> to aggregate the bins into the cells. This is mandatory if you used stardist only, but optional if you ran proseg. Even if you used proseg, it can still be useful it if you want some additional aggregation or filtering.</p> <p>For each cell, we expand their radius, and then Sopa will sum the transcript counts of all 2-microns-bins touching or included within the cell.</p> <p>Here, <code>expand_radius_ratio = 1</code>, which means that the cells will be expanded a value of <code>1 * mean_radius</code> before aggregating the means. You can choose any positive float value. If you ran proseg, it will only be used for channel aggregation, since the transcripts are already aggregated.</p> <p>Note: There is an argument <code>bins_key</code>, but by default Sopa will understand that it's Visium HD data and that it should use the 2-microns bins. Also, on the example below, we only aggregate the bins, not the H&amp;E channels.</p> <p>Note 2: You can also provide <code>no_overlap=True</code> to force each bin being mapped to only one cell.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.aggregate(sdata, aggregate_channels=False, expand_radius_ratio=1)\n</pre> sopa.aggregate(sdata, aggregate_channels=False, expand_radius_ratio=1) <p>Now, we have an AnnData object with the gene expression per cell.</p> In\u00a0[10]: Copied! <pre>adata = sdata[\"table\"]\nadata\n</pre> adata = sdata[\"table\"] adata Out[10]: <pre>AnnData object with n_obs \u00d7 n_vars = 408458 \u00d7 19059\n    obs: 'region', 'slide', 'cell_id', 'area'\n    var: 'gene_ids', 'feature_types', 'genome'\n    uns: 'sopa_attrs', 'spatialdata_attrs'\n    obsm: 'spatial'</pre> <p>For instance, we can now use Scanpy to plot gene expression.</p> In\u00a0[11]: Copied! <pre>import scanpy as sc\n</pre> import scanpy as sc In\u00a0[12]: Copied! <pre># basic preprocessing\nsc.pp.filter_genes(adata, min_cells=10)\nsc.pp.filter_cells(adata, min_counts=20)\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\n</pre> # basic preprocessing sc.pp.filter_genes(adata, min_cells=10) sc.pp.filter_cells(adata, min_counts=20) sc.pp.normalize_total(adata) sc.pp.log1p(adata) <p>We can then use <code>sc.pl.spatial</code> to show the gene expression per cells. Note that, here, we show cells, not bins.</p> In\u00a0[13]: Copied! <pre>sc.pl.spatial(adata, color=\"Tpm2\", spot_size=80, vmax=\"p98\")\n</pre> sc.pl.spatial(adata, color=\"Tpm2\", spot_size=80, vmax=\"p98\") In\u00a0[\u00a0]: Copied! <pre>sdata[\"square_002um\"].X = sdata[\"square_002um\"].X.tocsc()  # optimisation with the csc format\n\nlazy_bins_image = spatialdata.rasterize_bins(\n    sdata,\n    bins=\"Visium_HD_Mouse_Small_Intestine_square_002um\",  # key of the bins shapes\n    table_name=\"square_002um\",  # key of the table with the bins gene expression\n    row_key=\"array_row\",\n    col_key=\"array_col\",\n)\n</pre> sdata[\"square_002um\"].X = sdata[\"square_002um\"].X.tocsc()  # optimisation with the csc format  lazy_bins_image = spatialdata.rasterize_bins(     sdata,     bins=\"Visium_HD_Mouse_Small_Intestine_square_002um\",  # key of the bins shapes     table_name=\"square_002um\",  # key of the table with the bins gene expression     row_key=\"array_row\",     col_key=\"array_col\", ) <p>Note that <code>lazy_bins_image</code> is an image of size <code>(19059, 690, 690)</code>, that is <code>G=19059</code> genes, and <code>690x690</code> bins. This would correspond to a 33.80GB image in memory, if it wasn't lazy.</p> In\u00a0[\u00a0]: Copied! <pre>lazy_bins_image\n</pre> lazy_bins_image <p>We can save this image in the <code>sdata</code> object.</p> In\u00a0[13]: Copied! <pre>sdata[\"gene_expression_2_um\"] = lazy_bins_image\n</pre> sdata[\"gene_expression_2_um\"] = lazy_bins_image <p>Then, we can visualize this image with Napari. When showing a gene, it will compute the corresponding layer of the lazy image, and it will be displayed in milliseconds, i.e. looking instantaneous.</p> In\u00a0[\u00a0]: Copied! <pre>from napari_spatialdata import Interactive\n\nInteractive(sdata)\n</pre> from napari_spatialdata import Interactive  Interactive(sdata) <p>You'll be able to display cells and the bins expression. It should look like that:</p> <p> </p> In\u00a0[15]: Copied! <pre>sopa.io.explorer.write(\"mouse_small_intestine.explorer\", sdata)\n</pre> sopa.io.explorer.write(\"mouse_small_intestine.explorer\", sdata) <pre>[INFO] (sopa.io.explorer.table) Writing table with 18166 columns\n[INFO] (sopa.io.explorer.table) Writing 2 cell categories: region, slide\n[INFO] (sopa.io.explorer.shapes) Writing 332556 cell polygons\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (3, 21943, 23618)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (3, 21943, 23618)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (3, 10971, 11809)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (3, 5485, 5904)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (3, 2742, 2952)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (3, 1371, 1476)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (3, 685, 738)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: mouse_small_intestine.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open mouse_small_intestine.explorer/experiment.xenium'\n</pre>"},{"location":"tutorials/visium_hd/#visium-hd-tutorial","title":"Visium HD tutorial\u00b6","text":"<p>We can run Sopa on Visium HD, as the 2 micron bins are subcellular. It uses similar functions as in the \"normal\" API tutorial.</p> <p>For this tutorial, we use the mouse small intestine public dataset from 10X Genomics.</p>"},{"location":"tutorials/visium_hd/#reading-the-data","title":"Reading the data\u00b6","text":""},{"location":"tutorials/visium_hd/#option-1-running-stardist","title":"Option 1: running StarDist\u00b6","text":""},{"location":"tutorials/visium_hd/#option-2-running-proseg","title":"Option 2: running Proseg\u00b6","text":""},{"location":"tutorials/visium_hd/#aggregation","title":"Aggregation\u00b6","text":""},{"location":"tutorials/visium_hd/#single-cell-table","title":"Single-cell table\u00b6","text":""},{"location":"tutorials/visium_hd/#bins-visualization","title":"Bins visualization\u00b6","text":"<p>The 2-micron bins are arranged in a grid, so they can be visualized as an image of <code>G</code> channels, where <code>G</code> is the number of genes.</p> <p>Creating the image would be massive, so we need to create it lazily. This can be done with <code>spatialdata.rasterize_bins</code>.</p>"},{"location":"tutorials/visium_hd/#xenium-explorer","title":"Xenium Explorer\u00b6","text":"<p>Although the Xenium Explorer can be used (as below), it will not display the bins. If you want to see the bins, use <code>Napari</code> as detailed above.</p>"},{"location":"tutorials/xenium_explorer/explorer/","title":"Xenium Explorer usage","text":"<p>This tutorial shows interoperability tools between Sopa and the Xenium Explorer. We show how to go back and forth, between analysis and visualization.</p> <p>Ensure that you have already run Sopa, either with the Snakemake pipeline, CLI, or API.</p> <p>For image alignment with the Xenium Explorer, refer to this tutorial.</p> <p>Xenium Explorer is a registered trademark of 10x Genomics. The Xenium Explorer is licensed for usage on Xenium data (more details here).</p> In\u00a0[\u00a0]: Copied! <pre>import sopa\n</pre> import sopa <p>For this tutorial, we use some generated data that looks similar to the output of Sopa.</p> In\u00a0[\u00a0]: Copied! <pre># if you have your own data, then\n# use `sdata = spatialdata.read_zarr(\"...\")` instead\n\nsdata = sopa.io.toy_dataset(as_output=True)\n</pre> # if you have your own data, then # use `sdata = spatialdata.read_zarr(\"...\")` instead  sdata = sopa.io.toy_dataset(as_output=True) In\u00a0[\u00a0]: Copied! <pre># directory where we'll save all the Xenium Explorer files\nexplorer_path = \"tuto.explorer\"\n</pre> # directory where we'll save all the Xenium Explorer files explorer_path = \"tuto.explorer\" <p>Now, we need to create the Xenium Explorer input files. To do so, you can use <code>sopa.io.explorer.write</code> as below:</p> <p>If you have already run Sopa on your own data, you have likely already done the step below.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.io.explorer.write(explorer_path, sdata)\n</pre> sopa.io.explorer.write(explorer_path, sdata) <pre>[INFO] (sopa.io.explorer.table) Writing table with 6 columns\n[INFO] (sopa.io.explorer.table) Writing 2 cell categories: region, slide\n[INFO] (sopa.io.explorer.shapes) Writing 400 cell polygons\n[INFO] (sopa.io.explorer.points) Writing 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 0: 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 1: 10000 transcripts\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (4, 2048, 2048)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 2048, 2048)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 1024, 1024)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 512, 512)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 256, 256)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 128, 128)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 64, 64)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre> <p>Now, inside the <code>explorer_path</code> directory, you have an <code>experiment.xenium</code> file that you can open with the Xenium Explorer.</p> In\u00a0[\u00a0]: Copied! <pre>import scanpy as sc\n\n# for convenience, we extract the AnnData table as a new variable\nadata = sdata.tables[\"table\"]\n</pre> import scanpy as sc  # for convenience, we extract the AnnData table as a new variable adata = sdata.tables[\"table\"] In\u00a0[\u00a0]: Copied! <pre>sc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\nsc.tl.leiden(adata, resolution=0.1)\n</pre> sc.pp.normalize_total(adata) sc.pp.log1p(adata) sc.pp.pca(adata) sc.pp.neighbors(adata) sc.tl.umap(adata) sc.tl.leiden(adata, resolution=0.1) In\u00a0[7]: Copied! <pre>sc.pl.umap(adata, color=\"leiden\")\n</pre> sc.pl.umap(adata, color=\"leiden\") In\u00a0[8]: Copied! <pre>sopa.io.explorer.write_cell_categories(explorer_path, adata)\n</pre> sopa.io.explorer.write_cell_categories(explorer_path, adata) <pre>[INFO] (sopa.io.explorer.table) Writing 3 cell categories: region, slide, leiden\n</pre> In\u00a0[\u00a0]: Copied! <pre>sopa.io.explorer.write(explorer_path, sdata, mode=\"+o\")\n</pre> sopa.io.explorer.write(explorer_path, sdata, mode=\"+o\") In\u00a0[\u00a0]: Copied! <pre># update all files except the images and transcript files\nsopa.io.explorer.write(explorer_path, sdata, mode=\"-it\")\n</pre> # update all files except the images and transcript files sopa.io.explorer.write(explorer_path, sdata, mode=\"-it\") In\u00a0[9]: Copied! <pre>import pandas as pd\n\n# write below the path to the file that you downloaded, e.g. \"Selection_1_cells_stats.csv\"\ndf_selection = pd.read_csv(\"Selection_1_cells_stats.csv\", skiprows=2)\n\n# we create a new column to annotate which cells were selected or not\nadata.obs[\"lasso\"] = \"not-selected\"\nadata.obs.loc[df_selection[\"Cell ID\"].values, \"lasso\"] = \"selected\"\n</pre> import pandas as pd  # write below the path to the file that you downloaded, e.g. \"Selection_1_cells_stats.csv\" df_selection = pd.read_csv(\"Selection_1_cells_stats.csv\", skiprows=2)  # we create a new column to annotate which cells were selected or not adata.obs[\"lasso\"] = \"not-selected\" adata.obs.loc[df_selection[\"Cell ID\"].values, \"lasso\"] = \"selected\" <p>Now, <code>sdata.table.obs[\"lasso\"]</code> denotes which cells have been selected by the lasso tool (either \"selected\" or \"not-selected\").</p> <p>We can then use <code>spatialdata_plot</code> to display the cells that were selected by the lasso tool. Make sure to install <code>spatialdata_plot &gt;= 0.1.0</code>, e.g. via <code>pip install spatialdata_plot</code>. Now, we can render the shapes (i.e., the spots) and colour them based on the <code>\"lasso\"</code> column that was saved in <code>sdata.table.obs</code>:</p> In\u00a0[10]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[11]: Copied! <pre>sdata.pl.render_shapes(color=\"lasso\").pl.show(\"global\")\n</pre> sdata.pl.render_shapes(color=\"lasso\").pl.show(\"global\") <pre>/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/spatialdata_plot/pl/basic.py:879: UserWarning: Converting copy of 'lasso' column to categorical dtype for categorical plotting. Consider converting before plotting.\n  _render_shapes(\n/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/spatialdata_plot/pl/utils.py:782: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n  color_vector = color_source_vector.map(color_mapping)\n</pre> <p>Then, we read the polygon coordinates, and perform a polygon query on the <code>\"global\"</code> coordinate system (i.e., the pixel coordinate system).</p> <p>Note: if not using Xenium data, please provide the <code>pixel_size</code> argument in the <code>sopa.io.add_explorer_selection</code> function below (the <code>pixel_size</code> should be the one that has been used when running Sopa). If you used the snakemake pipeline, this argument can be found in the config. Without this, the polygon may not be in the right coordinate system.</p> In\u00a0[12]: Copied! <pre>import spatialdata_io\n\npolygon = spatialdata_io.xenium_explorer_selection(\"Selection_1_coordinates.csv\")\n</pre> import spatialdata_io  polygon = spatialdata_io.xenium_explorer_selection(\"Selection_1_coordinates.csv\") In\u00a0[13]: Copied! <pre>query_sdata = sdata.query.polygon(polygon, target_coordinate_system=\"global\")\nquery_sdata\n</pre> query_sdata = sdata.query.polygon(polygon, target_coordinate_system=\"global\") query_sdata Out[13]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 523, 418), (3, 261, 209), (3, 131, 105)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 1044, 837)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u2514\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (47, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (47, 6)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), transcripts (Points), cellpose_boundaries (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Using <code>spatialdata_plot</code>, we see that we indeed selected the cells we desired.</p> In\u00a0[14]: Copied! <pre>query_sdata.pl.render_shapes().pl.show(\"global\")\n</pre> query_sdata.pl.render_shapes().pl.show(\"global\") In\u00a0[3]: Copied! <pre>key_added = \"large_cells\"\n\nsopa.io.explorer.add_explorer_selection(sdata, \"coordinates.csv\", key_added=key_added)\n</pre> key_added = \"large_cells\"  sopa.io.explorer.add_explorer_selection(sdata, \"coordinates.csv\", key_added=key_added) <p>New shapes have been added to the <code>sdata</code> object:</p> In\u00a0[4]: Copied! <pre>sdata\n</pre> sdata Out[4]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 1024, 1024), (3, 512, 512), (3, 256, 256)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u251c\u2500\u2500 'misc': DataFrame with shape: (&lt;Delayed&gt;, 2) (2D points)\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (400, 1) (2D shapes)\n\u2502     \u2514\u2500\u2500 'large_cells': GeoDataFrame shape: (4, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (400, 6)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), misc (Points), transcripts (Points), cellpose_boundaries (Shapes), large_cells (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Now, we will update the segmentation. In particular, it will perform aggregation (i.e., counting the transcripts and/or averaging the channels inside the new cells), and it will remove cells that are behind the selected cells:</p> In\u00a0[5]: Copied! <pre>sopa.overlay_segmentation(sdata, shapes_key=key_added)\n</pre> sopa.overlay_segmentation(sdata, shapes_key=key_added) <pre>[INFO] (sopa.aggregation.transcripts) Aggregating transcripts over 4 cells\n</pre> <pre>[########################################] | 100% Completed | 101.67 ms\n</pre> <pre>[INFO] (sopa.aggregation.channels) Averaging channels intensity over 4 cells with expansion expand_radius_ratio=0\n</pre> <pre>[########################################] | 100% Completed | 105.89 ms\n</pre> <pre>/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:96: UserWarning: Key `large_cells` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n  utils.warn_names_duplicates(\"obs\")\n/Users/quentinblampey/dev/_external/spatialdata/src/spatialdata/_core/_elements.py:116: UserWarning: Key `table` already exists. Overwriting it in-memory.\n  self._check_key(key, self.keys(), self._shared_keys)\n</pre> <p>Now, we have a new table (the old table is also kept), and we have new shapes called <code>'cellpose_boundaries_overlay_large_cells'</code>.</p> In\u00a0[6]: Copied! <pre>sdata\n</pre> sdata Out[6]: <pre>SpatialData object\n\u251c\u2500\u2500 Images\n\u2502     \u251c\u2500\u2500 'he_image': DataTree[cyx] (3, 1024, 1024), (3, 512, 512), (3, 256, 256)\n\u2502     \u2514\u2500\u2500 'image': DataArray[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u251c\u2500\u2500 'misc': DataFrame with shape: (&lt;Delayed&gt;, 2) (2D points)\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 5) (2D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (400, 1) (2D shapes)\n\u2502     \u251c\u2500\u2500 'cellpose_boundaries_overlay_large_cells': GeoDataFrame shape: (380, 1) (2D shapes)\n\u2502     \u2514\u2500\u2500 'large_cells': GeoDataFrame shape: (4, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u251c\u2500\u2500 'old_table': AnnData (400, 6)\n      \u2514\u2500\u2500 'table': AnnData (380, 6)\nwith coordinate systems:\n    \u25b8 'global', with elements:\n        he_image (Images), image (Images), misc (Points), transcripts (Points), cellpose_boundaries (Shapes), cellpose_boundaries_overlay_large_cells (Shapes), large_cells (Shapes)\n    \u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Now, we can update the Xenium Explorer.</p> <p>For this, we provide <code>mode=\"-it\"</code>, which means that images and transcripts will not be computed again. This is particular useful to save time: since we already have these files, they don't need to be updated.</p> In\u00a0[\u00a0]: Copied! <pre>sopa.io.explorer.write(\n    explorer_path,\n    sdata,\n    shapes_key=\"cellpose_boundaries_overlay_large_cells\",\n    gene_column=\"genes\",\n    mode=\"-it\",\n)\n</pre> sopa.io.explorer.write(     explorer_path,     sdata,     shapes_key=\"cellpose_boundaries_overlay_large_cells\",     gene_column=\"genes\",     mode=\"-it\", ) <pre>[INFO] (sopa.io.explorer.table) Writing table with 6 columns\n[INFO] (sopa.io.explorer.table) Writing 2 cell categories: region, slide\n[INFO] (sopa.io.explorer.shapes) Writing 380 cell polygons\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre> <p>It will lead to the following visualization, i.e. the old cells with an overlay of the cells that we selected with the lasso tool:</p>"},{"location":"tutorials/xenium_explorer/explorer/#explorer-directory-creation","title":"Explorer directory creation\u00b6","text":""},{"location":"tutorials/xenium_explorer/explorer/#update-the-cell-categoriesclusters","title":"Update the cell categories/clusters\u00b6","text":"<p>Here, we run some Leiden clustering with <code>scanpy</code>. Then, we will update the Xenium Explorer files to display the spot clusters.</p> <p>More generally, you can add new cell categories, i.e. a column of <code>sdata[\"table\"].obs</code>, and the Xenium Explorer will show it after the instructions below.</p> <p>Note that we only display categorical columns. If a column from <code>sdata[\"table\"].obs</code> contains continuous numerical values (e.g., <code>3.13, 7.89, ...</code>), it will not be transformed into a categorical variable, and therefore not shown in the Xenium Explorer. In this case, we recommend using the <code>spatiadata_plot</code> static plotting library or the <code>napari_spatialdata</code> interactive plotting library.</p>"},{"location":"tutorials/xenium_explorer/explorer/#option-1-via-the-anndata-object","title":"Option 1: via the AnnData object\u00b6","text":"<p>Now, you can update the explorer with your new cluster assignment. You don't need to re-run the complete conversion; you can edit the <code>analysis.zarr.zip</code> file only, as below.</p> <p>Note that the second argument of <code>write_cell_categories</code> is the <code>AnnData</code> object corresponding to <code>sdata[\"table\"]</code>.</p>"},{"location":"tutorials/xenium_explorer/explorer/#option-2-via-the-spatialdata-object","title":"Option 2: via the SpatialData object\u00b6","text":"<p>You can also re-use <code>sopa.io.explorer.write</code> with the <code>SpatialData</code> object, but provide <code>mode=\"+o\"</code> to update only the observation file (i.e., the explorer file containing the information in <code>sdata[\"table\"].obs</code>).</p> <p>Note that, it assumes the cells boundaries didn't change since you last ran <code>sopa.io.explorer.write</code>. If you performed some cell filtering, see the next section.</p>"},{"location":"tutorials/xenium_explorer/explorer/#visualize-the-new-categories-in-the-explorer","title":"Visualize the new categories in the explorer\u00b6","text":"<p>To visualize these clusters, re-open the <code>experiment.xenium</code> file and select the new <code>\"leiden\"</code> cell group (under the \"Cells\" panel and in the \"Cell groups\" dropdown). See the examples above to see how it looks on the Xenium Explorer.</p>"},{"location":"tutorials/xenium_explorer/explorer/#filtering-cells","title":"Filtering cells\u00b6","text":"<p>Sometimes, you may want to filter some cells after running Sopa. If you want these cells to be also removed in the Xenium Explorer, you'll need to update the cell boundaries, cell counts, and cell observation files.</p> <p>To do that, you can re-run <code>sopa.io.explorer.write</code>, but provide <code>mode=\"-it\"</code> to avoid creating again the images and transcript files - which are the most time-consuming files to create.</p>"},{"location":"tutorials/xenium_explorer/explorer/#use-the-coordinates-of-a-lasso-selection-in-spatialdata","title":"Use the coordinates of a lasso selection in SpatialData\u00b6","text":"<p>On the Xenium Explorer, you can use the Lasso or Rectangular selection tools to select some regions of interest. Then, you'll be able to analyze back this region of interest using <code>spatialdata</code>.</p>"},{"location":"tutorials/xenium_explorer/explorer/#selecting-cells-from-a-selection","title":"Selecting cells from a selection\u00b6","text":"<p>After making a selection, click on \"Download Cell Stats as CSV\", as below. It will create a file called <code>\"Selection_1_cells_stats.csv\"</code>.</p>"},{"location":"tutorials/xenium_explorer/explorer/#cropping-a-spatialdata-object-from-a-selection","title":"Cropping a SpatialData object from a selection\u00b6","text":"<p>You can also export the whole selection as a polygon and use it to crop the <code>spatialdata</code> object. For that, click on \"Download Selection Coordinates as CSV\", as below. It will create a file called <code>\"Selection_1_coordinates.csv\"</code>.</p>"},{"location":"tutorials/xenium_explorer/explorer/#segmentation-overlay","title":"Segmentation overlay\u00b6","text":"<p>Sometimes, you may need to select specific cells and update the segmentation accordingly. This can be specifically inetresting when you have multinucleated giant cells (MGC), which are difficult to segment. In that case, you can perform multiple lasso selections in the Xenium Explorer, and then download them all into one single file, as below.</p> <p>Then, we can load the selection coordinates and save it as new <code>sdata</code> key. Here, we call it <code>\"large_cells\"</code>.</p> <p>Note: if not using Xenium data, please provide the <code>pixel_size</code> argument in the <code>sopa.io.add_explorer_selection</code> function below (the <code>pixel_size</code> should be the one that has been used when running Sopa). If you used the snakemake pipeline, this argument can be found in the config. Without this, the polygon may not be in the right coordinate system.</p>"}]}